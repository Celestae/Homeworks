{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['C:\\\\Users\\\\love-\\\\Documents\\\\Homeworks\\\\80-629\\\\week3-Supervised']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b725e29a7551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_svc_decision_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import generate_data, plot_predictions, plot_svc_decision_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"a22_devoir_q2-classification.npz\")\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 2 2 0 0 2 1 0 2 1 1 2 2 0 2 1 2 1 1 0 1 1 1 0 1 0 1 1 0 0 1 2 2 2 2\n",
      " 0 2 2 0 2 2 2 1 0 1 0 1 2 0 1 0 0 0 2 1 2 2 2 1 1 1 1 0 0 0 2 1 0 0 1 0 2\n",
      " 0 0 0 1 0 1 1 2 2 0 2 2 0 2 0 2 0 1 1 2 0 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15494743  0.37816252]\n",
      " [ 4.6781908   3.88829842]\n",
      " [ 0.06651722  0.3024719 ]\n",
      " [ 4.44780833  5.02608254]\n",
      " [ 4.77223375  5.00873958]\n",
      " [ 1.53277921  1.46935877]\n",
      " [ 0.17742614 -0.40178094]\n",
      " [ 4.68207696  5.33821665]\n",
      " [ 3.26816936  1.23011275]\n",
      " [-1.70627019  1.9507754 ]\n",
      " [ 5.5940149   5.15847131]\n",
      " [ 0.13905245  1.57791809]\n",
      " [ 2.50844214  2.11119275]\n",
      " [ 4.95077374  4.66826086]\n",
      " [ 6.08161797  5.66826397]\n",
      " [ 0.14404357  1.45427351]\n",
      " [ 4.9658792   5.85667136]\n",
      " [ 2.42111906  2.88331001]\n",
      " [ 5.28829541  4.89585062]\n",
      " [ 0.45814821  1.27554819]\n",
      " [ 0.34512589  2.30887379]\n",
      " [-0.51080514 -1.18063218]\n",
      " [ 1.81241247  2.96495855]\n",
      " [ 2.10351246  0.47278486]\n",
      " [ 2.0345496   2.55985975]\n",
      " [ 0.8644362  -0.74216502]\n",
      " [ 0.89523458  3.33366761]\n",
      " [ 1.86755799 -0.97727788]\n",
      " [-0.24772476  2.85123973]\n",
      " [ 4.32472605 -0.52163859]\n",
      " [ 1.23029068  1.20237985]\n",
      " [ 2.26975462 -1.45436567]\n",
      " [-0.25968511  4.41543178]\n",
      " [ 5.31261573  4.19897117]\n",
      " [ 5.38589528  5.41175208]\n",
      " [ 4.49989233  4.22761445]\n",
      " [ 4.35357155  5.13352543]\n",
      " [-0.81314628 -1.7262826 ]\n",
      " [ 4.48287858  5.34079726]\n",
      " [ 6.19157239  5.47223974]\n",
      " [-2.55298982  0.6536186 ]\n",
      " [ 5.56331796  4.46003425]\n",
      " [ 4.34204629  4.7692077 ]\n",
      " [ 5.46042941  5.15936383]\n",
      " [ 1.94735726  3.48957885]\n",
      " [ 0.97873798  2.2408932 ]\n",
      " [ 3.73237829  4.34383376]\n",
      " [ 0.95008842 -0.15135721]\n",
      " [ 1.51575003  4.17880574]\n",
      " [ 5.19800336  4.45346925]\n",
      " [-0.34791215  0.15634897]\n",
      " [ 3.20910103 -0.35223873]\n",
      " [-0.38732682 -0.30230275]\n",
      " [ 1.76405235  0.40015721]\n",
      " [ 0.3130677  -0.85409574]\n",
      " [ 4.98035859  4.41595325]\n",
      " [ 2.19849366 -0.80436553]\n",
      " [ 4.59829517  4.65522511]\n",
      " [ 4.38728224  5.42218149]\n",
      " [ 5.42841531  4.6744872 ]\n",
      " [ 0.84726967  4.27389559]\n",
      " [ 4.30133844  2.85906699]\n",
      " [ 0.87957153  0.37881778]\n",
      " [-0.4057275   2.95409506]\n",
      " [-1.63019835  0.46278226]\n",
      " [-0.63432209 -0.36274117]\n",
      " [-0.02818223  0.42833187]\n",
      " [ 4.62762259  4.58678073]\n",
      " [ 1.09799494  2.70368459]\n",
      " [-1.04855297 -1.42001794]\n",
      " [-0.89546656  0.3869025 ]\n",
      " [ 4.38441304  3.72077219]\n",
      " [-0.67246045 -0.35955316]\n",
      " [ 5.26163833  4.91422683]\n",
      " [-0.10321885  0.4105985 ]\n",
      " [-1.61389785 -0.21274028]\n",
      " [-1.25279536  0.77749036]\n",
      " [ 0.20816147  4.36509743]\n",
      " [-0.88778575 -1.98079647]\n",
      " [ 2.0646383  -0.14910119]\n",
      " [ 0.48850101  1.54774584]\n",
      " [ 5.08333675  5.31751572]\n",
      " [ 5.4747104   5.04377562]\n",
      " [ 0.76103773  0.12167502]\n",
      " [ 4.82300304  4.31252435]\n",
      " [ 4.42626567  4.78108998]\n",
      " [-0.50965218 -0.4380743 ]\n",
      " [ 4.75098377  5.96476603]\n",
      " [ 0.44386323  0.33367433]\n",
      " [ 4.6302185   5.7715073 ]\n",
      " [ 1.49407907 -0.20515826]\n",
      " [ 1.0326712   1.58424801]\n",
      " [ 0.19380428  0.6317255 ]\n",
      " [ 4.2543712   5.21969585]\n",
      " [ 0.04575852 -0.18718385]\n",
      " [-0.10612893  3.08167759]\n",
      " [ 4.54358889  5.55850814]\n",
      " [ 1.69036814  2.10298405]\n",
      " [ 2.92087795  1.26748486]\n",
      " [ 2.59363584  1.69347437]]\n",
      "[0.15494743 0.37816252]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2693209543318646"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = zip(*X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  8., 17.,  7., 11.,  6.,  8.,  9., 18., 12.]),\n",
       " array([-1.98079647, -1.18624022, -0.39168397,  0.40287228,  1.19742853,\n",
       "         1.99198478,  2.78654103,  3.58109728,  4.37565353,  5.17020978,\n",
       "         5.96476603]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.hist(x1)\n",
    "ax2.hist(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.,  7., 14., 16., 11., 10.,  3.,  9., 20.,  8.],\n",
       "        [ 2.,  6., 13., 15., 10.,  6.,  9., 11., 17., 11.]]),\n",
       " array([-2.55298982, -1.6785336 , -0.80407738,  0.07037885,  0.94483507,\n",
       "         1.81929129,  2.69374751,  3.56820373,  4.44265995,  5.31711617,\n",
       "         6.19157239]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x1, x2, hue=y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4pt) Suite `a une exploration des donn´ees, que remarquez-vous?\n",
    "# Il y a deux grands groupes que l'on peut appercevoir.\n",
    "# Que pouvez-vous dire de la performance (taux de bonne classification) de test\n",
    "# d’un mod`ele n’utilisant que des fronti`eres de d´ecision lin´eaire pour ce probl`eme?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(X, y):\n",
    "    # Note: on transforme simplement les cibles de {0,1} à {-1,+1}\n",
    "    Y = (X_train[1]*2)-1\n",
    "    Y = Y.reshape(2, 1)\n",
    "\n",
    "    # On calcule les paramètres du modèle\n",
    "    # (c'est le même calcul que celui de la semaine dernière pour w_ols)\n",
    "    A = np.linalg.inv(np.dot(X.T, X))\n",
    "    B = np.dot(X.T, Y)\n",
    "\n",
    "    return np.dot(A, B)\n",
    "\n",
    "# pour obtenir la frontière de décision visuellement\n",
    "\n",
    "\n",
    "def calculate_decision_boundary(W):\n",
    "    x_1 = np.linspace(-10, 10)  # <- pour x1;\n",
    "\n",
    "    # Le but est donc de calculer x2 à partir de x1 et des poids.\n",
    "    x_2 = (-W[0] - W[1]*x_1) / W[2]\n",
    "    return x_1, x_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,67) and (2,1) not aligned: 67 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/2641869053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 1) On (estime) entraîne les paramètres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# k est le nombre de classes et dim est la dimensionalité des données\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# dim x k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# 2) Une fois les paramètres obtenus, on peut obtenir les prédictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/668108507.py\u001b[0m in \u001b[0;36mOLS\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# (c'est le même calcul que celui de la semaine dernière pour w_ols)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,67) and (2,1) not aligned: 67 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "\n",
    "# On ajoute une colonne de 1 aux données\n",
    "# Ça nous permet d'apprendre le biais (w0 dans: w_1x + w0)\n",
    "X_b = np.array([np.ones(len(X)), X[:, 0], X[:, 1]]).T\n",
    "####\n",
    "\n",
    "Y = y_train\n",
    "X_test = X_test\n",
    "\n",
    "# Comme plus haut on ajoute une colonne de 1 aux données de test\n",
    "X_test_b = np.array([np.ones(len(X_test)), X_test[:, 0], X_test[:, 1]]).T\n",
    "###\n",
    "\n",
    "Y_test = y_test\n",
    "\n",
    "# 1) On (estime) entraîne les paramètres\n",
    "# k est le nombre de classes et dim est la dimensionalité des données\n",
    "W = OLS(X_b, Y)  # dim x k\n",
    "\n",
    "# 2) Une fois les paramètres obtenus, on peut obtenir les prédictions\n",
    "# a) for test data\n",
    "y_x = np.dot(W.T, X_test_b.T)  # valeur réelle\n",
    "pred_test = 1*(y_x > 0)[0]  # valeur binaire\n",
    "\n",
    "# b) Idem pour l'ensemble d'entraînement\n",
    "y_x = np.dot(W.T, X_b.T)\n",
    "pred_train = 1*(y_x > 0)[0]\n",
    "\n",
    "\n",
    "# 3) On calcule aussi la frontière de décision\n",
    "#    pour pouvoir la visualiser\n",
    "line_x, line_y = calculate_decision_boundary(W)\n",
    "\n",
    "\n",
    "# 4) Rendu visuel\n",
    "plot_predictions(X, Y, X_test, Y_test, pred_train, pred_test, line_x, line_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6pt) Divide your dataset into training, validation, and test sets.\n",
    "# The validation and test sets must each make up 20% of the total original dataset (so 40% in total).\n",
    "# Make sure to use this parameter upon calling the appropriate sklearn function: random state=1234.\n",
    "# Train a linear SVM on the training set for each one of these C hyperparameter values: {0.001,0.01,0.1,1,10}.\n",
    "# For each value of C, what is the performance (accuracy) of the model on the training and validation sets?\n",
    "#  Given your answer, obtain the performance of the best model on the test set.\n",
    "#  We ask that you provide the few lines of code you used to divide the data, train the model, and obtain the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1234)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  0.001 , the accuracy of the train model is 41.66666666666667 % ans the accuracy of the  validation model is 30.0 %\n",
      "With a value of C:  0.01 , the accuracy of the train model is 83.33333333333334 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  0.1 , the accuracy of the train model is 86.66666666666667 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  1 , the accuracy of the train model is 90.0 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  10 , the accuracy of the train model is 90.0 % ans the accuracy of the  validation model is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "for i, c in enumerate(cs):\n",
    "    model = SVC(kernel='linear', C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    acc_train = (sum(model.predict(X_train) == y_train)/len(y_train))*100\n",
    "    acc_validation = (sum(model.predict(X_val) == y_val)/len(y_val)) * 100\n",
    "\n",
    "    print(\"With a value of C: \", c, \", the accuracy of the train model is\", acc_train,\n",
    "          \"% anf<d the accuracy of the  validation model is\", acc_validation, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  10 , the accuracy of the test model is 85.0 %\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acc_test = (sum(model.predict(X_test) == y_test)/len(y_test)) * 100\n",
    "\n",
    "print(\"With a value of C: \", c, \", the accuracy of the test model is\", acc_test, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4pt) Retrain the SVM model using 10-fold cross-validation for each of the C hyperparameter values from above.\n",
    "# For each value of C, provide the training and validation accuracies as well as the performance on the test set of the best model.\n",
    "#  Careful that you must use the same test set in both cases (previous question and this question)!\n",
    "#  We ask that you provide the few lines of codes you used to divide the data, train the model, and obtain all accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep validation and train together unlike the question above\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  0.001 , the mean accuracy of the train model is 0.3875 % and the mean accuracy of the validation model is 0.3875 %\n",
      "With a value of C:  0.01 , the mean accuracy of the train model is 0.861111111111111 % and the mean accuracy of the validation model is 0.85 %\n",
      "With a value of C:  0.1 , the mean accuracy of the train model is 0.8777777777777779 % and the mean accuracy of the validation model is 0.8625 %\n",
      "With a value of C:  1 , the mean accuracy of the train model is 0.9027777777777777 % and the mean accuracy of the validation model is 0.8625 %\n",
      "With a value of C:  10 , the mean accuracy of the train model is 0.9152777777777776 % and the mean accuracy of the validation model is 0.875 %\n"
     ]
    }
   ],
   "source": [
    "for c in cs:\n",
    "    model = SVC(kernel='linear', C=c, random_state=1234)\n",
    "    test = model.fit(X_train, y_train)\n",
    "\n",
    "    scores = cross_validate(test, X_train,  y_train,\n",
    "                            cv=10,  return_train_score=True)\n",
    "\n",
    "    #acc_train = (sum(model.predict(X_train)==y_train)/len(y_train))*100\n",
    "    #acc_validation =  (sum(model.predict(X_val)==y_val)/len(y_val)) *100\n",
    "\n",
    "    print(\"With a value of C: \", c, \", the mean accuracy of the train model is\", scores['train_score'].mean(\n",
    "    ), '% and the mean accuracy of the validation model is', scores['test_score'].mean(), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  10 , the accuracy of the test model is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=10)\n",
    "\n",
    "acc_test = (sum(test.predict(X_test) == y_test)/len(y_test)) * 100\n",
    "\n",
    "print(\"With a value of C: \", c, \", the accuracy of the test model is\", acc_test, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 - (2pt) Explain precisely how is the validation performance evaluated when doing cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5 - (2pt) Do you obtain a better model with cross validation or without it? Justify your answer and explain your result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Bought one a few years ago for my daughter and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have a stainless steel refrigerator therefor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>There are multiple shapes part like oval and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5</td>\n",
       "      <td>My 2 1/2 year old loves playing with these puz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>I only wish I bought this toy sooner!  It was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "      <td>My not quite 2 year old grandson took to this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>To say that my two year old loves these puzzle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating                                             Review\n",
       "0          5  I like the item pricing. My granddaughter want...\n",
       "1          4  Love the magnet easel... great for moving to d...\n",
       "2          5  Both sides are magnetic.  A real plus when you...\n",
       "3          5  Bought one a few years ago for my daughter and...\n",
       "4          4  I have a stainless steel refrigerator therefor...\n",
       "...      ...                                                ...\n",
       "9995       1  There are multiple shapes part like oval and t...\n",
       "9996       5  My 2 1/2 year old loves playing with these puz...\n",
       "9997       5  I only wish I bought this toy sooner!  It was ...\n",
       "9998       5  My not quite 2 year old grandson took to this ...\n",
       "9999       5  To say that my two year old loves these puzzle...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = pd.read_csv(\"C:\\\\Users\\\\love-\\\\Documents\\\\Homeworks\\\\reviews.tsv\",\n",
    "                 sep='\\t', header=None, names=['Rating', 'Review'])\n",
    "q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    0\n",
       "Review    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating Review\n",
       "2339       5    NaN\n",
       "2702       5    NaN\n",
       "4653       5    NaN\n",
       "8751       5    NaN\n",
       "8770       2    NaN\n",
       "9258       4    NaN\n",
       "9690       5    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = q3[q3['Review'].isna()]\n",
    "check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = q3.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\love-\\AppData\\Local\\Temp/ipykernel_19164/3717941936.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n",
      "C:\\Users\\love-\\AppData\\Local\\Temp/ipykernel_19164/3717941936.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9993,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3['Rating'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9993,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3['Review'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    0\n",
       "Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = q3['Rating']\n",
    "X = q3['Review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.652826\n",
       "4    0.192596\n",
       "3    0.098049\n",
       "2    0.030015\n",
       "1    0.026513\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'I like the item pricing  My granddaughter wanted to mark on it but I wanted it just for the letters '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19164/3791642413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moversample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1072\u001b[0m         )\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    871\u001b[0m         \"\"\"\n\u001b[1;32m--> 872\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'I like the item pricing  My granddaughter wanted to mark on it but I wanted it just for the letters '"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like the item pricing  My granddaughter wanted to mark on it but I wanted it just for the letters '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". (3pt) On vous demande ensuite d’obtenir une repr´esentation sac à mots (bag-of-words) des caract´eristiques (features). sklearn offre des fonctions pour y arriver. Pour limiter le temps d’entraˆınement requis, on vous demande d’utiliser un maximumde2000motsdansvotre vocabulaire (max features=2000) et d’utiliser la liste des mots vides de sklearn (stop words=\"english\"). Cette liste permet de retirer des mots qui à priori ne seront pas utiles a la pr´ediction. Utilisez les autres param`etres par d´efaut de la fonction. Nous vous demandons les quelques lignes de code de sklearn que vous avez utilis´ees pour encoder (et seulement encoder) les donn´ees d’entraˆınement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1234)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4946    This is a must have for any infant toy collect...\n",
       "8509    My   year old received this game for Christmas...\n",
       "6790    I bought this toy for my   boys    and    and ...\n",
       "7615    Cute accessory for Calico Critters playhouse  ...\n",
       "5438    After she killed a few sets of batteries   I p...\n",
       "                              ...                        \n",
       "2309    I have always wanted a chopper but found them ...\n",
       "8211    Bought this set for my two year old twins that...\n",
       "1232    Ok  if you have seen my other reviews then you...\n",
       "3641    My cousins would always bring this game over f...\n",
       "5500    She is really showing an interest in the state...\n",
       "Name: Review, Length: 5995, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4946    4\n",
       "8509    4\n",
       "6790    2\n",
       "7615    4\n",
       "5438    5\n",
       "       ..\n",
       "2309    4\n",
       "8211    4\n",
       "1232    4\n",
       "3641    5\n",
       "5500    5\n",
       "Name: Rating, Length: 5995, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  # Import the stop word list\n",
    "print(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                             stop_words=\"english\",\n",
    "                             max_features=2000)\n",
    "\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "valid_data_features = vectorizer.fit_transform(X_val)\n",
    "test_data_features = vectorizer.fit_transform(X_test)\n",
    "\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "valid_data_features = valid_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample the dataset because we have too much y = 5\n",
    "oversample = SMOTE()\n",
    "train_data_features, y_train = oversample.fit_resample(train_data_features, y_train)\n",
    "valid_data_features, y_val = oversample.fit_resample(valid_data_features, y_val)\n",
    "test_data_features, y_test = oversample.fit_resample(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1305\n",
       "3    1305\n",
       "4    1305\n",
       "1    1305\n",
       "2    1305\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19360, 2000)\n",
      "(19360,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)\n",
    "print(y_train.shape)\n",
    "# This has 9993 rows and 2000 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'abc', 'abilities', 'ability', 'able', 'absolutely', 'abuse', 'access', 'accessories', 'accidentally', 'accurate', 'act', 'action', 'actions', 'activities', 'activity', 'actual', 'actually', 'adapter', 'add', 'added', 'addictive', 'adding', 'addition', 'additional', 'adds', 'adjust', 'admit', 'adorable', 'adult', 'adults', 'advance', 'advanced', 'advantage', 'adventure', 'adventures', 'affair', 'affect', 'afraid', 'age', 'aged', 'ages', 'ago', 'agree', 'ahead', 'air', 'alike', 'allow', 'allowing', 'allows', 'alot', 'alphabet', 'alternative', 'amazing', 'amazingly', 'amazon', 'american', 'ancient', 'angle', 'animal', 'animals', 'annoying', 'answer', 'answers', 'apart', 'apparently', 'appeal', 'appealing', 'appear', 'appears', 'apples', 'appreciate', 'appropriate', 'area', 'aren', 'arkham', 'arm', 'armies', 'arms', 'arrived', 'art', 'arts', 'artwork', 'aside', 'ask', 'asked', 'asking', 'asks', 'aspect', 'assemble', 'assembled', 'assembly', 'assistance', 'attach', 'attached', 'attack', 'attempt', 'attempting', 'attention', 'available', 'average', 'avoid', 'aware', 'away', 'awesome', 'awhile', 'babies', 'baby', 'backwards', 'bad', 'bag', 'balance', 'balanced', 'ball', 'balls', 'bananagrams', 'bang', 'bank', 'barely', 'barrel', 'base', 'based', 'basic', 'basically', 'basics', 'basket', 'batteries', 'battery', 'battle', 'beads', 'beans', 'bear', 'beat', 'beating', 'beautiful', 'bed', 'beds', 'begin', 'beginner', 'beginning', 'behavior', 'believe', 'bench', 'bend', 'benefit', 'bent', 'best', 'better', 'beware', 'big', 'bigger', 'biggest', 'bin', 'bird', 'birthday', 'bit', 'bite', 'black', 'blank', 'blast', 'block', 'blocks', 'blow', 'blue', 'board', 'boards', 'body', 'boggle', 'bonus', 'book', 'books', 'bored', 'boring', 'born', 'bother', 'bought', 'bounce', 'bouncing', 'box', 'boxes', 'boy', 'boys', 'brain', 'brand', 'bread', 'break', 'breaking', 'bright', 'brightly', 'bring', 'brings', 'broke', 'broken', 'brother', 'brought', 'bruder', 'bucks', 'build', 'building', 'buildings', 'built', 'bumble', 'bunch', 'bunnies', 'bunny', 'bus', 'busy', 'butterflies', 'butterfly', 'button', 'buttons', 'buy', 'buying', 'called', 'came', 'camelot', 'campaign', 'camping', 'candy', 'candyland', 'cans', 'car', 'card', 'cardboard', 'cards', 'care', 'careful', 'carpet', 'carrot', 'carry', 'carrying', 'cars', 'cart', 'case', 'cash', 'castle', 'cat', 'catan', 'catch', 'categories', 'caterpillars', 'caught', 'cause', 'center', 'certain', 'certainly', 'chain', 'challenge', 'challenges', 'challenging', 'chance', 'chances', 'change', 'changed', 'changes', 'changing', 'channel', 'character', 'characters', 'charge', 'charging', 'cheap', 'cheaper', 'cheaply', 'check', 'chess', 'chest', 'chew', 'child', 'childhood', 'children', 'chips', 'choice', 'choices', 'choking', 'choose', 'chooses', 'chose', 'chosen', 'christmas', 'circle', 'class', 'classic', 'classroom', 'clean', 'clear', 'clearly', 'click', 'climb', 'climber', 'climbing', 'clip', 'clock', 'close', 'closet', 'cloth', 'clothes', 'clue', 'clues', 'coins', 'collect', 'collection', 'college', 'color', 'colored', 'colorful', 'coloring', 'colors', 'combat', 'come', 'comes', 'comfortable', 'comfortably', 'coming', 'commodity', 'company', 'compare', 'compared', 'compete', 'competition', 'competitive', 'complain', 'complaint', 'complete', 'completed', 'completely', 'completing', 'complex', 'complicated', 'components', 'computer', 'concept', 'concern', 'concerned', 'condition', 'confusing', 'connect', 'cons', 'consider', 'considered', 'considering', 'consists', 'constant', 'constantly', 'constructed', 'construction', 'container', 'containers', 'contains', 'continue', 'continues', 'control', 'controller', 'controls', 'conversation', 'cool', 'cooperative', 'coordination', 'cooties', 'copy', 'core', 'corners', 'correct', 'correctly', 'cost', 'costs', 'couldn', 'count', 'counters', 'counting', 'counts', 'couple', 'course', 'cousin', 'cover', 'craft', 'cranky', 'crawl', 'crayola', 'crayons', 'crazy', 'create', 'created', 'creating', 'creative', 'creativity', 'credit', 'creeper', 'creepers', 'crew', 'crib', 'crowd', 'cthulhu', 'cube', 'cup', 'current', 'currently', 'cut', 'cute', 'dad', 'daddy', 'daily', 'damage', 'dance', 'dangerous', 'dark', 'date', 'daughter', 'daughters', 'day', 'days', 'dd', 'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decisions', 'deck', 'decks', 'deep', 'definitely', 'degree', 'depending', 'depends', 'depth', 'descent', 'described', 'description', 'design', 'designed', 'designs', 'despite', 'detailed', 'details', 'determine', 'dial', 'dice', 'did', 'didn', 'didnt', 'die', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'direction', 'directions', 'disappointed', 'disappointing', 'disappointment', 'discard', 'discovered', 'display', 'districts', 'doctor', 'does', 'doesn', 'doesnt', 'dog', 'doh', 'doing', 'doll', 'dollar', 'dollars', 'dolls', 'dominion', 'don', 'dont', 'doom', 'door', 'doors', 'dot', 'dots', 'double', 'doubt', 'doug', 'downside', 'drag', 'drain', 'draw', 'drawback', 'drawer', 'drawing', 'drawn', 'draws', 'drive', 'driving', 'drop', 'dropping', 'drum', 'dry', 'dumb', 'dungeon', 'dunwich', 'duplo', 'durability', 'durable', 'dvd', 'ear', 'earlier', 'early', 'ears', 'ease', 'easel', 'easier', 'easily', 'easy', 'eat', 'ebay', 'edge', 'edges', 'edition', 'education', 'educational', 'effect', 'effects', 'effort', 'eggs', 'elder', 'electric', 'electronic', 'element', 'elements', 'elf', 'empire', 'encounter', 'encourage', 'encourages', 'end', 'ended', 'endless', 'ends', 'energy', 'engine', 'engines', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enjoying', 'enjoyment', 'enjoys', 'entertain', 'entertained', 'entertaining', 'entertainment', 'entire', 'entirely', 'erase', 'especially', 'essentially', 'etch', 'euro', 'eve', 'evening', 'events', 'eventually', 'everyday', 'everytime', 'evil', 'exact', 'exactly', 'example', 'excellent', 'exception', 'excited', 'excitement', 'exciting', 'exercise', 'expansion', 'expansions', 'expect', 'expected', 'expecting', 'expensive', 'experience', 'experiment', 'explain', 'explained', 'explore', 'extra', 'extremely', 'eye', 'eyes', 'face', 'faces', 'fact', 'factor', 'fail', 'fair', 'fairly', 'falcon', 'fall', 'falling', 'falls', 'familiar', 'families', 'family', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fashion', 'fashioned', 'fast', 'faster', 'father', 'fault', 'favor', 'favorite', 'favorites', 'feature', 'features', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'ffg', 'field', 'fight', 'fighter', 'fighters', 'fighting', 'figure', 'figured', 'figuring', 'filled', 'filling', 'fills', 'final', 'finally', 'finding', 'fine', 'fingers', 'finish', 'finished', 'fish', 'fisher', 'fishing', 'fit', 'fits', 'flat', 'flexible', 'flies', 'flight', 'flimsy', 'flip', 'floor', 'floors', 'fluxx', 'fly', 'flying', 'foam', 'focus', 'fold', 'folks', 'follow', 'following', 'food', 'foot', 'force', 'forever', 'forget', 'form', 'forth', 'fortunately', 'forward', 'fourth', 'frame', 'free', 'frequently', 'fresh', 'friend', 'friendly', 'friends', 'frog', 'frogs', 'fruit', 'frustrated', 'frustrating', 'frustration', 'fully', 'fun', 'funny', 'furniture', 'future', 'gain', 'game', 'gameplay', 'gamer', 'gamers', 'games', 'gaming', 'garage', 'garbage', 'garden', 'gate', 'gather', 'gathering', 'gave', 'gear', 'gears', 'general', 'generally', 'generic', 'gets', 'getting', 'gift', 'gifts', 'girl', 'girls', 'given', 'gives', 'giving', 'glad', 'glass', 'glue', 'goal', 'goals', 'goes', 'going', 'gold', 'gone', 'good', 'goods', 'got', 'gotten', 'grab', 'grade', 'grail', 'grand', 'grandchildren', 'granddaughter', 'grandkids', 'grandma', 'grandparents', 'grandson', 'grandsons', 'graphics', 'gras', 'grasp', 'grass', 'great', 'greatly', 'green', 'grew', 'grid', 'grocery', 'ground', 'group', 'groups', 'grow', 'growing', 'grown', 'grows', 'guess', 'guests', 'gun', 'guy', 'guys', 'half', 'hammer', 'hand', 'handle', 'handling', 'hands', 'handy', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'harder', 'hardly', 'hardwood', 'harold', 'hasn', 'hate', 'haven', 'having', 'hazard', 'head', 'heads', 'hear', 'heard', 'hearing', 'heart', 'heavy', 'height', 'held', 'heli', 'helicopter', 'helicopters', 'help', 'helped', 'helpful', 'helping', 'helps', 'heroes', 'hey', 'hide', 'high', 'higher', 'highest', 'highly', 'hilarious', 'hill', 'hippo', 'hippos', 'history', 'hit', 'hitting', 'hold', 'holder', 'holders', 'holding', 'holds', 'hole', 'holes', 'holidays', 'home', 'honestly', 'hook', 'hooked', 'hope', 'hopefully', 'hoping', 'horror', 'horse', 'hot', 'hotels', 'hour', 'hours', 'house', 'houses', 'hubby', 'huge', 'hull', 'hungry', 'hurt', 'husband', 'ice', 'idea', 'ideas', 'illustrations', 'im', 'image', 'images', 'imagination', 'imagine', 'immediately', 'imperial', 'important', 'impossible', 'impressed', 'impressive', 'improve', 'improved', 'inch', 'inches', 'include', 'included', 'includes', 'including', 'increase', 'incredibly', 'individual', 'indoor', 'indoors', 'inexpensive', 'initial', 'initially', 'ink', 'insert', 'inside', 'instead', 'instruction', 'instructions', 'intended', 'interaction', 'interested', 'interesting', 'intrigue', 'introduce', 'introduced', 'investigator', 'investigators', 'investment', 'involved', 'involves', 'isn', 'issue', 'issues', 'item', 'items', 'jack', 'job', 'join', 'joy', 'jr', 'judge', 'juice', 'jump', 'jumping', 'junk', 'just', 'keeper', 'keeping', 'keeps', 'kept', 'key', 'keys', 'kick', 'kid', 'kids', 'kill', 'killing', 'kind', 'kinds', 'king', 'kingsburg', 'kit', 'kitchen', 'knew', 'knight', 'knights', 'knobs', 'knock', 'know', 'knowing', 'knows', 'lack', 'ladders', 'laminate', 'land', 'landing', 'lands', 'large', 'larger', 'lasted', 'lasting', 'later', 'laugh', 'laughing', 'laughs', 'launcher', 'law', 'lawn', 'lay', 'layout', 'lead', 'leads', 'leap', 'leapfrog', 'learn', 'learned', 'learning', 'leave', 'leaves', 'leaving', 'left', 'lego', 'legos', 'legs', 'length', 'lessons', 'let', 'lets', 'letter', 'letters', 'letting', 'level', 'levels', 'lever', 'lid', 'life', 'lift', 'light', 'lights', 'lightweight', 'like', 'liked', 'likely', 'likes', 'limit', 'limited', 'limiting', 'line', 'lines', 'list', 'listen', 'literally', 'little', 'live', 'living', 'll', 'llama', 'loads', 'local', 'location', 'lock', 'logic', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'loom', 'loops', 'loose', 'lose', 'losing', 'loss', 'lost', 'lot', 'lots', 'loud', 'love', 'lovecraft', 'loved', 'loves', 'loving', 'low', 'lower', 'lowercase', 'lowest', 'luck', 'luckily', 'lucky', 'magic', 'magnetic', 'magnets', 'mail', 'main', 'mainly', 'major', 'make', 'makes', 'making', 'man', 'manage', 'managed', 'mancala', 'maneuver', 'manipulate', 'manufacturer', 'map', 'marble', 'marbles', 'mark', 'marker', 'markers', 'market', 'marks', 'master', 'mat', 'match', 'matching', 'material', 'materials', 'math', 'matter', 'maximum', 'maybe', 'mean', 'meaning', 'means', 'meant', 'mechanic', 'mechanics', 'meet', 'melissa', 'members', 'memories', 'memory', 'mention', 'mentioned', 'mess', 'metal', 'middle', 'milk', 'mind', 'mini', 'miniature', 'miniatures', 'minimal', 'minimum', 'minis', 'minor', 'minute', 'minutes', 'mirror', 'misfit', 'miss', 'missiles', 'missing', 'mission', 'missions', 'mix', 'mixed', 'mo', 'mobile', 'mode', 'model', 'models', 'module', 'mom', 'moment', 'mommy', 'money', 'monkey', 'monkeys', 'monopoly', 'monster', 'monsters', 'month', 'months', 'monty', 'morning', 'mother', 'motor', 'mouth', 'moved', 'movement', 'moves', 'movie', 'movies', 'moving', 'mr', 'multiple', 'munchkin', 'music', 'musical', 'mythos', 'names', 'nature', 'nd', 'near', 'nearly', 'neat', 'necessary', 'neck', 'need', 'needed', 'needs', 'negative', 'nephew', 'new', 'newer', 'nice', 'nicely', 'niece', 'night', 'nights', 'noise', 'noises', 'noisy', 'non', 'normal', 'north', 'note', 'noted', 'notice', 'noticed', 'number', 'numbers', 'numerous', 'object', 'objects', 'obsessed', 'obvious', 'obviously', 'occasion', 'occasionally', 'occupied', 'offer', 'offered', 'offers', 'office', 'oh', 'ok', 'okay', 'old', 'older', 'oldest', 'olds', 'ones', 'online', 'open', 'opened', 'opening', 'operate', 'opinion', 'opponent', 'opponents', 'opportunity', 'option', 'options', 'orange', 'order', 'ordered', 'organs', 'original', 'originally', 'othello', 'ounce', 'outdoor', 'outside', 'overall', 'overly', 'pack', 'package', 'packaging', 'packed', 'pad', 'page', 'pages', 'paid', 'pain', 'paint', 'painted', 'painting', 'paints', 'pairs', 'paper', 'parent', 'parents', 'park', 'particular', 'particularly', 'parties', 'parts', 'party', 'pass', 'passed', 'past', 'patience', 'pattern', 'patterns', 'pawns', 'pay', 'paying', 'peg', 'pegs', 'pen', 'pencils', 'penny', 'people', 'perfect', 'perfectly', 'perform', 'person', 'personal', 'personally', 'pete', 'phase', 'phone', 'photo', 'piano', 'pick', 'picked', 'picking', 'picks', 'picture', 'pictures', 'piece', 'pieces', 'pile', 'pilot', 'pilots', 'pirate', 'pit', 'place', 'placed', 'placement', 'places', 'placing', 'plan', 'planet', 'planets', 'planning', 'plastic', 'plate', 'plates', 'play', 'playdoh', 'played', 'player', 'players', 'playing', 'plays', 'pleased', 'plenty', 'plug', 'plus', 'point', 'points', 'pole', 'pooh', 'pool', 'poor', 'pop', 'popper', 'pops', 'popular', 'portable', 'position', 'positive', 'possibilities', 'possible', 'possibly', 'post', 'pot', 'potential', 'potentially', 'potholders', 'pound', 'pounding', 'power', 'powerful', 'practice', 'pre', 'prefer', 'prefers', 'premise', 'prepared', 'preschool', 'preschooler', 'present', 'press', 'pressing', 'pretend', 'pretty', 'prevent', 'previous', 'previously', 'price', 'priced', 'prices', 'pricey', 'printed', 'probably', 'problem', 'problems', 'process', 'product', 'products', 'program', 'progress', 'projects', 'properly', 'properties', 'property', 'pros', 'provide', 'provided', 'provides', 'puck', 'pull', 'pulled', 'pulling', 'pulls', 'pump', 'purchase', 'purchased', 'purchasing', 'pure', 'purple', 'purpose', 'push', 'pushed', 'pushing', 'puts', 'putting', 'puzzle', 'puzzles', 'pvc', 'python', 'quality', 'quest', 'question', 'questions', 'quests', 'quick', 'quickly', 'quiet', 'quite', 'quot', 'race', 'racing', 'rainy', 'random', 'range', 'rarely', 'rate', 'rated', 'rating', 'ravensburger', 'rc', 'rd', 'reach', 'read', 'reading', 'reads', 'ready', 'real', 'realistic', 'reality', 'realize', 'realized', 'really', 'realm', 'reason', 'reasonable', 'reasons', 'rebel', 'receive', 'received', 'recently', 'recommend', 'recommended', 'red', 'register', 'regular', 'regularly', 'relatively', 'release', 'released', 'remember', 'remembered', 'remote', 'remove', 'rent', 'replace', 'replaced', 'replacement', 'replay', 'replayability', 'report', 'require', 'required', 'requires', 'research', 'resources', 'response', 'rest', 'result', 'results', 'return', 'returned', 'reveal', 'review', 'reviewer', 'reviewers', 'reviews', 'rewards', 'ride', 'rides', 'riding', 'right', 'ring', 'rings', 'risk', 'road', 'rocket', 'rockets', 'rocks', 'rody', 'role', 'roles', 'roll', 'rolled', 'rolling', 'rolls', 'roof', 'room', 'rooms', 'rope', 'rough', 'round', 'rounds', 'routes', 'rover', 'row', 'rudolph', 'ruin', 'rule', 'rules', 'run', 'running', 'runs', 'rush', 'safe', 'safety', 'said', 'sale', 'sand', 'sandbox', 'santa', 'sat', 'save', 'saw', 'say', 'saying', 'says', 'scenarios', 'scene', 'school', 'score', 'scoring', 'scrabble', 'screen', 'screw', 'search', 'seat', 'second', 'secondary', 'seconds', 'seeing', 'seen', 'select', 'selection', 'sell', 'send', 'sense', 'sent', 'series', 'seriously', 'session', 'set', 'sets', 'setting', 'settings', 'setup', 'seven', 'shake', 'shallow', 'shape', 'shaped', 'shapes', 'share', 'sharp', 'sheet', 'sheets', 'shelf', 'ship', 'shipping', 'ships', 'shoot', 'shop', 'shopping', 'short', 'shot', 'shouldn', 'showed', 'shown', 'shows', 'shut', 'sided', 'sides', 'sign', 'signs', 'silly', 'similar', 'simple', 'simply', 'sing', 'singing', 'single', 'sister', 'sit', 'site', 'sits', 'sitting', 'situation', 'size', 'sized', 'sketch', 'skill', 'skills', 'skip', 'sleep', 'slide', 'slightly', 'slinky', 'slots', 'slow', 'slowly', 'small', 'smaller', 'smart', 'smell', 'smile', 'smock', 'smooth', 'snap', 'snow', 'soft', 'sold', 'solid', 'solitaire', 'solo', 'solution', 'solve', 'solving', 'somewhat', 'son', 'song', 'songs', 'sons', 'soon', 'sorry', 'sort', 'sorting', 'sorts', 'sound', 'sounds', 'space', 'spaces', 'special', 'specific', 'speed', 'spell', 'spelling', 'spells', 'spend', 'spending', 'spent', 'spin', 'spinner', 'spinning', 'spins', 'spot', 'spots', 'square', 'st', 'stable', 'stack', 'stacked', 'stacking', 'stairs', 'stand', 'standard', 'standards', 'standing', 'stands', 'star', 'stars', 'start', 'started', 'starter', 'starting', 'starts', 'state', 'states', 'stay', 'stays', 'steal', 'step', 'stethoscope', 'stick', 'sticker', 'stickers', 'sticking', 'sticks', 'stocking', 'stood', 'stop', 'stops', 'storage', 'store', 'stores', 'stories', 'story', 'straight', 'strategic', 'strategies', 'strategy', 'strength', 'string', 'strong', 'stronger', 'structure', 'structures', 'stuck', 'students', 'stuff', 'stuffed', 'sturdier', 'sturdy', 'style', 'subject', 'subtle', 'successful', 'sugar', 'suggest', 'suggested', 'summer', 'sun', 'super', 'support', 'supports', 'suppose', 'supposed', 'sure', 'surface', 'surprise', 'surprised', 'survey', 'survived', 'sweet', 'swing', 'switch', 'symbols', 'table', 'tabletop', 'tactical', 'tad', 'tail', 'taken', 'takes', 'taking', 'talk', 'talking', 'tall', 'tape', 'target', 'task', 'tasks', 'tea', 'teach', 'teacher', 'teaches', 'teaching', 'team', 'teams', 'tech', 'technology', 'tell', 'telling', 'tells', 'tend', 'tends', 'tent', 'terms', 'test', 'testing', 'th', 'thanks', 'thanksgiving', 'theme', 'themed', 'thicker', 'thing', 'things', 'think', 'thinkfun', 'thinking', 'thinks', 'thomas', 'thought', 'thrilled', 'throw', 'thrown', 'ticket', 'tie', 'tight', 'tikes', 'tile', 'tiles', 'till', 'time', 'timeline', 'timer', 'times', 'tin', 'tiny', 'tip', 'tips', 'tire', 'tired', 'title', 'today', 'toddler', 'toddlers', 'token', 'tokens', 'told', 'ton', 'tonka', 'tons', 'took', 'tool', 'tools', 'toss', 'total', 'totally', 'touch', 'tough', 'toy', 'toys', 'track', 'tracks', 'trade', 'tradition', 'traditional', 'train', 'trains', 'traitor', 'travel', 'tray', 'treasure', 'treat', 'tree', 'trees', 'tricky', 'tried', 'tries', 'trim', 'trip', 'trips', 'trouble', 'truck', 'true', 'truly', 'try', 'trying', 'tub', 'tube', 'tune', 'tunes', 'tunnel', 'tunnels', 'turn', 'turned', 'turning', 'turns', 'tv', 'twice', 'twins', 'twist', 'twister', 'twists', 'type', 'types', 'typical', 'typically', 'underneath', 'understand', 'understanding', 'unfortunately', 'unique', 'unit', 'unless', 'unlike', 'uno', 'update', 'updated', 'upgrade', 'upgrades', 'upper', 'upset', 'upside', 'usb', 'use', 'used', 'useful', 'useless', 'uses', 'using', 'usual', 'usually', 'vacuum', 'value', 'variation', 'variations', 'variety', 'various', 've', 'velcro', 'version', 'versions', 'vertical', 'vibrant', 'victory', 'video', 'village', 'vinyl', 'visit', 'visual', 'visually', 'vocabulary', 'voice', 'volume', 'vs', 'wagon', 'wait', 'waiting', 'walk', 'walker', 'walking', 'wall', 'walls', 'want', 'wanted', 'wanting', 'wants', 'wars', 'wash', 'washable', 'wasn', 'waste', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weapon', 'weapons', 'wear', 'weather', 'website', 'week', 'weeks', 'weight', 'weird', 'went', 'weren', 'wheel', 'wheels', 'white', 'wide', 'wife', 'wild', 'willing', 'win', 'wind', 'wing', 'wings', 'winner', 'winning', 'wins', 'winter', 'wire', 'wish', 'withstand', 'won', 'wonder', 'wonderful', 'wood', 'wooden', 'word', 'words', 'work', 'worked', 'worker', 'working', 'workout', 'works', 'world', 'worried', 'worry', 'worse', 'worth', 'worthwhile', 'wouldn', 'write', 'writing', 'written', 'wrong', 'wrote', 'xmas', 'yahtzee', 'yard', 'yeah', 'year', 'years', 'yellow', 'yes', 'yo', 'young', 'younger', 'youngest', 'youth', 'youtube', 'yr', 'yrs', 'zero', 'zombie', 'zombies']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 aa\n",
      "29 abc\n",
      "74 abilities\n",
      "165 ability\n",
      "411 able\n",
      "20 absolutely\n",
      "156 abuse\n",
      "29 access\n",
      "45 accessories\n",
      "115 accidentally\n",
      "73 accurate\n",
      "34 act\n",
      "44 action\n",
      "66 actions\n",
      "82 activities\n",
      "399 activity\n",
      "234 actual\n",
      "100 actually\n",
      "49 adapter\n",
      "200 add\n",
      "98 added\n",
      "101 addictive\n",
      "41 adding\n",
      "48 addition\n",
      "178 additional\n",
      "307 adds\n",
      "81 adjust\n",
      "32 admit\n",
      "47 adorable\n",
      "33 adult\n",
      "25 adults\n",
      "407 advance\n",
      "269 advanced\n",
      "205 advantage\n",
      "48 adventure\n",
      "52 adventures\n",
      "174 affair\n",
      "44 affect\n",
      "22 afraid\n",
      "98 age\n",
      "29 aged\n",
      "23 ages\n",
      "108 ago\n",
      "41 agree\n",
      "103 ahead\n",
      "36 air\n",
      "30 alike\n",
      "29 allow\n",
      "86 allowing\n",
      "409 allows\n",
      "32 alot\n",
      "48 alphabet\n",
      "111 alternative\n",
      "125 amazing\n",
      "163 amazingly\n",
      "100 amazon\n",
      "35 american\n",
      "193 ancient\n",
      "34 angle\n",
      "46 animal\n",
      "31 animals\n",
      "58 annoying\n",
      "76 answer\n",
      "115 answers\n",
      "74 apart\n",
      "80 apparently\n",
      "125 appeal\n",
      "57 appealing\n",
      "32 appear\n",
      "97 appears\n",
      "78 apples\n",
      "42 appreciate\n",
      "22 appropriate\n",
      "77 area\n",
      "22 aren\n",
      "49 arkham\n",
      "31 arm\n",
      "45 armies\n",
      "27 arms\n",
      "51 arrived\n",
      "160 art\n",
      "45 arts\n",
      "29 artwork\n",
      "167 aside\n",
      "29 ask\n",
      "111 asked\n",
      "49 asking\n",
      "67 asks\n",
      "29 aspect\n",
      "353 assemble\n",
      "115 assembled\n",
      "33 assembly\n",
      "70 assistance\n",
      "415 attach\n",
      "23 attached\n",
      "287 attack\n",
      "107 attempt\n",
      "25 attempting\n",
      "78 attention\n",
      "25 available\n",
      "360 average\n",
      "250 avoid\n",
      "23 aware\n",
      "47 away\n",
      "27 awesome\n",
      "42 awhile\n",
      "321 babies\n",
      "171 baby\n",
      "226 backwards\n",
      "111 bad\n",
      "30 bag\n",
      "34 balance\n",
      "74 balanced\n",
      "271 ball\n",
      "196 balls\n",
      "81 bananagrams\n",
      "29 bang\n",
      "99 bank\n",
      "39 barely\n",
      "82 barrel\n",
      "95 base\n",
      "34 based\n",
      "52 basic\n",
      "33 basically\n",
      "42 basics\n",
      "86 basket\n",
      "94 batteries\n",
      "20 battery\n",
      "26 battle\n",
      "23 beads\n",
      "30 beans\n",
      "452 bear\n",
      "764 beat\n",
      "26 beating\n",
      "516 beautiful\n",
      "130 bed\n",
      "61 beds\n",
      "28 begin\n",
      "297 beginner\n",
      "595 beginning\n",
      "83 behavior\n",
      "32 believe\n",
      "100 bench\n",
      "61 bend\n",
      "291 benefit\n",
      "47 bent\n",
      "162 best\n",
      "1648 better\n",
      "39 beware\n",
      "115 big\n",
      "70 bigger\n",
      "504 biggest\n",
      "218 bin\n",
      "101 bird\n",
      "111 birthday\n",
      "19 bit\n",
      "24 bite\n",
      "1247 black\n",
      "56 blank\n",
      "860 blast\n",
      "55 block\n",
      "154 blocks\n",
      "221 blow\n",
      "38 blue\n",
      "66 board\n",
      "23 boards\n",
      "160 body\n",
      "39 boggle\n",
      "24 bonus\n",
      "124 book\n",
      "83 books\n",
      "36 bored\n",
      "113 boring\n",
      "86 born\n",
      "82 bother\n",
      "62 bought\n",
      "23 bounce\n",
      "51 bouncing\n",
      "37 box\n",
      "42 boxes\n",
      "39 boy\n",
      "44 boys\n",
      "257 brain\n",
      "270 brand\n",
      "103 bread\n",
      "20 break\n",
      "86 breaking\n",
      "73 bright\n",
      "52 brightly\n",
      "117 bring\n",
      "45 brings\n",
      "57 broke\n",
      "106 broken\n",
      "59 brother\n",
      "124 brought\n",
      "118 bruder\n",
      "928 bucks\n",
      "199 build\n",
      "70 building\n",
      "298 buildings\n",
      "41 built\n",
      "61 bumble\n",
      "30 bunch\n",
      "379 bunnies\n",
      "1473 bunny\n",
      "150 bus\n",
      "2681 busy\n",
      "107 butterflies\n",
      "74 butterfly\n",
      "23 button\n",
      "55 buttons\n",
      "79 buy\n",
      "69 buying\n",
      "34 called\n",
      "236 came\n",
      "80 camelot\n",
      "285 campaign\n",
      "43 camping\n",
      "61 candy\n",
      "41 candyland\n",
      "33 cans\n",
      "55 car\n",
      "70 card\n",
      "27 cardboard\n",
      "117 cards\n",
      "41 care\n",
      "80 careful\n",
      "20 carpet\n",
      "49 carrot\n",
      "148 carry\n",
      "84 carrying\n",
      "24 cars\n",
      "103 cart\n",
      "45 case\n",
      "165 cash\n",
      "190 castle\n",
      "168 cat\n",
      "47 catan\n",
      "84 catch\n",
      "61 categories\n",
      "23 caterpillars\n",
      "211 caught\n",
      "222 cause\n",
      "57 center\n",
      "50 certain\n",
      "317 certainly\n",
      "60 chain\n",
      "60 challenge\n",
      "90 challenges\n",
      "94 challenging\n",
      "31 chance\n",
      "25 chances\n",
      "46 change\n",
      "1028 changed\n",
      "44 changes\n",
      "879 changing\n",
      "58 channel\n",
      "94 character\n",
      "50 characters\n",
      "41 charge\n",
      "127 charging\n",
      "22 cheap\n",
      "28 cheaper\n",
      "29 cheaply\n",
      "630 check\n",
      "23 chess\n",
      "71 chest\n",
      "123 chew\n",
      "131 child\n",
      "51 childhood\n",
      "25 children\n",
      "254 chips\n",
      "24 choice\n",
      "126 choices\n",
      "115 choking\n",
      "40 choose\n",
      "47 chooses\n",
      "40 chose\n",
      "37 chosen\n",
      "53 christmas\n",
      "148 circle\n",
      "62 class\n",
      "20 classic\n",
      "31 classroom\n",
      "43 clean\n",
      "28 clear\n",
      "81 clearly\n",
      "78 click\n",
      "22 climb\n",
      "78 climber\n",
      "26 climbing\n",
      "67 clip\n",
      "31 clock\n",
      "103 close\n",
      "403 closet\n",
      "146 cloth\n",
      "134 clothes\n",
      "35 clue\n",
      "730 clues\n",
      "20 coins\n",
      "56 collect\n",
      "49 collection\n",
      "23 college\n",
      "23 color\n",
      "499 colored\n",
      "413 colorful\n",
      "28 coloring\n",
      "82 colors\n",
      "35 combat\n",
      "25 come\n",
      "138 comes\n",
      "53 comfortable\n",
      "29 comfortably\n",
      "38 coming\n",
      "29 commodity\n",
      "66 company\n",
      "23 compare\n",
      "108 compared\n",
      "31 compete\n",
      "150 competition\n",
      "29 competitive\n",
      "105 complain\n",
      "40 complaint\n",
      "86 complete\n",
      "21 completed\n",
      "123 completely\n",
      "101 completing\n",
      "64 complex\n",
      "139 complicated\n",
      "28 components\n",
      "25 computer\n",
      "43 concept\n",
      "30 concern\n",
      "23 concerned\n",
      "32 condition\n",
      "50 confusing\n",
      "23 connect\n",
      "37 cons\n",
      "66 consider\n",
      "66 considered\n",
      "26 considering\n",
      "93 consists\n",
      "39 constant\n",
      "49 constantly\n",
      "35 constructed\n",
      "25 construction\n",
      "47 container\n",
      "25 containers\n",
      "51 contains\n",
      "26 continue\n",
      "147 continues\n",
      "33 control\n",
      "24 controller\n",
      "164 controls\n",
      "65 conversation\n",
      "53 cool\n",
      "42 cooperative\n",
      "71 coordination\n",
      "151 cooties\n",
      "33 copy\n",
      "42 core\n",
      "25 corners\n",
      "58 correct\n",
      "62 correctly\n",
      "54 cost\n",
      "81 costs\n",
      "42 couldn\n",
      "185 count\n",
      "133 counters\n",
      "113 counting\n",
      "272 counts\n",
      "159 couple\n",
      "22 course\n",
      "20 cousin\n",
      "84 cover\n",
      "37 craft\n",
      "19 cranky\n",
      "22 crawl\n",
      "22 crayola\n",
      "46 crayons\n",
      "22 crazy\n",
      "24 create\n",
      "20 created\n",
      "96 creating\n",
      "170 creative\n",
      "73 creativity\n",
      "65 credit\n",
      "29 creeper\n",
      "37 creepers\n",
      "29 crew\n",
      "80 crib\n",
      "39 crowd\n",
      "41 cthulhu\n",
      "52 cube\n",
      "34 cup\n",
      "32 current\n",
      "40 currently\n",
      "35 cut\n",
      "135 cute\n",
      "43 dad\n",
      "26 daddy\n",
      "43 daily\n",
      "33 damage\n",
      "32 dance\n",
      "106 dangerous\n",
      "79 dark\n",
      "374 date\n",
      "49 daughter\n",
      "28 daughters\n",
      "41 day\n",
      "66 days\n",
      "76 dd\n",
      "1395 dead\n",
      "64 deal\n",
      "418 death\n",
      "236 decent\n",
      "36 decide\n",
      "120 decided\n",
      "29 decisions\n",
      "21 deck\n",
      "48 decks\n",
      "37 deep\n",
      "134 definitely\n",
      "34 degree\n",
      "54 depending\n",
      "289 depends\n",
      "100 depth\n",
      "68 descent\n",
      "31 described\n",
      "21 description\n",
      "333 design\n",
      "43 designed\n",
      "80 designs\n",
      "92 despite\n",
      "20 detailed\n",
      "45 details\n",
      "23 determine\n",
      "83 dial\n",
      "112 dice\n",
      "97 did\n",
      "26 didn\n",
      "30 didnt\n",
      "55 die\n",
      "49 difference\n",
      "45 different\n",
      "30 differently\n",
      "23 difficult\n",
      "38 difficulty\n",
      "26 direction\n",
      "20 directions\n",
      "36 disappointed\n",
      "570 disappointing\n",
      "658 disappointment\n",
      "696 discard\n",
      "207 discovered\n",
      "35 display\n",
      "813 districts\n",
      "410 doctor\n",
      "62 does\n",
      "27 doesn\n",
      "58 doesnt\n",
      "93 dog\n",
      "22 doh\n",
      "194 doing\n",
      "28 doll\n",
      "41 dollar\n",
      "28 dollars\n",
      "36 dolls\n",
      "99 dominion\n",
      "56 don\n",
      "851 dont\n",
      "835 doom\n",
      "22 door\n",
      "83 doors\n",
      "42 dot\n",
      "153 dots\n",
      "240 double\n",
      "31 doubt\n",
      "50 doug\n",
      "25 downside\n",
      "36 drag\n",
      "2163 drain\n",
      "41 draw\n",
      "108 drawback\n",
      "43 drawer\n",
      "39 drawing\n",
      "52 drawn\n",
      "30 draws\n",
      "78 drive\n",
      "34 driving\n",
      "37 drop\n",
      "28 dropping\n",
      "47 drum\n",
      "53 dry\n",
      "253 dumb\n",
      "26 dungeon\n",
      "52 dunwich\n",
      "44 duplo\n",
      "28 durability\n",
      "49 durable\n",
      "38 dvd\n",
      "147 ear\n",
      "94 earlier\n",
      "28 early\n",
      "157 ears\n",
      "62 ease\n",
      "78 easel\n",
      "470 easier\n",
      "22 easily\n",
      "184 easy\n",
      "20 eat\n",
      "69 ebay\n",
      "20 edge\n",
      "27 edges\n",
      "153 edition\n",
      "591 education\n",
      "1125 educational\n",
      "28 effect\n",
      "33 effects\n",
      "34 effort\n",
      "207 eggs\n",
      "23 elder\n",
      "298 electric\n",
      "54 electronic\n",
      "41 element\n",
      "36 elements\n",
      "36 elf\n",
      "39 empire\n",
      "43 encounter\n",
      "382 encourage\n",
      "73 encourages\n",
      "49 end\n",
      "49 ended\n",
      "23 endless\n",
      "410 ends\n",
      "90 energy\n",
      "31 engine\n",
      "30 engines\n",
      "81 english\n",
      "56 enjoy\n",
      "35 enjoyable\n",
      "41 enjoyed\n",
      "44 enjoying\n",
      "611 enjoyment\n",
      "64 enjoys\n",
      "317 entertain\n",
      "48 entertained\n",
      "35 entertaining\n",
      "170 entertainment\n",
      "25 entire\n",
      "50 entirely\n",
      "76 erase\n",
      "30 especially\n",
      "103 essentially\n",
      "29 etch\n",
      "40 euro\n",
      "243 eve\n",
      "41 evening\n",
      "58 events\n",
      "28 eventually\n",
      "25 everyday\n",
      "52 everytime\n",
      "47 evil\n",
      "66 exact\n",
      "45 exactly\n",
      "21 example\n",
      "36 excellent\n",
      "27 exception\n",
      "101 excited\n",
      "117 excitement\n",
      "168 exciting\n",
      "27 exercise\n",
      "163 expansion\n",
      "57 expansions\n",
      "32 expect\n",
      "20 expected\n",
      "426 expecting\n",
      "174 expensive\n",
      "127 experience\n",
      "103 experiment\n",
      "31 explain\n",
      "96 explained\n",
      "187 explore\n",
      "26 extra\n",
      "46 extremely\n",
      "213 eye\n",
      "79 eyes\n",
      "63 face\n",
      "60 faces\n",
      "162 fact\n",
      "87 factor\n",
      "246 fail\n",
      "42 fair\n",
      "54 fairly\n",
      "151 falcon\n",
      "240 fall\n",
      "44 falling\n",
      "63 falls\n",
      "84 familiar\n",
      "55 families\n",
      "846 family\n",
      "156 fan\n",
      "71 fans\n",
      "78 fantastic\n",
      "144 fantasy\n",
      "366 far\n",
      "245 fashion\n",
      "57 fashioned\n",
      "28 fast\n",
      "328 faster\n",
      "47 father\n",
      "72 fault\n",
      "50 favor\n",
      "337 favorite\n",
      "38 favorites\n",
      "69 feature\n",
      "121 features\n",
      "36 feel\n",
      "62 feeling\n",
      "19 feels\n",
      "31 feet\n",
      "23 fell\n",
      "31 felt\n",
      "85 ffg\n",
      "48 field\n",
      "38 fight\n",
      "47 fighter\n",
      "173 fighters\n",
      "87 fighting\n",
      "49 figure\n",
      "53 figured\n",
      "36 figuring\n",
      "113 filled\n",
      "54 filling\n",
      "33 fills\n",
      "223 final\n",
      "49 finally\n",
      "59 finding\n",
      "78 fine\n",
      "48 fingers\n",
      "23 finish\n",
      "225 finished\n",
      "109 fish\n",
      "87 fisher\n",
      "382 fishing\n",
      "77 fit\n",
      "26 fits\n",
      "23 flat\n",
      "58 flexible\n",
      "30 flies\n",
      "168 flight\n",
      "119 flimsy\n",
      "58 flip\n",
      "161 floor\n",
      "22 floors\n",
      "156 fluxx\n",
      "153 fly\n",
      "77 flying\n",
      "25 foam\n",
      "60 focus\n",
      "31 fold\n",
      "23 folks\n",
      "91 follow\n",
      "37 following\n",
      "105 food\n",
      "27 foot\n",
      "32 force\n",
      "23 forever\n",
      "78 forget\n",
      "40 form\n",
      "77 forth\n",
      "28 fortunately\n",
      "128 forward\n",
      "34 fourth\n",
      "110 frame\n",
      "28 free\n",
      "31 frequently\n",
      "143 fresh\n",
      "48 friend\n",
      "375 friendly\n",
      "71 friends\n",
      "21 frog\n",
      "92 frogs\n",
      "121 fruit\n",
      "43 frustrated\n",
      "4010 frustrating\n",
      "64 frustration\n",
      "28 fully\n",
      "56 fun\n",
      "41 funny\n",
      "15843 furniture\n",
      "148 future\n",
      "69 gain\n",
      "81 game\n",
      "2040 gameplay\n",
      "116 gamer\n",
      "21 gamers\n",
      "41 games\n",
      "32 gaming\n",
      "168 garage\n",
      "31 garbage\n",
      "154 garden\n",
      "61 gate\n",
      "38 gather\n",
      "23 gathering\n",
      "27 gave\n",
      "34 gear\n",
      "511 gears\n",
      "485 general\n",
      "23 generally\n",
      "426 generic\n",
      "61 gets\n",
      "105 getting\n",
      "125 gift\n",
      "162 gifts\n",
      "100 girl\n",
      "63 girls\n",
      "110 given\n",
      "48 gives\n",
      "61 giving\n",
      "55 glad\n",
      "32 glass\n",
      "110 glue\n",
      "41 goal\n",
      "216 goals\n",
      "480 goes\n",
      "84 going\n",
      "46 gold\n",
      "2161 gone\n",
      "29 good\n",
      "1429 goods\n",
      "83 got\n",
      "44 gotten\n",
      "30 grab\n",
      "65 grade\n",
      "79 grail\n",
      "122 grand\n",
      "37 grandchildren\n",
      "22 granddaughter\n",
      "29 grandkids\n",
      "255 grandma\n",
      "27 grandparents\n",
      "30 grandson\n",
      "25 grandsons\n",
      "3281 graphics\n",
      "119 gras\n",
      "42 grasp\n",
      "40 grass\n",
      "48 great\n",
      "337 greatly\n",
      "46 green\n",
      "75 grew\n",
      "56 grid\n",
      "37 grocery\n",
      "28 ground\n",
      "199 group\n",
      "34 groups\n",
      "49 grow\n",
      "22 growing\n",
      "42 grown\n",
      "127 grows\n",
      "59 guess\n",
      "469 guests\n",
      "237 gun\n",
      "293 guy\n",
      "28 guys\n",
      "54 half\n",
      "79 hammer\n",
      "28 hand\n",
      "73 handle\n",
      "251 handling\n",
      "740 hands\n",
      "66 handy\n",
      "20 hang\n",
      "84 happen\n",
      "21 happened\n",
      "56 happens\n",
      "146 happy\n",
      "400 hard\n",
      "61 harder\n",
      "123 hardly\n",
      "35 hardwood\n",
      "70 harold\n",
      "38 hasn\n",
      "19 hate\n",
      "35 haven\n",
      "122 having\n",
      "24 hazard\n",
      "111 head\n",
      "65 heads\n",
      "93 hear\n",
      "39 heard\n",
      "385 hearing\n",
      "74 heart\n",
      "35 heavy\n",
      "37 height\n",
      "128 held\n",
      "77 heli\n",
      "93 helicopter\n",
      "44 helicopters\n",
      "28 help\n",
      "269 helped\n",
      "68 helpful\n",
      "327 helping\n",
      "60 helps\n",
      "52 heroes\n",
      "260 hey\n",
      "38 hide\n",
      "291 high\n",
      "27 higher\n",
      "66 highest\n",
      "108 highly\n",
      "112 hilarious\n",
      "183 hill\n",
      "27 hippo\n",
      "20 hippos\n",
      "186 history\n",
      "23 hit\n",
      "36 hitting\n",
      "33 hold\n",
      "88 holder\n",
      "40 holders\n",
      "19 holding\n",
      "45 holds\n",
      "29 hole\n",
      "78 holes\n",
      "53 holidays\n",
      "54 home\n",
      "173 honestly\n",
      "371 hook\n",
      "460 hooked\n",
      "26 hope\n",
      "128 hopefully\n",
      "23 hoping\n",
      "27 horror\n",
      "44 horse\n",
      "225 hot\n",
      "105 hotels\n",
      "337 hour\n",
      "25 hours\n",
      "24 house\n",
      "24 houses\n",
      "21 hubby\n",
      "37 huge\n",
      "22 hull\n",
      "62 hungry\n",
      "69 hurt\n",
      "79 husband\n",
      "29 ice\n",
      "87 idea\n",
      "54 ideas\n",
      "41 illustrations\n",
      "29 im\n",
      "30 image\n",
      "26 images\n",
      "37 imagination\n",
      "96 imagine\n",
      "231 immediately\n",
      "117 imperial\n",
      "103 important\n",
      "36 impossible\n",
      "34 impressed\n",
      "31 impressive\n",
      "37 improve\n",
      "32 improved\n",
      "40 inch\n",
      "23 inches\n",
      "29 include\n",
      "40 included\n",
      "25 includes\n",
      "34 including\n",
      "41 increase\n",
      "213 incredibly\n",
      "335 individual\n",
      "142 indoor\n",
      "22 indoors\n",
      "24 inexpensive\n",
      "43 initial\n",
      "43 initially\n",
      "20 ink\n",
      "121 insert\n",
      "152 inside\n",
      "45 instead\n",
      "34 instruction\n",
      "31 instructions\n",
      "21 intended\n",
      "21 interaction\n",
      "27 interested\n",
      "117 interesting\n",
      "26 intrigue\n",
      "23 introduce\n",
      "460 introduced\n",
      "118 investigator\n",
      "90 investigators\n",
      "315 investment\n",
      "119 involved\n",
      "33 involves\n",
      "90 isn\n",
      "24 issue\n",
      "28 issues\n",
      "29 item\n",
      "65 items\n",
      "20 jack\n",
      "32 job\n",
      "32 join\n",
      "4383 joy\n",
      "39 jr\n",
      "65 judge\n",
      "159 juice\n",
      "90 jump\n",
      "73 jumping\n",
      "26 junk\n",
      "32 just\n",
      "405 keeper\n",
      "2810 keeping\n",
      "98 keeps\n",
      "222 kept\n",
      "23 key\n",
      "43 keys\n",
      "47 kick\n",
      "44 kid\n",
      "83 kids\n",
      "97 kill\n",
      "75 killing\n",
      "65 kind\n",
      "91 kinds\n",
      "31 king\n",
      "670 kingsburg\n",
      "33 kit\n",
      "34 kitchen\n",
      "34 knew\n",
      "77 knight\n",
      "35 knights\n",
      "23 knobs\n",
      "31 knock\n",
      "25 know\n",
      "82 knowing\n",
      "20 knows\n",
      "274 lack\n",
      "120 ladders\n",
      "37 laminate\n",
      "29 land\n",
      "179 landing\n",
      "58 lands\n",
      "45 large\n",
      "33 larger\n",
      "31 lasted\n",
      "33 lasting\n",
      "173 later\n",
      "32 laugh\n",
      "114 laughing\n",
      "566 laughs\n",
      "114 launcher\n",
      "388 law\n",
      "90 lawn\n",
      "23 lay\n",
      "20 layout\n",
      "161 lead\n",
      "140 leads\n",
      "71 leap\n",
      "76 leapfrog\n",
      "71 learn\n",
      "234 learned\n",
      "54 learning\n",
      "202 leave\n",
      "369 leaves\n",
      "35 leaving\n",
      "327 left\n",
      "62 lego\n",
      "117 legos\n",
      "220 legs\n",
      "199 length\n",
      "88 lessons\n",
      "32 let\n",
      "3713 lets\n",
      "172 letter\n",
      "71 letters\n",
      "326 letting\n",
      "23 level\n",
      "68 levels\n",
      "179 lever\n",
      "84 lid\n",
      "66 life\n",
      "21 lift\n",
      "23 light\n",
      "30 lights\n",
      "2528 lightweight\n",
      "59 like\n",
      "43 liked\n",
      "625 likely\n",
      "24 likes\n",
      "41 limit\n",
      "80 limited\n",
      "44 limiting\n",
      "39 line\n",
      "41 lines\n",
      "741 list\n",
      "250 listen\n",
      "433 literally\n",
      "86 little\n",
      "357 live\n",
      "261 living\n",
      "24 ll\n",
      "65 llama\n",
      "38 loads\n",
      "49 local\n",
      "169 location\n",
      "33 lock\n",
      "89 logic\n",
      "129 lol\n",
      "1055 long\n",
      "286 longer\n",
      "146 look\n",
      "1602 looked\n",
      "43 looking\n",
      "509 looks\n",
      "23 loom\n",
      "1427 loops\n",
      "27 loose\n",
      "157 lose\n",
      "90 losing\n",
      "296 loss\n",
      "23 lost\n",
      "48 lot\n",
      "40 lots\n",
      "151 loud\n",
      "32 love\n",
      "64 lovecraft\n",
      "37 loved\n",
      "56 loves\n",
      "81 loving\n",
      "57 low\n",
      "42 lower\n",
      "1407 lowercase\n",
      "613 lowest\n",
      "238 luck\n",
      "67 luckily\n",
      "27 lucky\n",
      "40 magic\n",
      "32 magnetic\n",
      "68 magnets\n",
      "46 mail\n",
      "62 main\n",
      "151 mainly\n",
      "49 major\n",
      "174 make\n",
      "37 makes\n",
      "67 making\n",
      "42 man\n",
      "105 manage\n",
      "29 managed\n",
      "71 mancala\n",
      "52 maneuver\n",
      "72 manipulate\n",
      "106 manufacturer\n",
      "108 map\n",
      "41 marble\n",
      "335 marbles\n",
      "72 mark\n",
      "27 marker\n",
      "88 markers\n",
      "35 market\n",
      "43 marks\n",
      "111 master\n",
      "74 mat\n",
      "22 match\n",
      "59 matching\n",
      "35 material\n",
      "76 materials\n",
      "47 math\n",
      "72 matter\n",
      "52 maximum\n",
      "21 maybe\n",
      "83 mean\n",
      "61 meaning\n",
      "42 means\n",
      "150 meant\n",
      "39 mechanic\n",
      "97 mechanics\n",
      "73 meet\n",
      "77 melissa\n",
      "60 members\n",
      "435 memories\n",
      "33 memory\n",
      "87 mention\n",
      "31 mentioned\n",
      "71 mess\n",
      "26 metal\n",
      "52 middle\n",
      "51 milk\n",
      "129 mind\n",
      "59 mini\n",
      "80 miniature\n",
      "28 miniatures\n",
      "31 minimal\n",
      "27 minimum\n",
      "919 minis\n",
      "178 minor\n",
      "145 minute\n",
      "242 minutes\n",
      "355 mirror\n",
      "771 misfit\n",
      "86 miss\n",
      "24 missiles\n",
      "49 missing\n",
      "100 mission\n",
      "139 missions\n",
      "48 mix\n",
      "54 mixed\n",
      "44 mo\n",
      "79 mobile\n",
      "109 mode\n",
      "103 model\n",
      "114 models\n",
      "20 module\n",
      "115 mom\n",
      "143 moment\n",
      "377 mommy\n",
      "40 money\n",
      "47 monkey\n",
      "23 monkeys\n",
      "54 monopoly\n",
      "51 monster\n",
      "55 monsters\n",
      "39 month\n",
      "65 months\n",
      "46 monty\n",
      "40 morning\n",
      "657 mother\n",
      "143 motor\n",
      "124 mouth\n",
      "71 moved\n",
      "25 movement\n",
      "23 moves\n",
      "82 movie\n",
      "23 movies\n",
      "937 moving\n",
      "31 mr\n",
      "792 multiple\n",
      "81 munchkin\n",
      "74 music\n",
      "254 musical\n",
      "26 mythos\n",
      "160 names\n",
      "32 nature\n",
      "46 nd\n",
      "95 near\n",
      "45 nearly\n",
      "31 neat\n",
      "86 necessary\n",
      "25 neck\n",
      "30 need\n",
      "28 needed\n",
      "62 needs\n",
      "355 negative\n",
      "137 nephew\n",
      "29 new\n",
      "61 newer\n",
      "27 nice\n",
      "61 nicely\n",
      "19 niece\n",
      "32 night\n",
      "38 nights\n",
      "31 noise\n",
      "28 noises\n",
      "19 noisy\n",
      "40 non\n",
      "39 normal\n",
      "69 north\n",
      "151 note\n",
      "70 noted\n",
      "4030 notice\n",
      "366 noticed\n",
      "32 number\n",
      "115 numbers\n",
      "332 numerous\n",
      "65 object\n",
      "33 objects\n",
      "289 obsessed\n",
      "80 obvious\n",
      "52 obviously\n",
      "27 occasion\n",
      "38 occasionally\n",
      "68 occupied\n",
      "67 offer\n",
      "52 offered\n",
      "44 offers\n",
      "43 office\n",
      "101 oh\n",
      "73 ok\n",
      "245 okay\n",
      "183 old\n",
      "28 older\n",
      "533 oldest\n",
      "37 olds\n",
      "22 ones\n",
      "31 online\n",
      "122 open\n",
      "323 opened\n",
      "28 opening\n",
      "31 operate\n",
      "20 opinion\n",
      "35 opponent\n",
      "96 opponents\n",
      "54 opportunity\n",
      "50 option\n",
      "40 options\n",
      "142 orange\n",
      "143 order\n",
      "110 ordered\n",
      "89 organs\n",
      "30 original\n",
      "340 originally\n",
      "47 othello\n",
      "47 ounce\n",
      "75 outdoor\n",
      "151 outside\n",
      "64 overall\n",
      "152 overly\n",
      "38 pack\n",
      "86 package\n",
      "50 packaging\n",
      "38 packed\n",
      "185 pad\n",
      "239 page\n",
      "65 pages\n",
      "33 paid\n",
      "116 pain\n",
      "135 paint\n",
      "40 painted\n",
      "34 painting\n",
      "31 paints\n",
      "90 pairs\n",
      "40 paper\n",
      "21 parent\n",
      "50 parents\n",
      "312 park\n",
      "67 particular\n",
      "22 particularly\n",
      "97 parties\n",
      "838 parts\n",
      "35 party\n",
      "324 pass\n",
      "69 passed\n",
      "31 past\n",
      "24 patience\n",
      "314 pattern\n",
      "22 patterns\n",
      "51 pawns\n",
      "91 pay\n",
      "114 paying\n",
      "25 peg\n",
      "262 pegs\n",
      "77 pen\n",
      "48 pencils\n",
      "24 penny\n",
      "184 people\n",
      "157 perfect\n",
      "315 perfectly\n",
      "1516 perform\n",
      "21 person\n",
      "63 personal\n",
      "113 personally\n",
      "74 pete\n",
      "33 phase\n",
      "40 phone\n",
      "355 photo\n",
      "71 piano\n",
      "60 pick\n",
      "61 picked\n",
      "38 picking\n",
      "32 picks\n",
      "88 picture\n",
      "36 pictures\n",
      "54 piece\n",
      "720 pieces\n",
      "67 pile\n",
      "54 pilot\n",
      "5143 pilots\n",
      "1322 pirate\n",
      "1075 pit\n",
      "1541 place\n",
      "1663 placed\n",
      "380 placement\n",
      "90 places\n",
      "93 placing\n",
      "162 plan\n",
      "36 planet\n",
      "320 planets\n",
      "446 planning\n",
      "60 plastic\n",
      "201 plate\n",
      "44 plates\n",
      "24 play\n",
      "144 playdoh\n",
      "43 played\n",
      "40 player\n",
      "27 players\n",
      "47 playing\n",
      "38 plays\n",
      "58 pleased\n",
      "34 plenty\n",
      "67 plug\n",
      "34 plus\n",
      "160 point\n",
      "22 points\n",
      "22 pole\n",
      "24 pooh\n",
      "32 pool\n",
      "109 poor\n",
      "25 pop\n",
      "20 popper\n",
      "83 pops\n",
      "44 popular\n",
      "66 portable\n",
      "29 position\n",
      "28 positive\n",
      "52 possibilities\n",
      "31 possible\n",
      "95 possibly\n",
      "61 post\n",
      "24 pot\n",
      "58 potential\n",
      "599 potentially\n",
      "26 potholders\n",
      "44 pound\n",
      "624 pounding\n",
      "26 power\n",
      "23 powerful\n",
      "23 practice\n",
      "33 pre\n",
      "41 prefer\n",
      "331 prefers\n",
      "393 premise\n",
      "117 prepared\n",
      "58 preschool\n",
      "635 preschooler\n",
      "94 present\n",
      "42 press\n",
      "25 pressing\n",
      "30 pretend\n",
      "72 pretty\n",
      "47 prevent\n",
      "49 previous\n",
      "40 previously\n",
      "48 price\n",
      "212 priced\n",
      "35 prices\n",
      "47 pricey\n",
      "64 printed\n",
      "269 probably\n",
      "463 problem\n",
      "46 problems\n",
      "59 process\n",
      "59 product\n",
      "347 products\n",
      "43 program\n",
      "50 progress\n",
      "137 projects\n",
      "41 properly\n",
      "185 properties\n",
      "703 property\n",
      "271 pros\n",
      "22 provide\n",
      "792 provided\n",
      "68 provides\n",
      "151 puck\n",
      "322 pull\n",
      "123 pulled\n",
      "168 pulling\n",
      "345 pulls\n",
      "35 pump\n",
      "444 purchase\n",
      "409 purchased\n",
      "23 purchasing\n",
      "68 pure\n",
      "26 purple\n",
      "56 purpose\n",
      "26 push\n",
      "38 pushed\n",
      "43 pushing\n",
      "27 puts\n",
      "192 putting\n",
      "26 puzzle\n",
      "125 puzzles\n",
      "21 pvc\n",
      "28 python\n",
      "59 quality\n",
      "34 quest\n",
      "51 question\n",
      "41 questions\n",
      "49 quests\n",
      "45 quick\n",
      "39 quickly\n",
      "40 quiet\n",
      "354 quite\n",
      "172 quot\n",
      "42 race\n",
      "106 racing\n",
      "309 rainy\n",
      "46 random\n",
      "48 range\n",
      "32 rarely\n",
      "2340 rate\n",
      "121 rated\n",
      "32 rating\n",
      "53 ravensburger\n",
      "25 rc\n",
      "46 rd\n",
      "260 reach\n",
      "66 read\n",
      "26 reading\n",
      "23 reads\n",
      "813 ready\n",
      "21 real\n",
      "144 realistic\n",
      "202 reality\n",
      "26 realize\n",
      "37 realized\n",
      "22 really\n",
      "108 realm\n",
      "27 reason\n",
      "27 reasonable\n",
      "46 reasons\n",
      "27 rebel\n",
      "36 receive\n",
      "306 received\n",
      "26 recently\n",
      "64 recommend\n",
      "71 recommended\n",
      "29 red\n",
      "42 register\n",
      "31 regular\n",
      "73 regularly\n",
      "46 relatively\n",
      "31 release\n",
      "67 released\n",
      "75 remember\n",
      "113 remembered\n",
      "71 remote\n",
      "107 remove\n",
      "37 rent\n",
      "71 replace\n",
      "31 replaced\n",
      "40 replacement\n",
      "122 replay\n",
      "130 replayability\n",
      "26 report\n",
      "197 require\n",
      "28 required\n",
      "63 requires\n",
      "313 research\n",
      "21 resources\n",
      "24 response\n",
      "301 rest\n",
      "27 result\n",
      "59 results\n",
      "714 return\n",
      "88 returned\n",
      "123 reveal\n",
      "76 review\n",
      "24 reviewer\n",
      "23 reviewers\n",
      "84 reviews\n",
      "75 rewards\n",
      "36 ride\n",
      "42 rides\n",
      "76 riding\n",
      "290 right\n",
      "63 ring\n",
      "24 rings\n",
      "98 risk\n",
      "61 road\n",
      "307 rocket\n",
      "70 rockets\n",
      "192 rocks\n",
      "72 rody\n",
      "39 role\n",
      "31 roles\n",
      "45 roll\n",
      "47 rolled\n",
      "114 rolling\n",
      "38 rolls\n",
      "735 roof\n",
      "158 room\n",
      "44 rooms\n",
      "60 rope\n",
      "61 rough\n",
      "41 round\n",
      "25 rounds\n",
      "83 routes\n",
      "26 rover\n",
      "220 row\n",
      "40 rudolph\n",
      "125 ruin\n",
      "54 rule\n",
      "145 rules\n",
      "39 run\n",
      "46 running\n",
      "110 runs\n",
      "479 rush\n",
      "38 safe\n",
      "111 safety\n",
      "30 said\n",
      "22 sale\n",
      "54 sand\n",
      "66 sandbox\n",
      "184 santa\n",
      "121 sat\n",
      "24 save\n",
      "28 saw\n",
      "19 say\n",
      "155 saying\n",
      "72 says\n",
      "196 scenarios\n",
      "44 scene\n",
      "27 school\n",
      "38 score\n",
      "24 scoring\n",
      "109 scrabble\n",
      "219 screen\n",
      "53 screw\n",
      "39 search\n",
      "55 seat\n",
      "70 second\n",
      "141 secondary\n",
      "49 seconds\n",
      "23 seeing\n",
      "32 seen\n",
      "31 select\n",
      "34 selection\n",
      "64 sell\n",
      "69 send\n",
      "39 sense\n",
      "23 sent\n",
      "77 series\n",
      "54 seriously\n",
      "89 session\n",
      "1468 set\n",
      "216 sets\n",
      "68 setting\n",
      "63 settings\n",
      "67 setup\n",
      "42 seven\n",
      "146 shake\n",
      "31 shallow\n",
      "230 shape\n",
      "35 shaped\n",
      "29 shapes\n",
      "38 share\n",
      "53 sharp\n",
      "92 sheet\n",
      "250 sheets\n",
      "73 shelf\n",
      "195 ship\n",
      "32 shipping\n",
      "52 ships\n",
      "82 shoot\n",
      "173 shop\n",
      "35 shopping\n",
      "26 short\n",
      "53 shot\n",
      "33 shouldn\n",
      "103 showed\n",
      "29 shown\n",
      "21 shows\n",
      "29 shut\n",
      "78 sided\n",
      "20 sides\n",
      "51 sign\n",
      "48 signs\n",
      "126 silly\n",
      "633 similar\n",
      "121 simple\n",
      "33 simply\n",
      "113 sing\n",
      "81 singing\n",
      "232 single\n",
      "48 sister\n",
      "102 sit\n",
      "294 site\n",
      "47 sits\n",
      "21 sitting\n",
      "38 situation\n",
      "103 size\n",
      "270 sized\n",
      "31 sketch\n",
      "20 skill\n",
      "40 skills\n",
      "34 skip\n",
      "33 sleep\n",
      "109 slide\n",
      "69 slightly\n",
      "46 slinky\n",
      "46 slots\n",
      "60 slow\n",
      "19 slowly\n",
      "699 small\n",
      "189 smaller\n",
      "29 smart\n",
      "126 smell\n",
      "23 smile\n",
      "39 smock\n",
      "32 smooth\n",
      "44 snap\n",
      "38 snow\n",
      "22 soft\n",
      "94 sold\n",
      "34 solid\n",
      "90 solitaire\n",
      "36 solo\n",
      "21 solution\n",
      "41 solve\n",
      "45 solving\n",
      "76 somewhat\n",
      "2193 son\n",
      "141 song\n",
      "81 songs\n",
      "49 sons\n",
      "145 soon\n",
      "59 sorry\n",
      "88 sort\n",
      "28 sorting\n",
      "23 sorts\n",
      "27 sound\n",
      "233 sounds\n",
      "166 space\n",
      "257 spaces\n",
      "89 special\n",
      "25 specific\n",
      "22 speed\n",
      "254 spell\n",
      "90 spelling\n",
      "81 spells\n",
      "46 spend\n",
      "35 spending\n",
      "119 spent\n",
      "22 spin\n",
      "94 spinner\n",
      "115 spinning\n",
      "58 spins\n",
      "47 spot\n",
      "50 spots\n",
      "41 square\n",
      "66 st\n",
      "55 stable\n",
      "23 stack\n",
      "25 stacked\n",
      "33 stacking\n",
      "62 stairs\n",
      "30 stand\n",
      "57 standard\n",
      "49 standards\n",
      "94 standing\n",
      "28 stands\n",
      "23 star\n",
      "46 stars\n",
      "215 start\n",
      "70 started\n",
      "45 starter\n",
      "32 starting\n",
      "241 starts\n",
      "225 state\n",
      "335 states\n",
      "192 stay\n",
      "64 stays\n",
      "116 steal\n",
      "86 step\n",
      "24 stethoscope\n",
      "28 stick\n",
      "46 sticker\n",
      "158 stickers\n",
      "29 sticking\n",
      "19 sticks\n",
      "39 stocking\n",
      "53 stood\n",
      "83 stop\n",
      "28 stops\n",
      "115 storage\n",
      "58 store\n",
      "147 stores\n",
      "111 stories\n",
      "52 story\n",
      "20 straight\n",
      "151 strategic\n",
      "29 strategies\n",
      "26 strategy\n",
      "110 strength\n",
      "258 string\n",
      "56 strong\n",
      "70 stronger\n",
      "219 structure\n",
      "105 structures\n",
      "39 stuck\n",
      "43 students\n",
      "445 stuff\n",
      "29 stuffed\n",
      "30 sturdier\n",
      "33 sturdy\n",
      "113 style\n",
      "36 subject\n",
      "123 subtle\n",
      "84 successful\n",
      "35 sugar\n",
      "149 suggest\n",
      "29 suggested\n",
      "355 summer\n",
      "111 sun\n",
      "32 super\n",
      "25 support\n",
      "35 supports\n",
      "36 suppose\n",
      "65 supposed\n",
      "24 sure\n",
      "60 surface\n",
      "34 surprise\n",
      "152 surprised\n",
      "58 survey\n",
      "27 survived\n",
      "80 sweet\n",
      "603 swing\n",
      "49 switch\n",
      "36 symbols\n",
      "71 table\n",
      "22 tabletop\n",
      "25 tactical\n",
      "55 tad\n",
      "66 tail\n",
      "41 taken\n",
      "222 takes\n",
      "35 taking\n",
      "67 talk\n",
      "36 talking\n",
      "49 tall\n",
      "367 tape\n",
      "152 target\n",
      "32 task\n",
      "44 tasks\n",
      "50 tea\n",
      "56 teach\n",
      "56 teacher\n",
      "64 teaches\n",
      "21 teaching\n",
      "34 team\n",
      "64 teams\n",
      "209 tech\n",
      "22 technology\n",
      "88 tell\n",
      "119 telling\n",
      "47 tells\n",
      "21 tend\n",
      "21 tends\n",
      "27 tent\n",
      "135 terms\n",
      "45 test\n",
      "40 testing\n",
      "49 th\n",
      "26 thanks\n",
      "69 thanksgiving\n",
      "39 theme\n",
      "22 themed\n",
      "21 thicker\n",
      "45 thing\n",
      "84 things\n",
      "86 think\n",
      "39 thinkfun\n",
      "31 thinking\n",
      "236 thinks\n",
      "32 thomas\n",
      "734 thought\n",
      "577 thrilled\n",
      "1201 throw\n",
      "128 thrown\n",
      "37 ticket\n",
      "233 tie\n",
      "387 tight\n",
      "43 tikes\n",
      "78 tile\n",
      "35 tiles\n",
      "127 till\n",
      "33 time\n",
      "133 timeline\n",
      "43 timer\n",
      "41 times\n",
      "129 tin\n",
      "245 tiny\n",
      "43 tip\n",
      "2539 tips\n",
      "19 tire\n",
      "37 tired\n",
      "538 title\n",
      "98 today\n",
      "78 toddler\n",
      "28 toddlers\n",
      "58 token\n",
      "22 tokens\n",
      "20 told\n",
      "90 ton\n",
      "203 tonka\n",
      "79 tons\n",
      "61 took\n",
      "174 tool\n",
      "65 tools\n",
      "62 toss\n",
      "72 total\n",
      "277 totally\n",
      "74 touch\n",
      "47 tough\n",
      "77 toy\n",
      "84 toys\n",
      "123 track\n",
      "34 tracks\n",
      "24 trade\n",
      "26 tradition\n",
      "4497 traditional\n",
      "950 train\n",
      "221 trains\n",
      "55 traitor\n",
      "48 travel\n",
      "46 tray\n",
      "61 treasure\n",
      "239 treat\n",
      "131 tree\n",
      "48 trees\n",
      "61 tricky\n",
      "77 tried\n",
      "112 tries\n",
      "84 trim\n",
      "37 trip\n",
      "20 trips\n",
      "261 trouble\n",
      "48 truck\n",
      "43 true\n",
      "42 truly\n",
      "45 try\n",
      "126 trying\n",
      "63 tub\n",
      "21 tube\n",
      "69 tune\n",
      "59 tunes\n",
      "35 tunnel\n",
      "350 tunnels\n",
      "327 turn\n",
      "84 turned\n",
      "29 turning\n",
      "71 turns\n",
      "698 tv\n",
      "111 twice\n",
      "67 twins\n",
      "312 twist\n",
      "37 twister\n",
      "90 twists\n",
      "104 type\n",
      "31 types\n",
      "38 typical\n",
      "41 typically\n",
      "156 underneath\n",
      "65 understand\n",
      "29 understanding\n",
      "206 unfortunately\n",
      "21 unique\n",
      "93 unit\n",
      "140 unless\n",
      "44 unlike\n",
      "30 uno\n",
      "105 update\n",
      "73 updated\n",
      "41 upgrade\n",
      "82 upgrades\n",
      "25 upper\n",
      "121 upset\n",
      "43 upside\n",
      "22 usb\n",
      "33 use\n",
      "27 used\n",
      "1262 useful\n",
      "793 useless\n",
      "49 uses\n",
      "28 using\n",
      "126 usual\n",
      "354 usually\n",
      "27 vacuum\n",
      "200 value\n",
      "86 variation\n",
      "280 variations\n",
      "41 variety\n",
      "27 various\n",
      "40 ve\n",
      "167 velcro\n",
      "95 version\n",
      "28 versions\n",
      "833 vertical\n",
      "31 vibrant\n",
      "748 victory\n",
      "87 video\n",
      "30 village\n",
      "86 vinyl\n",
      "65 visit\n",
      "20 visual\n",
      "54 visually\n",
      "42 vocabulary\n",
      "22 voice\n",
      "35 volume\n",
      "52 vs\n",
      "20 wagon\n",
      "141 wait\n",
      "129 waiting\n",
      "57 walk\n",
      "203 walker\n",
      "90 walking\n",
      "112 wall\n",
      "43 walls\n",
      "67 want\n",
      "52 wanted\n",
      "659 wanting\n",
      "317 wants\n",
      "37 wars\n",
      "133 wash\n",
      "33 washable\n",
      "89 wasn\n",
      "50 waste\n",
      "51 watch\n",
      "149 watched\n",
      "114 watching\n",
      "157 water\n",
      "23 way\n",
      "123 ways\n",
      "206 weapon\n",
      "44 weapons\n",
      "1030 wear\n",
      "123 weather\n",
      "29 website\n",
      "39 week\n",
      "46 weeks\n",
      "25 weight\n",
      "27 weird\n",
      "103 went\n",
      "121 weren\n",
      "57 wheel\n",
      "146 wheels\n",
      "34 white\n",
      "76 wide\n",
      "188 wife\n",
      "105 wild\n",
      "58 willing\n",
      "81 win\n",
      "31 wind\n",
      "29 wing\n",
      "366 wings\n",
      "40 winner\n",
      "230 winning\n",
      "32 wins\n",
      "86 winter\n",
      "89 wire\n",
      "105 wish\n",
      "31 withstand\n",
      "22 won\n",
      "312 wonder\n",
      "266 wonderful\n",
      "40 wood\n",
      "168 wooden\n",
      "29 word\n",
      "180 words\n",
      "178 work\n",
      "144 worked\n",
      "308 worker\n",
      "844 working\n",
      "114 workout\n",
      "62 works\n",
      "33 world\n",
      "120 worried\n",
      "283 worry\n",
      "120 worse\n",
      "27 worth\n",
      "52 worthwhile\n",
      "21 wouldn\n",
      "369 write\n",
      "161 writing\n",
      "110 written\n",
      "58 wrong\n",
      "38 wrote\n",
      "141 xmas\n",
      "21 yahtzee\n",
      "37 yard\n",
      "69 yeah\n",
      "2599 year\n",
      "695 years\n",
      "83 yellow\n",
      "195 yes\n",
      "21 yo\n",
      "135 young\n",
      "368 younger\n",
      "264 youngest\n",
      "53 youth\n",
      "28 youtube\n",
      "202 yr\n",
      "38 yrs\n",
      "85 zero\n",
      "54 zombie\n",
      "30 zombies\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it\n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3pt) Which of the following three distance functions ‘cosine’, ’euclidean’, and ‘manhattan’ do you deem more appropriate for this problem? Please justify\n",
    "\n",
    "Cosine permet de mesurer la proximité entre deux vecteurs qui est représenté par les unités de texte (train_data_features) \n",
    "Ainsi, si les vecteurs ont le même angle; ils ont une similarité cosine de 1\n",
    "Si les deux deux vecteurs sont orientés à 90 degrés, ils ont une simlarité cosine de 0 \n",
    "Enfin, si elles sont orientés à 180 degrés, donc totalement opposé, ils ont une similarité de 0.\n",
    "Cosine normalise ainsi la similarité entre deux points pour chaque vecteur.\n",
    "\n",
    "La distance euclédienne permet de mesurer la distance entre deux points dans un espace tel qu'exprimé par la mesure de pythagore. De ce fait, elle ne prend pas en considération l'angle de ceux-ci comme la mesure cosine.\n",
    "\n",
    "La distance Manhattan est la somme des différences absolues entre deux points. Dans la mesure où les points se trouvent sur le même x ou le même y; la distance euclédienne et manhattan sont équivalente.\n",
    "\n",
    "Ainsi, ces deux mesures sont similaires et réagissent similairement à la distance entre les mots. Plus un vecteur à des mots différents, plus son poids pèsera sur la balance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1  number of neighboors, the accuracy of the train model is 83.88946280991736 % and the accuracy of the valid model is 17.24137931034483 %\n",
      "With 10  number of neighboors, the accuracy of the train model is 60.85227272727273 % and the accuracy of the valid model is 19.908045977011493 %\n",
      "With 50  number of neighboors, the accuracy of the train model is 48.97210743801653 % and the accuracy of the valid model is 18.590038314176248 %\n",
      "With 100  number of neighboors, the accuracy of the train model is 43.1456611570248 % and the accuracy of the valid model is 19.54022988505747 %\n",
      "With 1000  number of neighboors, the accuracy of the train model is 32.56198347107438 % and the accuracy of the valid model is 30.513409961685824 %\n"
     ]
    }
   ],
   "source": [
    "nb_neighboors = [1, 10, 50, 100, 1000]\n",
    "for neighboors in nb_neighboors:\n",
    "    knn = KNeighborsClassifier(neighboors,\n",
    "                               metric='cosine')\n",
    "    knn.fit(train_data_features, y_train)\n",
    "\n",
    "    knn_acc_train = (sum(knn.predict(train_data_features)\n",
    "                         == y_train)/len(y_train))*100\n",
    "    knn_acc_valid = (\n",
    "        sum(knn.predict(valid_data_features) == y_val)/len(y_val))*100\n",
    "\n",
    "    print(\"With\", neighboors, \" number of neighboors, the accuracy of the train model is\", knn_acc_train,\n",
    "          \"% and the accuracy of the valid model is\", knn_acc_valid, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.2\n",
       "2    0.2\n",
       "5    0.2\n",
       "3    0.2\n",
       "1    0.2\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".5pt)Whatvalueofthehyperparameterprovidesthebestresults?Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = [0.0, 0.5, 1.0]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "nb_neurons = [10, 20, 30]\n",
    "nb_hidden_layer = [10, 50, 100, 150, 500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.0 0.001 10 10  number of neighboors, the accuracy of the train model is 0.7660640495867769 % and the accuracy of the valid model is 0.26298850574712646 %\n",
      "[[ 1.          8.53639847]\n",
      " [ 2.         20.76628352]\n",
      " [ 3.         12.91954023]\n",
      " [ 4.         34.74329502]\n",
      " [ 5.         23.03448276]]\n",
      "1 91.46360153256705\n",
      "2 79.23371647509579\n",
      "3 87.08045977011494\n",
      "4 65.25670498084291\n",
      "5 76.96551724137932\n",
      "With 0.0 0.001 10 50  number of neighboors, the accuracy of the train model is 0.828099173553719 % and the accuracy of the valid model is 0.26022988505747124 %\n",
      "[[ 1.          6.52873563]\n",
      " [ 2.         22.78927203]\n",
      " [ 3.         11.0651341 ]\n",
      " [ 4.         31.7394636 ]\n",
      " [ 5.         27.87739464]]\n",
      "1 93.47126436781609\n",
      "2 77.21072796934865\n",
      "3 88.93486590038314\n",
      "4 68.26053639846744\n",
      "5 72.12260536398468\n",
      "With 0.0 0.001 10 100  number of neighboors, the accuracy of the train model is 0.8150826446280992 % and the accuracy of the valid model is 0.26191570881226056 %\n",
      "[[ 1.          8.45977011]\n",
      " [ 2.         18.05363985]\n",
      " [ 3.         12.59770115]\n",
      " [ 4.         38.14559387]\n",
      " [ 5.         22.74329502]]\n",
      "1 91.54022988505747\n",
      "2 81.9463601532567\n",
      "3 87.40229885057471\n",
      "4 61.8544061302682\n",
      "5 77.25670498084291\n",
      "With 0.0 0.001 10 150  number of neighboors, the accuracy of the train model is 0.8147727272727273 % and the accuracy of the valid model is 0.26252873563218393 %\n",
      "[[ 1.          6.14559387]\n",
      " [ 2.         15.81609195]\n",
      " [ 3.         13.30268199]\n",
      " [ 4.         36.76628352]\n",
      " [ 5.         27.96934866]]\n",
      "1 93.8544061302682\n",
      "2 84.183908045977\n",
      "3 86.69731800766284\n",
      "4 63.23371647509578\n",
      "5 72.03065134099617\n",
      "With 0.0 0.001 10 500  number of neighboors, the accuracy of the train model is 0.843646694214876 % and the accuracy of the valid model is 0.26559386973180077 %\n",
      "[[ 1.          1.7164751 ]\n",
      " [ 2.         15.64750958]\n",
      " [ 3.         11.54022989]\n",
      " [ 4.         35.98467433]\n",
      " [ 5.         35.11111111]]\n",
      "1 98.28352490421456\n",
      "2 84.35249042145594\n",
      "3 88.45977011494253\n",
      "4 64.01532567049809\n",
      "5 64.88888888888889\n",
      "With 0.0 0.001 20 10  number of neighboors, the accuracy of the train model is 0.8486570247933884 % and the accuracy of the valid model is 0.2697318007662835 %\n",
      "[[ 1.          7.63218391]\n",
      " [ 2.         17.82375479]\n",
      " [ 3.         12.88888889]\n",
      " [ 4.         39.55555556]\n",
      " [ 5.         22.09961686]]\n",
      "1 92.36781609195403\n",
      "2 82.17624521072797\n",
      "3 87.1111111111111\n",
      "4 60.44444444444444\n",
      "5 77.90038314176245\n",
      "With 0.0 0.001 20 50  number of neighboors, the accuracy of the train model is 0.8443181818181819 % and the accuracy of the valid model is 0.2642145593869732 %\n",
      "[[ 1.          7.43295019]\n",
      " [ 2.         19.31034483]\n",
      " [ 3.         16.24521073]\n",
      " [ 4.         35.23371648]\n",
      " [ 5.         21.77777778]]\n",
      "1 92.56704980842912\n",
      "2 80.6896551724138\n",
      "3 83.75478927203065\n",
      "4 64.76628352490421\n",
      "5 78.22222222222223\n",
      "With 0.0 0.001 20 100  number of neighboors, the accuracy of the train model is 0.8230888429752066 % and the accuracy of the valid model is 0.2798467432950192 %\n",
      "[[ 1.          6.8045977 ]\n",
      " [ 2.         20.42911877]\n",
      " [ 3.          7.52490421]\n",
      " [ 4.         40.44444444]\n",
      " [ 5.         24.79693487]]\n",
      "1 93.19540229885057\n",
      "2 79.57088122605363\n",
      "3 92.47509578544062\n",
      "4 59.55555555555555\n",
      "5 75.20306513409962\n",
      "With 0.0 0.001 20 150  number of neighboors, the accuracy of the train model is 0.8526342975206611 % and the accuracy of the valid model is 0.26298850574712646 %\n",
      "[[ 1.          5.10344828]\n",
      " [ 2.         17.74712644]\n",
      " [ 3.         15.64750958]\n",
      " [ 4.         38.51340996]\n",
      " [ 5.         22.98850575]]\n",
      "1 94.89655172413794\n",
      "2 82.25287356321839\n",
      "3 84.35249042145594\n",
      "4 61.48659003831418\n",
      "5 77.01149425287356\n",
      "With 0.0 0.001 20 500  number of neighboors, the accuracy of the train model is 0.8622933884297521 % and the accuracy of the valid model is 0.28904214559386976 %\n",
      "[[ 1.          3.04980843]\n",
      " [ 2.         17.63984674]\n",
      " [ 3.         11.23371648]\n",
      " [ 4.         42.57471264]\n",
      " [ 5.         25.50191571]]\n",
      "1 96.95019157088123\n",
      "2 82.36015325670498\n",
      "3 88.76628352490421\n",
      "4 57.42528735632184\n",
      "5 74.49808429118774\n",
      "With 0.0 0.001 30 10  number of neighboors, the accuracy of the train model is 0.8583161157024793 % and the accuracy of the valid model is 0.26559386973180077 %\n",
      "[[ 1.         10.00766284]\n",
      " [ 2.         20.38314176]\n",
      " [ 3.         11.90804598]\n",
      " [ 4.         35.55555556]\n",
      " [ 5.         22.14559387]]\n",
      "1 89.99233716475096\n",
      "2 79.61685823754789\n",
      "3 88.0919540229885\n",
      "4 64.44444444444444\n",
      "5 77.85440613026819\n",
      "With 0.0 0.001 30 50  number of neighboors, the accuracy of the train model is 0.8581611570247933 % and the accuracy of the valid model is 0.2856704980842912 %\n",
      "[[ 1.          4.55172414]\n",
      " [ 2.         20.07662835]\n",
      " [ 3.         13.47126437]\n",
      " [ 4.         38.11494253]\n",
      " [ 5.         23.78544061]]\n",
      "1 95.44827586206897\n",
      "2 79.92337164750958\n",
      "3 86.52873563218391\n",
      "4 61.88505747126437\n",
      "5 76.21455938697318\n",
      "With 0.0 0.001 30 100  number of neighboors, the accuracy of the train model is 0.8483987603305785 % and the accuracy of the valid model is 0.2660536398467433 %\n",
      "[[ 1.          3.92337165]\n",
      " [ 2.         18.03831418]\n",
      " [ 3.         13.68582375]\n",
      " [ 4.         41.51724138]\n",
      " [ 5.         22.83524904]]\n",
      "1 96.07662835249042\n",
      "2 81.96168582375479\n",
      "3 86.31417624521073\n",
      "4 58.48275862068966\n",
      "5 77.16475095785441\n",
      "With 0.0 0.001 30 150  number of neighboors, the accuracy of the train model is 0.8640495867768595 % and the accuracy of the valid model is 0.2657471264367816 %\n",
      "[[ 1.          2.91187739]\n",
      " [ 2.         17.02681992]\n",
      " [ 3.         15.4789272 ]\n",
      " [ 4.         41.8697318 ]\n",
      " [ 5.         22.71264368]]\n",
      "1 97.08812260536398\n",
      "2 82.97318007662835\n",
      "3 84.52107279693487\n",
      "4 58.13026819923371\n",
      "5 77.28735632183908\n",
      "With 0.0 0.001 30 500  number of neighboors, the accuracy of the train model is 0.8610537190082644 % and the accuracy of the valid model is 0.26590038314176245 %\n",
      "[[ 1.          4.53639847]\n",
      " [ 2.         15.89272031]\n",
      " [ 3.         11.81609195]\n",
      " [ 4.         42.8045977 ]\n",
      " [ 5.         24.95019157]]\n",
      "1 95.46360153256705\n",
      "2 84.10727969348659\n",
      "3 88.183908045977\n",
      "4 57.195402298850574\n",
      "5 75.04980842911877\n",
      "With 0.0 0.01 10 10  number of neighboors, the accuracy of the train model is 0.8141528925619834 % and the accuracy of the valid model is 0.2896551724137931 %\n",
      "[[ 1.          2.60536398]\n",
      " [ 2.         23.11111111]\n",
      " [ 3.         13.4559387 ]\n",
      " [ 4.         29.77777778]\n",
      " [ 5.         31.04980843]]\n",
      "1 97.39463601532567\n",
      "2 76.88888888888889\n",
      "3 86.544061302682\n",
      "4 70.22222222222221\n",
      "5 68.95019157088123\n",
      "With 0.0 0.01 10 50  number of neighboors, the accuracy of the train model is 0.8131198347107438 % and the accuracy of the valid model is 0.26375478927203067 %\n",
      "[[ 1.          7.60153257]\n",
      " [ 2.         18.651341  ]\n",
      " [ 3.         12.32183908]\n",
      " [ 4.         33.96168582]\n",
      " [ 5.         27.46360153]]\n",
      "1 92.3984674329502\n",
      "2 81.34865900383141\n",
      "3 87.67816091954023\n",
      "4 66.03831417624521\n",
      "5 72.53639846743295\n",
      "With 0.0 0.01 10 100  number of neighboors, the accuracy of the train model is 0.8586776859504133 % and the accuracy of the valid model is 0.2665134099616858 %\n",
      "[[ 1.          4.88888889]\n",
      " [ 2.         16.18390805]\n",
      " [ 3.         11.41762452]\n",
      " [ 4.         44.72030651]\n",
      " [ 5.         22.78927203]]\n",
      "1 95.11111111111111\n",
      "2 83.81609195402298\n",
      "3 88.5823754789272\n",
      "4 55.27969348659004\n",
      "5 77.21072796934865\n",
      "With 0.0 0.01 10 150  number of neighboors, the accuracy of the train model is 0.8024276859504132 % and the accuracy of the valid model is 0.28551724137931034 %\n",
      "[[ 1.          4.91954023]\n",
      " [ 2.         15.17241379]\n",
      " [ 3.          9.51724138]\n",
      " [ 4.         39.08045977]\n",
      " [ 5.         31.31034483]]\n",
      "1 95.08045977011494\n",
      "2 84.82758620689656\n",
      "3 90.48275862068965\n",
      "4 60.91954022988506\n",
      "5 68.6896551724138\n",
      "With 0.0 0.01 10 500  number of neighboors, the accuracy of the train model is 0.840702479338843 % and the accuracy of the valid model is 0.2754022988505747 %\n",
      "[[ 1.          2.29885057]\n",
      " [ 2.         17.37931034]\n",
      " [ 3.         11.75478927]\n",
      " [ 4.         37.8697318 ]\n",
      " [ 5.         30.69731801]]\n",
      "1 97.70114942528735\n",
      "2 82.62068965517241\n",
      "3 88.24521072796935\n",
      "4 62.13026819923372\n",
      "5 69.30268199233717\n",
      "With 0.0 0.01 20 10  number of neighboors, the accuracy of the train model is 0.8548037190082645 % and the accuracy of the valid model is 0.2686590038314176 %\n",
      "[[ 1.          6.49808429]\n",
      " [ 2.         16.68965517]\n",
      " [ 3.         10.49808429]\n",
      " [ 4.         34.05363985]\n",
      " [ 5.         32.2605364 ]]\n",
      "1 93.50191570881225\n",
      "2 83.3103448275862\n",
      "3 89.50191570881226\n",
      "4 65.9463601532567\n",
      "5 67.73946360153256\n",
      "With 0.0 0.01 20 50  number of neighboors, the accuracy of the train model is 0.8649793388429752 % and the accuracy of the valid model is 0.274176245210728 %\n",
      "[[ 1.          7.27969349]\n",
      " [ 2.         20.79693487]\n",
      " [ 3.         14.71264368]\n",
      " [ 4.         26.55938697]\n",
      " [ 5.         30.651341  ]]\n",
      "1 92.72030651340997\n",
      "2 79.20306513409962\n",
      "3 85.28735632183908\n",
      "4 73.44061302681992\n",
      "5 69.34865900383141\n",
      "With 0.0 0.01 20 100  number of neighboors, the accuracy of the train model is 0.8637913223140495 % and the accuracy of the valid model is 0.2872030651340996 %\n",
      "[[ 1.          5.88505747]\n",
      " [ 2.         16.4137931 ]\n",
      " [ 3.          7.38697318]\n",
      " [ 4.         34.36015326]\n",
      " [ 5.         35.95402299]]\n",
      "1 94.11494252873564\n",
      "2 83.58620689655173\n",
      "3 92.61302681992338\n",
      "4 65.63984674329501\n",
      "5 64.04597701149424\n",
      "With 0.0 0.01 20 150  number of neighboors, the accuracy of the train model is 0.8646177685950414 % and the accuracy of the valid model is 0.2700383141762452 %\n",
      "[[ 1.          4.24521073]\n",
      " [ 2.         16.04597701]\n",
      " [ 3.         14.36015326]\n",
      " [ 4.         32.53639847]\n",
      " [ 5.         32.81226054]]\n",
      "1 95.75478927203065\n",
      "2 83.95402298850576\n",
      "3 85.63984674329502\n",
      "4 67.46360153256705\n",
      "5 67.18773946360153\n",
      "With 0.0 0.01 20 500  number of neighboors, the accuracy of the train model is 0.8317665289256199 % and the accuracy of the valid model is 0.2910344827586207 %\n",
      "[[ 1.          2.46743295]\n",
      " [ 2.         16.96551724]\n",
      " [ 3.          9.33333333]\n",
      " [ 4.         34.22222222]\n",
      " [ 5.         37.01149425]]\n",
      "1 97.53256704980842\n",
      "2 83.03448275862068\n",
      "3 90.66666666666666\n",
      "4 65.77777777777779\n",
      "5 62.98850574712643\n",
      "With 0.0 0.01 30 10  number of neighboors, the accuracy of the train model is 0.8461260330578513 % and the accuracy of the valid model is 0.2603831417624521 %\n",
      "[[ 1.          3.66283525]\n",
      " [ 2.          8.85823755]\n",
      " [ 3.         24.9348659 ]\n",
      " [ 4.         35.60153257]\n",
      " [ 5.         26.94252874]]\n",
      "1 96.33716475095785\n",
      "2 91.14176245210727\n",
      "3 75.06513409961686\n",
      "4 64.39846743295018\n",
      "5 73.05747126436782\n",
      "With 0.0 0.01 30 50  number of neighboors, the accuracy of the train model is 0.8670454545454546 % and the accuracy of the valid model is 0.28153256704980845 %\n",
      "[[ 1.          5.05747126]\n",
      " [ 2.         16.61302682]\n",
      " [ 3.         14.23754789]\n",
      " [ 4.         32.64367816]\n",
      " [ 5.         31.44827586]]\n",
      "1 94.94252873563218\n",
      "2 83.38697318007662\n",
      "3 85.7624521072797\n",
      "4 67.35632183908045\n",
      "5 68.55172413793103\n",
      "With 0.0 0.01 30 100  number of neighboors, the accuracy of the train model is 0.8571280991735537 % and the accuracy of the valid model is 0.28980842911877397 %\n",
      "[[ 1.          3.3256705 ]\n",
      " [ 2.         19.03448276]\n",
      " [ 3.         13.8697318 ]\n",
      " [ 4.         38.23754789]\n",
      " [ 5.         25.53256705]]\n",
      "1 96.67432950191571\n",
      "2 80.96551724137932\n",
      "3 86.13026819923371\n",
      "4 61.7624521072797\n",
      "5 74.46743295019157\n",
      "With 0.0 0.01 30 150  number of neighboors, the accuracy of the train model is 0.856146694214876 % and the accuracy of the valid model is 0.2839846743295019 %\n",
      "[[ 1.          4.6743295 ]\n",
      " [ 2.         17.44061303]\n",
      " [ 3.         14.40613027]\n",
      " [ 4.         31.8467433 ]\n",
      " [ 5.         31.63218391]]\n",
      "1 95.32567049808429\n",
      "2 82.55938697318007\n",
      "3 85.59386973180077\n",
      "4 68.15325670498085\n",
      "5 68.36781609195403\n",
      "With 0.0 0.01 30 500  number of neighboors, the accuracy of the train model is 0.8598140495867769 % and the accuracy of the valid model is 0.28597701149425286 %\n",
      "[[ 1.          1.77777778]\n",
      " [ 2.         16.06130268]\n",
      " [ 3.         12.07662835]\n",
      " [ 4.         37.7164751 ]\n",
      " [ 5.         32.36781609]]\n",
      "1 98.22222222222223\n",
      "2 83.93869731800766\n",
      "3 87.92337164750957\n",
      "4 62.28352490421456\n",
      "5 67.63218390804597\n",
      "With 0.0 0.1 10 10  number of neighboors, the accuracy of the train model is 0.6972623966942149 % and the accuracy of the valid model is 0.27340996168582377 %\n",
      "[[ 1.          7.89272031]\n",
      " [ 2.         20.95019157]\n",
      " [ 3.         11.52490421]\n",
      " [ 4.         17.80842912]\n",
      " [ 5.         41.82375479]]\n",
      "1 92.10727969348659\n",
      "2 79.04980842911877\n",
      "3 88.47509578544062\n",
      "4 82.19157088122606\n",
      "5 58.17624521072797\n",
      "With 0.0 0.1 10 50  number of neighboors, the accuracy of the train model is 0.6848140495867768 % and the accuracy of the valid model is 0.266360153256705 %\n",
      "[[ 1.          5.37931034]\n",
      " [ 2.         18.45210728]\n",
      " [ 3.          8.39846743]\n",
      " [ 4.         30.60536398]\n",
      " [ 5.         37.16475096]]\n",
      "1 94.62068965517241\n",
      "2 81.54789272030652\n",
      "3 91.6015325670498\n",
      "4 69.39463601532567\n",
      "5 62.83524904214559\n",
      "With 0.0 0.1 10 100  number of neighboors, the accuracy of the train model is 0.656146694214876 % and the accuracy of the valid model is 0.2790804597701149 %\n",
      "[[ 1.          7.23371648]\n",
      " [ 2.         16.07662835]\n",
      " [ 3.         19.61685824]\n",
      " [ 4.         18.31417625]\n",
      " [ 5.         38.75862069]]\n",
      "1 92.76628352490421\n",
      "2 83.92337164750958\n",
      "3 80.3831417624521\n",
      "4 81.68582375478928\n",
      "5 61.241379310344826\n",
      "With 0.0 0.1 10 150  number of neighboors, the accuracy of the train model is 0.6665289256198347 % and the accuracy of the valid model is 0.2879693486590038 %\n",
      "[[ 1.          3.44827586]\n",
      " [ 2.         20.9348659 ]\n",
      " [ 3.         10.34482759]\n",
      " [ 4.         18.88122605]\n",
      " [ 5.         46.3908046 ]]\n",
      "1 96.55172413793103\n",
      "2 79.06513409961687\n",
      "3 89.65517241379311\n",
      "4 81.11877394636015\n",
      "5 53.60919540229885\n",
      "With 0.0 0.1 10 500  number of neighboors, the accuracy of the train model is 0.5340392561983471 % and the accuracy of the valid model is 0.3062068965517241 %\n",
      "[[ 1.          8.5210728 ]\n",
      " [ 2.         20.95019157]\n",
      " [ 3.         16.01532567]\n",
      " [ 4.         20.91954023]\n",
      " [ 5.         33.59386973]]\n",
      "1 91.47892720306513\n",
      "2 79.04980842911877\n",
      "3 83.98467432950191\n",
      "4 79.08045977011494\n",
      "5 66.40613026819923\n",
      "With 0.0 0.1 20 10  number of neighboors, the accuracy of the train model is 0.7791838842975206 % and the accuracy of the valid model is 0.27693486590038313 %\n",
      "[[ 1.          4.27586207]\n",
      " [ 2.         18.17624521]\n",
      " [ 3.         13.7164751 ]\n",
      " [ 4.         34.25287356]\n",
      " [ 5.         29.57854406]]\n",
      "1 95.72413793103448\n",
      "2 81.82375478927203\n",
      "3 86.28352490421456\n",
      "4 65.74712643678161\n",
      "5 70.42145593869732\n",
      "With 0.0 0.1 20 50  number of neighboors, the accuracy of the train model is 0.7455578512396694 % and the accuracy of the valid model is 0.2697318007662835 %\n",
      "[[ 1.          3.38697318]\n",
      " [ 2.         20.49042146]\n",
      " [ 3.         10.75862069]\n",
      " [ 4.         39.46360153]\n",
      " [ 5.         25.90038314]]\n",
      "1 96.61302681992338\n",
      "2 79.5095785440613\n",
      "3 89.24137931034483\n",
      "4 60.53639846743295\n",
      "5 74.09961685823755\n",
      "With 0.0 0.1 20 100  number of neighboors, the accuracy of the train model is 0.712603305785124 % and the accuracy of the valid model is 0.27770114942528734 %\n",
      "[[ 1.          2.71264368]\n",
      " [ 2.         17.40996169]\n",
      " [ 3.         21.28735632]\n",
      " [ 4.         21.27203065]\n",
      " [ 5.         37.31800766]]\n",
      "1 97.28735632183908\n",
      "2 82.59003831417625\n",
      "3 78.71264367816092\n",
      "4 78.727969348659\n",
      "5 62.68199233716475\n",
      "With 0.0 0.1 20 150  number of neighboors, the accuracy of the train model is 0.6703512396694215 % and the accuracy of the valid model is 0.26773946360153256 %\n",
      "[[ 1.          5.88505747]\n",
      " [ 2.         18.22222222]\n",
      " [ 3.         22.98850575]\n",
      " [ 4.         19.2183908 ]\n",
      " [ 5.         33.68582375]]\n",
      "1 94.11494252873564\n",
      "2 81.77777777777779\n",
      "3 77.01149425287356\n",
      "4 80.78160919540231\n",
      "5 66.31417624521073\n",
      "With 0.0 0.1 20 500  number of neighboors, the accuracy of the train model is 0.6102789256198347 % and the accuracy of the valid model is 0.28842911877394634 %\n",
      "[[ 1.          7.40229885]\n",
      " [ 2.         30.20689655]\n",
      " [ 3.          9.44061303]\n",
      " [ 4.         17.7164751 ]\n",
      " [ 5.         35.23371648]]\n",
      "1 92.59770114942528\n",
      "2 69.79310344827586\n",
      "3 90.55938697318008\n",
      "4 82.28352490421456\n",
      "5 64.76628352490421\n",
      "With 0.0 0.1 30 10  number of neighboors, the accuracy of the train model is 0.8038739669421487 % and the accuracy of the valid model is 0.282911877394636 %\n",
      "[[ 1.          3.37164751]\n",
      " [ 2.         18.86590038]\n",
      " [ 3.         12.88888889]\n",
      " [ 4.         20.19923372]\n",
      " [ 5.         44.6743295 ]]\n",
      "1 96.62835249042145\n",
      "2 81.13409961685824\n",
      "3 87.1111111111111\n",
      "4 79.80076628352491\n",
      "5 55.32567049808429\n",
      "With 0.0 0.1 30 50  number of neighboors, the accuracy of the train model is 0.765599173553719 % and the accuracy of the valid model is 0.27264367816091956 %\n",
      "[[ 1.          4.62835249]\n",
      " [ 2.         15.81609195]\n",
      " [ 3.         12.95019157]\n",
      " [ 4.         42.31417625]\n",
      " [ 5.         24.29118774]]\n",
      "1 95.37164750957854\n",
      "2 84.183908045977\n",
      "3 87.04980842911877\n",
      "4 57.68582375478927\n",
      "5 75.70881226053639\n",
      "With 0.0 0.1 30 100  number of neighboors, the accuracy of the train model is 0.6893595041322315 % and the accuracy of the valid model is 0.28229885057471266 %\n",
      "[[ 1.          3.96934866]\n",
      " [ 2.         17.8697318 ]\n",
      " [ 3.          8.84291188]\n",
      " [ 4.         28.30651341]\n",
      " [ 5.         41.01149425]]\n",
      "1 96.03065134099616\n",
      "2 82.13026819923371\n",
      "3 91.15708812260537\n",
      "4 71.69348659003832\n",
      "5 58.98850574712644\n",
      "With 0.0 0.1 30 150  number of neighboors, the accuracy of the train model is 0.6858987603305785 % and the accuracy of the valid model is 0.28260536398467434 %\n",
      "[[ 1.          5.16475096]\n",
      " [ 2.         19.27969349]\n",
      " [ 3.          7.80076628]\n",
      " [ 4.         43.34099617]\n",
      " [ 5.         24.4137931 ]]\n",
      "1 94.83524904214559\n",
      "2 80.72030651340995\n",
      "3 92.19923371647509\n",
      "4 56.65900383141762\n",
      "5 75.58620689655172\n",
      "With 0.0 0.1 30 500  number of neighboors, the accuracy of the train model is 0.5824896694214876 % and the accuracy of the valid model is 0.30482758620689654 %\n",
      "[[ 1.          5.24137931]\n",
      " [ 2.         21.82375479]\n",
      " [ 3.         13.53256705]\n",
      " [ 4.         17.73180077]\n",
      " [ 5.         41.67049808]]\n",
      "1 94.75862068965517\n",
      "2 78.17624521072797\n",
      "3 86.46743295019157\n",
      "4 82.26819923371647\n",
      "5 58.32950191570882\n",
      "With 0.5 0.001 10 10  number of neighboors, the accuracy of the train model is 0.756146694214876 % and the accuracy of the valid model is 0.2617624521072797 %\n",
      "[[ 1.         10.95785441]\n",
      " [ 2.         22.25287356]\n",
      " [ 3.          9.91570881]\n",
      " [ 4.         37.96168582]\n",
      " [ 5.         18.91187739]]\n",
      "1 89.04214559386973\n",
      "2 77.74712643678161\n",
      "3 90.08429118773947\n",
      "4 62.038314176245215\n",
      "5 81.08812260536399\n",
      "With 0.5 0.001 10 50  number of neighboors, the accuracy of the train model is 0.781353305785124 % and the accuracy of the valid model is 0.26773946360153256 %\n",
      "[[ 1.          8.03065134]\n",
      " [ 2.         22.51340996]\n",
      " [ 3.         14.8045977 ]\n",
      " [ 4.         36.38314176]\n",
      " [ 5.         18.26819923]]\n",
      "1 91.96934865900384\n",
      "2 77.48659003831418\n",
      "3 85.19540229885058\n",
      "4 63.61685823754789\n",
      "5 81.73180076628353\n",
      "With 0.5 0.001 10 100  number of neighboors, the accuracy of the train model is 0.7743801652892562 % and the accuracy of the valid model is 0.2631417624521073 %\n",
      "[[ 1.          9.93103448]\n",
      " [ 2.         24.06130268]\n",
      " [ 3.         13.53256705]\n",
      " [ 4.         39.35632184]\n",
      " [ 5.         13.11877395]]\n",
      "1 90.06896551724138\n",
      "2 75.93869731800767\n",
      "3 86.46743295019157\n",
      "4 60.64367816091954\n",
      "5 86.88122605363985\n",
      "With 0.5 0.001 10 150  number of neighboors, the accuracy of the train model is 0.7881714876033058 % and the accuracy of the valid model is 0.24919540229885057 %\n",
      "[[ 1.          8.12260536]\n",
      " [ 2.         18.77394636]\n",
      " [ 3.         16.50574713]\n",
      " [ 4.         41.79310345]\n",
      " [ 5.         14.8045977 ]]\n",
      "1 91.87739463601532\n",
      "2 81.22605363984674\n",
      "3 83.49425287356323\n",
      "4 58.20689655172414\n",
      "5 85.19540229885058\n",
      "With 0.5 0.001 10 500  number of neighboors, the accuracy of the train model is 0.7817148760330579 % and the accuracy of the valid model is 0.2668199233716475 %\n",
      "[[ 1.          4.49042146]\n",
      " [ 2.         21.67049808]\n",
      " [ 3.         15.77011494]\n",
      " [ 4.         41.85440613]\n",
      " [ 5.         16.21455939]]\n",
      "1 95.5095785440613\n",
      "2 78.3295019157088\n",
      "3 84.22988505747126\n",
      "4 58.145593869731805\n",
      "5 83.78544061302682\n",
      "With 0.5 0.001 20 10  number of neighboors, the accuracy of the train model is 0.7931818181818182 % and the accuracy of the valid model is 0.26406130268199235 %\n",
      "[[ 1.          8.19923372]\n",
      " [ 2.         22.88122605]\n",
      " [ 3.         16.50574713]\n",
      " [ 4.         34.45210728]\n",
      " [ 5.         17.96168582]]\n",
      "1 91.80076628352491\n",
      "2 77.11877394636015\n",
      "3 83.49425287356323\n",
      "4 65.5478927203065\n",
      "5 82.03831417624521\n",
      "With 0.5 0.001 20 50  number of neighboors, the accuracy of the train model is 0.7947830578512397 % and the accuracy of the valid model is 0.2668199233716475 %\n",
      "[[ 1.         11.46360153]\n",
      " [ 2.         22.22222222]\n",
      " [ 3.         14.62068966]\n",
      " [ 4.         34.46743295]\n",
      " [ 5.         17.22605364]]\n",
      "1 88.53639846743295\n",
      "2 77.77777777777779\n",
      "3 85.37931034482759\n",
      "4 65.53256704980843\n",
      "5 82.77394636015326\n",
      "With 0.5 0.001 20 100  number of neighboors, the accuracy of the train model is 0.7837809917355372 % and the accuracy of the valid model is 0.2590038314176245 %\n",
      "[[ 1.          8.33716475]\n",
      " [ 2.         23.46360153]\n",
      " [ 3.         10.11494253]\n",
      " [ 4.         42.52873563]\n",
      " [ 5.         15.55555556]]\n",
      "1 91.66283524904215\n",
      "2 76.53639846743296\n",
      "3 89.88505747126436\n",
      "4 57.47126436781609\n",
      "5 84.44444444444444\n",
      "With 0.5 0.001 20 150  number of neighboors, the accuracy of the train model is 0.8206095041322314 % and the accuracy of the valid model is 0.2574712643678161 %\n",
      "[[ 1.         10.2835249 ]\n",
      " [ 2.         21.56321839]\n",
      " [ 3.         13.82375479]\n",
      " [ 4.         38.97318008]\n",
      " [ 5.         15.35632184]]\n",
      "1 89.71647509578544\n",
      "2 78.4367816091954\n",
      "3 86.17624521072797\n",
      "4 61.02681992337165\n",
      "5 84.64367816091955\n",
      "With 0.5 0.001 20 500  number of neighboors, the accuracy of the train model is 0.8251033057851239 % and the accuracy of the valid model is 0.2636015325670498 %\n",
      "[[ 1.          9.07279693]\n",
      " [ 2.         20.73563218]\n",
      " [ 3.         15.00383142]\n",
      " [ 4.         38.94252874]\n",
      " [ 5.         16.24521073]]\n",
      "1 90.9272030651341\n",
      "2 79.26436781609195\n",
      "3 84.99616858237547\n",
      "4 61.05747126436781\n",
      "5 83.75478927203065\n",
      "With 0.5 0.001 30 10  number of neighboors, the accuracy of the train model is 0.8067148760330578 % and the accuracy of the valid model is 0.2617624521072797 %\n",
      "[[ 1.         12.50574713]\n",
      " [ 2.         23.5862069 ]\n",
      " [ 3.         11.43295019]\n",
      " [ 4.         32.9348659 ]\n",
      " [ 5.         19.54022989]]\n",
      "1 87.49425287356321\n",
      "2 76.41379310344828\n",
      "3 88.56704980842912\n",
      "4 67.06513409961687\n",
      "5 80.45977011494253\n",
      "With 0.5 0.001 30 50  number of neighboors, the accuracy of the train model is 0.831456611570248 % and the accuracy of the valid model is 0.2816858237547893 %\n",
      "[[ 1.          5.348659  ]\n",
      " [ 2.         27.90804598]\n",
      " [ 3.         10.68199234]\n",
      " [ 4.         41.70114943]\n",
      " [ 5.         14.36015326]]\n",
      "1 94.65134099616859\n",
      "2 72.0919540229885\n",
      "3 89.31800766283526\n",
      "4 58.298850574712645\n",
      "5 85.63984674329502\n",
      "With 0.5 0.001 30 100  number of neighboors, the accuracy of the train model is 0.8463842975206611 % and the accuracy of the valid model is 0.2671264367816092 %\n",
      "[[ 1.          6.46743295]\n",
      " [ 2.         21.82375479]\n",
      " [ 3.         15.01915709]\n",
      " [ 4.         43.2183908 ]\n",
      " [ 5.         13.47126437]]\n",
      "1 93.53256704980842\n",
      "2 78.17624521072797\n",
      "3 84.9808429118774\n",
      "4 56.7816091954023\n",
      "5 86.52873563218391\n",
      "With 0.5 0.001 30 150  number of neighboors, the accuracy of the train model is 0.8375 % and the accuracy of the valid model is 0.2603831417624521 %\n",
      "[[ 1.          7.92337165]\n",
      " [ 2.         21.47126437]\n",
      " [ 3.         13.99233716]\n",
      " [ 4.         41.28735632]\n",
      " [ 5.         15.3256705 ]]\n",
      "1 92.07662835249042\n",
      "2 78.52873563218391\n",
      "3 86.00766283524905\n",
      "4 58.712643678160916\n",
      "5 84.67432950191571\n",
      "With 0.5 0.001 30 500  number of neighboors, the accuracy of the train model is 0.8464876033057851 % and the accuracy of the valid model is 0.25992337164750956 %\n",
      "[[ 1.          9.18007663]\n",
      " [ 2.         23.03448276]\n",
      " [ 3.         13.50191571]\n",
      " [ 4.         42.29885057]\n",
      " [ 5.         11.98467433]]\n",
      "1 90.8199233716475\n",
      "2 76.96551724137932\n",
      "3 86.49808429118774\n",
      "4 57.701149425287355\n",
      "5 88.01532567049807\n",
      "With 0.5 0.01 10 10  number of neighboors, the accuracy of the train model is 0.7022727272727273 % and the accuracy of the valid model is 0.3206130268199234 %\n",
      "[[ 1.         10.63601533]\n",
      " [ 2.         33.76245211]\n",
      " [ 3.         13.67049808]\n",
      " [ 4.         20.73563218]\n",
      " [ 5.         21.1954023 ]]\n",
      "1 89.3639846743295\n",
      "2 66.2375478927203\n",
      "3 86.32950191570882\n",
      "4 79.26436781609195\n",
      "5 78.80459770114942\n",
      "With 0.5 0.01 10 50  number of neighboors, the accuracy of the train model is 0.7419938016528925 % and the accuracy of the valid model is 0.2988505747126437 %\n",
      "[[ 1.          6.77394636]\n",
      " [ 2.         31.3256705 ]\n",
      " [ 3.         16.2605364 ]\n",
      " [ 4.         27.57088123]\n",
      " [ 5.         18.06896552]]\n",
      "1 93.22605363984674\n",
      "2 68.67432950191571\n",
      "3 83.73946360153258\n",
      "4 72.42911877394636\n",
      "5 81.93103448275862\n",
      "With 0.5 0.01 10 100  number of neighboors, the accuracy of the train model is 0.7465909090909091 % and the accuracy of the valid model is 0.26881226053639845 %\n",
      "[[ 1.          8.38314176]\n",
      " [ 2.         22.26819923]\n",
      " [ 3.         20.29118774]\n",
      " [ 4.         29.90038314]\n",
      " [ 5.         19.15708812]]\n",
      "1 91.61685823754789\n",
      "2 77.73180076628353\n",
      "3 79.7088122605364\n",
      "4 70.09961685823754\n",
      "5 80.84291187739464\n",
      "With 0.5 0.01 10 150  number of neighboors, the accuracy of the train model is 0.7285640495867769 % and the accuracy of the valid model is 0.2704980842911877 %\n",
      "[[ 1.          9.85440613]\n",
      " [ 2.         20.85823755]\n",
      " [ 3.         16.09195402]\n",
      " [ 4.         35.4789272 ]\n",
      " [ 5.         17.7164751 ]]\n",
      "1 90.1455938697318\n",
      "2 79.14176245210727\n",
      "3 83.9080459770115\n",
      "4 64.52107279693486\n",
      "5 82.28352490421456\n",
      "With 0.5 0.01 10 500  number of neighboors, the accuracy of the train model is 0.7393078512396695 % and the accuracy of the valid model is 0.29226053639846744 %\n",
      "[[ 1.          6.26819923]\n",
      " [ 2.         27.14176245]\n",
      " [ 3.         15.35632184]\n",
      " [ 4.         28.98084291]\n",
      " [ 5.         22.25287356]]\n",
      "1 93.73180076628353\n",
      "2 72.85823754789273\n",
      "3 84.64367816091955\n",
      "4 71.01915708812261\n",
      "5 77.74712643678161\n",
      "With 0.5 0.01 20 10  number of neighboors, the accuracy of the train model is 0.7692665289256199 % and the accuracy of the valid model is 0.31386973180076627 %\n",
      "[[ 1.         13.27203065]\n",
      " [ 2.         27.15708812]\n",
      " [ 3.         13.59386973]\n",
      " [ 4.         19.11111111]\n",
      " [ 5.         26.86590038]]\n",
      "1 86.727969348659\n",
      "2 72.84291187739463\n",
      "3 86.40613026819923\n",
      "4 80.88888888888889\n",
      "5 73.13409961685824\n",
      "With 0.5 0.01 20 50  number of neighboors, the accuracy of the train model is 0.7691632231404959 % and the accuracy of the valid model is 0.2976245210727969 %\n",
      "[[ 1.          6.89655172]\n",
      " [ 2.         24.2605364 ]\n",
      " [ 3.         14.1302682 ]\n",
      " [ 4.         32.72030651]\n",
      " [ 5.         21.99233716]]\n",
      "1 93.10344827586206\n",
      "2 75.73946360153256\n",
      "3 85.86973180076627\n",
      "4 67.27969348659005\n",
      "5 78.00766283524905\n",
      "With 0.5 0.01 20 100  number of neighboors, the accuracy of the train model is 0.781301652892562 % and the accuracy of the valid model is 0.2803065134099617 %\n",
      "[[ 1.          6.88122605]\n",
      " [ 2.         21.47126437]\n",
      " [ 3.         10.08429119]\n",
      " [ 4.         47.86206897]\n",
      " [ 5.         13.70114943]]\n",
      "1 93.11877394636015\n",
      "2 78.52873563218391\n",
      "3 89.91570881226055\n",
      "4 52.137931034482754\n",
      "5 86.29885057471265\n",
      "With 0.5 0.01 20 150  number of neighboors, the accuracy of the train model is 0.759607438016529 % and the accuracy of the valid model is 0.2665134099616858 %\n",
      "[[ 1.          6.97318008]\n",
      " [ 2.          3.01915709]\n",
      " [ 3.         36.39846743]\n",
      " [ 4.         35.60153257]\n",
      " [ 5.         18.00766284]]\n",
      "1 93.02681992337165\n",
      "2 96.9808429118774\n",
      "3 63.601532567049816\n",
      "4 64.39846743295018\n",
      "5 81.99233716475096\n",
      "With 0.5 0.01 20 500  number of neighboors, the accuracy of the train model is 0.7764979338842976 % and the accuracy of the valid model is 0.28229885057471266 %\n",
      "[[ 1.         11.63218391]\n",
      " [ 2.         28.82758621]\n",
      " [ 3.         14.89655172]\n",
      " [ 4.         29.16475096]\n",
      " [ 5.         15.4789272 ]]\n",
      "1 88.36781609195403\n",
      "2 71.17241379310344\n",
      "3 85.10344827586206\n",
      "4 70.83524904214559\n",
      "5 84.52107279693487\n",
      "With 0.5 0.01 30 10  number of neighboors, the accuracy of the train model is 0.7901859504132231 % and the accuracy of the valid model is 0.28444444444444444 %\n",
      "[[ 1.          7.17241379]\n",
      " [ 2.         24.84291188]\n",
      " [ 3.         14.77394636]\n",
      " [ 4.         40.56704981]\n",
      " [ 5.         12.64367816]]\n",
      "1 92.82758620689656\n",
      "2 75.15708812260536\n",
      "3 85.22605363984674\n",
      "4 59.432950191570875\n",
      "5 87.35632183908046\n",
      "With 0.5 0.01 30 50  number of neighboors, the accuracy of the train model is 0.7762396694214876 % and the accuracy of the valid model is 0.27555555555555555 %\n",
      "[[ 1.          6.05363985]\n",
      " [ 2.         22.20689655]\n",
      " [ 3.         17.13409962]\n",
      " [ 4.         39.57088123]\n",
      " [ 5.         15.03448276]]\n",
      "1 93.9463601532567\n",
      "2 77.79310344827586\n",
      "3 82.86590038314176\n",
      "4 60.42911877394636\n",
      "5 84.9655172413793\n",
      "With 0.5 0.01 30 100  number of neighboors, the accuracy of the train model is 0.7887396694214877 % and the accuracy of the valid model is 0.2593103448275862 %\n",
      "[[ 1.          8.42911877]\n",
      " [ 2.         20.12260536]\n",
      " [ 3.         17.10344828]\n",
      " [ 4.         42.59003831]\n",
      " [ 5.         11.75478927]]\n",
      "1 91.57088122605363\n",
      "2 79.87739463601532\n",
      "3 82.89655172413794\n",
      "4 57.40996168582375\n",
      "5 88.24521072796935\n",
      "With 0.5 0.01 30 150  number of neighboors, the accuracy of the train model is 0.7852272727272728 % and the accuracy of the valid model is 0.28735632183908044 %\n",
      "[[ 1.          4.2605364 ]\n",
      " [ 2.         26.78927203]\n",
      " [ 3.         17.73180077]\n",
      " [ 4.         36.58237548]\n",
      " [ 5.         14.63601533]]\n",
      "1 95.73946360153258\n",
      "2 73.21072796934865\n",
      "3 82.26819923371647\n",
      "4 63.4176245210728\n",
      "5 85.3639846743295\n",
      "With 0.5 0.01 30 500  number of neighboors, the accuracy of the train model is 0.7816115702479339 % and the accuracy of the valid model is 0.28904214559386976 %\n",
      "[[ 1.          5.80842912]\n",
      " [ 2.         24.39846743]\n",
      " [ 3.         16.96551724]\n",
      " [ 4.         33.44061303]\n",
      " [ 5.         19.38697318]]\n",
      "1 94.19157088122606\n",
      "2 75.60153256704982\n",
      "3 83.03448275862068\n",
      "4 66.55938697318008\n",
      "5 80.61302681992338\n",
      "With 0.5 0.1 10 10  number of neighboors, the accuracy of the train model is 0.5115185950413224 % and the accuracy of the valid model is 0.304367816091954 %\n",
      "[[ 1.          7.63218391]\n",
      " [ 2.         39.7394636 ]\n",
      " [ 3.         18.72796935]\n",
      " [ 4.         12.22988506]\n",
      " [ 5.         21.67049808]]\n",
      "1 92.36781609195403\n",
      "2 60.26053639846744\n",
      "3 81.272030651341\n",
      "4 87.77011494252874\n",
      "5 78.3295019157088\n",
      "With 0.5 0.1 10 50  number of neighboors, the accuracy of the train model is 0.5142561983471075 % and the accuracy of the valid model is 0.29195402298850576 %\n",
      "[[ 1.          6.43678161]\n",
      " [ 2.         29.04214559]\n",
      " [ 3.         33.73180077]\n",
      " [ 4.          4.79693487]\n",
      " [ 5.         25.99233716]]\n",
      "1 93.5632183908046\n",
      "2 70.95785440613027\n",
      "3 66.26819923371647\n",
      "4 95.20306513409962\n",
      "5 74.00766283524905\n",
      "With 0.5 0.1 10 100  number of neighboors, the accuracy of the train model is 0.5085743801652892 % and the accuracy of the valid model is 0.2947126436781609 %\n",
      "[[ 1.          9.82375479]\n",
      " [ 2.         33.40996169]\n",
      " [ 3.         27.95402299]\n",
      " [ 4.         10.02298851]\n",
      " [ 5.         18.78927203]]\n",
      "1 90.17624521072797\n",
      "2 66.59003831417624\n",
      "3 72.04597701149426\n",
      "4 89.97701149425288\n",
      "5 81.21072796934867\n",
      "With 0.5 0.1 10 150  number of neighboors, the accuracy of the train model is 0.2 % and the accuracy of the valid model is 0.2 %\n",
      "[[  1. 100.]]\n",
      "1 0.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 100.0\n",
      "With 0.5 0.1 10 500  number of neighboors, the accuracy of the train model is 0.2 % and the accuracy of the valid model is 0.2 %\n",
      "[[  2. 100.]]\n",
      "1 100.0\n",
      "2 0.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 100.0\n",
      "With 0.5 0.1 20 10  number of neighboors, the accuracy of the train model is 0.5208161157024793 % and the accuracy of the valid model is 0.29011494252873565 %\n",
      "[[ 1.         24.82758621]\n",
      " [ 2.         35.09578544]\n",
      " [ 3.         21.68582375]\n",
      " [ 4.          4.81226054]\n",
      " [ 5.         13.57854406]]\n",
      "1 75.17241379310344\n",
      "2 64.90421455938697\n",
      "3 78.31417624521073\n",
      "4 95.18773946360153\n",
      "5 86.42145593869732\n",
      "With 0.5 0.1 20 50  number of neighboors, the accuracy of the train model is 0.5480371900826446 % and the accuracy of the valid model is 0.27846743295019155 %\n",
      "[[ 1.         10.31417625]\n",
      " [ 2.         37.63984674]\n",
      " [ 3.         31.14176245]\n",
      " [ 4.          9.62452107]\n",
      " [ 5.         11.27969349]]\n",
      "1 89.68582375478927\n",
      "2 62.360153256704976\n",
      "3 68.85823754789271\n",
      "4 90.37547892720306\n",
      "5 88.72030651340997\n",
      "With 0.5 0.1 20 100  number of neighboors, the accuracy of the train model is 0.4881714876033058 % and the accuracy of the valid model is 0.2853639846743295 %\n",
      "[[ 1.         13.21072797]\n",
      " [ 2.         52.09195402]\n",
      " [ 4.         15.46360153]\n",
      " [ 5.         19.23371648]]\n",
      "1 86.78927203065135\n",
      "2 47.90804597701149\n",
      "3 100.0\n",
      "4 84.53639846743295\n",
      "5 80.76628352490421\n",
      "With 0.5 0.1 20 150  number of neighboors, the accuracy of the train model is 0.5442148760330578 % and the accuracy of the valid model is 0.30482758620689654 %\n",
      "[[ 1.         15.24904215]\n",
      " [ 2.         30.51340996]\n",
      " [ 3.         29.59386973]\n",
      " [ 4.          7.63218391]\n",
      " [ 5.         17.01149425]]\n",
      "1 84.75095785440612\n",
      "2 69.48659003831418\n",
      "3 70.40613026819923\n",
      "4 92.36781609195403\n",
      "5 82.98850574712644\n",
      "With 0.5 0.1 20 500  number of neighboors, the accuracy of the train model is 0.4409090909090909 % and the accuracy of the valid model is 0.27080459770114945 %\n",
      "[[ 1.         22.81992337]\n",
      " [ 3.         55.34099617]\n",
      " [ 5.         21.83908046]]\n",
      "1 77.1800766283525\n",
      "2 100.0\n",
      "3 44.65900383141763\n",
      "4 100.0\n",
      "5 78.16091954022988\n",
      "With 0.5 0.1 30 10  number of neighboors, the accuracy of the train model is 0.518853305785124 % and the accuracy of the valid model is 0.26191570881226056 %\n",
      "[[ 1.         23.60153257]\n",
      " [ 2.         35.23371648]\n",
      " [ 3.         12.09195402]\n",
      " [ 4.         15.43295019]\n",
      " [ 5.         13.63984674]]\n",
      "1 76.39846743295018\n",
      "2 64.76628352490421\n",
      "3 87.9080459770115\n",
      "4 84.56704980842912\n",
      "5 86.36015325670499\n",
      "With 0.5 0.1 30 50  number of neighboors, the accuracy of the train model is 0.5213326446280991 % and the accuracy of the valid model is 0.29747126436781607 %\n",
      "[[ 1.         10.98850575]\n",
      " [ 2.         43.12643678]\n",
      " [ 3.         19.67816092]\n",
      " [ 4.          7.34099617]\n",
      " [ 5.         18.86590038]]\n",
      "1 89.01149425287358\n",
      "2 56.8735632183908\n",
      "3 80.32183908045977\n",
      "4 92.65900383141762\n",
      "5 81.13409961685824\n",
      "With 0.5 0.1 30 100  number of neighboors, the accuracy of the train model is 0.5079028925619835 % and the accuracy of the valid model is 0.2942528735632184 %\n",
      "[[ 1.          9.10344828]\n",
      " [ 2.         29.65517241]\n",
      " [ 3.         25.01149425]\n",
      " [ 4.         10.11494253]\n",
      " [ 5.         26.11494253]]\n",
      "1 90.89655172413794\n",
      "2 70.34482758620689\n",
      "3 74.98850574712644\n",
      "4 89.88505747126436\n",
      "5 73.88505747126437\n",
      "With 0.5 0.1 30 150  number of neighboors, the accuracy of the train model is 0.4836776859504132 % and the accuracy of the valid model is 0.29042145593869734 %\n",
      "[[ 1.         13.91570881]\n",
      " [ 2.         44.        ]\n",
      " [ 3.          4.59770115]\n",
      " [ 4.         20.09195402]\n",
      " [ 5.         17.39463602]]\n",
      "1 86.08429118773945\n",
      "2 56.00000000000001\n",
      "3 95.40229885057471\n",
      "4 79.9080459770115\n",
      "5 82.60536398467433\n",
      "With 0.5 0.1 30 500  number of neighboors, the accuracy of the train model is 0.45258264462809916 % and the accuracy of the valid model is 0.29900383141762454 %\n",
      "[[ 1.         12.35249042]\n",
      " [ 2.         58.83524904]\n",
      " [ 4.         12.61302682]\n",
      " [ 5.         16.19923372]]\n",
      "1 87.64750957854406\n",
      "2 41.16475095785441\n",
      "3 100.0\n",
      "4 87.38697318007664\n",
      "5 83.80076628352491\n",
      "With 1.0 0.001 10 10  number of neighboors, the accuracy of the train model is 0.7235537190082645 % and the accuracy of the valid model is 0.296551724137931 %\n",
      "[[ 1.         12.9348659 ]\n",
      " [ 2.         27.14176245]\n",
      " [ 3.          9.36398467]\n",
      " [ 4.         29.33333333]\n",
      " [ 5.         21.22605364]]\n",
      "1 87.06513409961686\n",
      "2 72.85823754789273\n",
      "3 90.6360153256705\n",
      "4 70.66666666666667\n",
      "5 78.77394636015326\n",
      "With 1.0 0.001 10 50  number of neighboors, the accuracy of the train model is 0.7464359504132232 % and the accuracy of the valid model is 0.26222222222222225 %\n",
      "[[ 1.          9.50191571]\n",
      " [ 2.         23.66283525]\n",
      " [ 3.         16.44444444]\n",
      " [ 4.         36.75095785]\n",
      " [ 5.         13.63984674]]\n",
      "1 90.49808429118774\n",
      "2 76.33716475095785\n",
      "3 83.55555555555556\n",
      "4 63.24904214559387\n",
      "5 86.36015325670499\n",
      "With 1.0 0.001 10 100  number of neighboors, the accuracy of the train model is 0.7263429752066116 % and the accuracy of the valid model is 0.25885057471264367 %\n",
      "[[ 1.         10.19157088]\n",
      " [ 2.         25.96168582]\n",
      " [ 3.         15.3256705 ]\n",
      " [ 4.         36.07662835]\n",
      " [ 5.         12.44444444]]\n",
      "1 89.80842911877394\n",
      "2 74.03831417624521\n",
      "3 84.67432950191571\n",
      "4 63.923371647509576\n",
      "5 87.55555555555556\n",
      "With 1.0 0.001 10 150  number of neighboors, the accuracy of the train model is 0.7490185950413223 % and the accuracy of the valid model is 0.25808429118773946 %\n",
      "[[ 1.         10.74329502]\n",
      " [ 2.         20.49042146]\n",
      " [ 3.         16.33716475]\n",
      " [ 4.         39.86206897]\n",
      " [ 5.         12.56704981]]\n",
      "1 89.25670498084291\n",
      "2 79.5095785440613\n",
      "3 83.66283524904215\n",
      "4 60.13793103448276\n",
      "5 87.43295019157088\n",
      "With 1.0 0.001 10 500  number of neighboors, the accuracy of the train model is 0.7339876033057852 % and the accuracy of the valid model is 0.2611494252873563 %\n",
      "[[ 1.          6.46743295]\n",
      " [ 2.         23.24904215]\n",
      " [ 3.         19.17241379]\n",
      " [ 4.         37.02681992]\n",
      " [ 5.         14.08429119]]\n",
      "1 93.53256704980842\n",
      "2 76.75095785440614\n",
      "3 80.82758620689656\n",
      "4 62.97318007662835\n",
      "5 85.91570881226053\n",
      "With 1.0 0.001 20 10  number of neighboors, the accuracy of the train model is 0.7607954545454545 % and the accuracy of the valid model is 0.2942528735632184 %\n",
      "[[ 1.          8.7816092 ]\n",
      " [ 2.         29.31800766]\n",
      " [ 3.         13.94636015]\n",
      " [ 4.         30.75862069]\n",
      " [ 5.         17.1954023 ]]\n",
      "1 91.2183908045977\n",
      "2 70.68199233716476\n",
      "3 86.0536398467433\n",
      "4 69.24137931034483\n",
      "5 82.80459770114943\n",
      "With 1.0 0.001 20 50  number of neighboors, the accuracy of the train model is 0.7712293388429752 % and the accuracy of the valid model is 0.28551724137931034 %\n",
      "[[ 1.          8.12260536]\n",
      " [ 2.         32.13793103]\n",
      " [ 3.         13.11877395]\n",
      " [ 4.         30.34482759]\n",
      " [ 5.         16.27586207]]\n",
      "1 91.87739463601532\n",
      "2 67.86206896551724\n",
      "3 86.88122605363985\n",
      "4 69.6551724137931\n",
      "5 83.72413793103448\n",
      "With 1.0 0.001 20 100  number of neighboors, the accuracy of the train model is 0.7573863636363637 % and the accuracy of the valid model is 0.2704980842911877 %\n",
      "[[ 1.          8.50574713]\n",
      " [ 2.         26.14559387]\n",
      " [ 3.         14.1302682 ]\n",
      " [ 4.         37.63984674]\n",
      " [ 5.         13.57854406]]\n",
      "1 91.49425287356323\n",
      "2 73.8544061302682\n",
      "3 85.86973180076627\n",
      "4 62.360153256704976\n",
      "5 86.42145593869732\n",
      "With 1.0 0.001 20 150  number of neighboors, the accuracy of the train model is 0.784400826446281 % and the accuracy of the valid model is 0.2694252873563218 %\n",
      "[[ 1.          6.83524904]\n",
      " [ 2.         25.97701149]\n",
      " [ 3.         18.3908046 ]\n",
      " [ 4.         36.64367816]\n",
      " [ 5.         12.1532567 ]]\n",
      "1 93.16475095785441\n",
      "2 74.02298850574712\n",
      "3 81.60919540229885\n",
      "4 63.356321839080465\n",
      "5 87.84674329501915\n",
      "With 1.0 0.001 20 500  number of neighboors, the accuracy of the train model is 0.7786673553719008 % and the accuracy of the valid model is 0.28842911877394634 %\n",
      "[[ 1.         12.82758621]\n",
      " [ 2.         25.68582375]\n",
      " [ 3.         12.53639847]\n",
      " [ 4.         31.38697318]\n",
      " [ 5.         17.56321839]]\n",
      "1 87.17241379310346\n",
      "2 74.31417624521073\n",
      "3 87.46360153256705\n",
      "4 68.61302681992338\n",
      "5 82.43678160919539\n",
      "With 1.0 0.001 30 10  number of neighboors, the accuracy of the train model is 0.7852272727272728 % and the accuracy of the valid model is 0.2796934865900383 %\n",
      "[[ 1.          7.75478927]\n",
      " [ 2.         23.20306513]\n",
      " [ 3.         19.78544061]\n",
      " [ 4.         32.06130268]\n",
      " [ 5.         17.1954023 ]]\n",
      "1 92.24521072796935\n",
      "2 76.79693486590038\n",
      "3 80.21455938697318\n",
      "4 67.93869731800767\n",
      "5 82.80459770114943\n",
      "With 1.0 0.001 30 50  number of neighboors, the accuracy of the train model is 0.7976756198347107 % and the accuracy of the valid model is 0.28076628352490424 %\n",
      "[[ 1.          9.56321839]\n",
      " [ 2.         22.59003831]\n",
      " [ 3.         15.78544061]\n",
      " [ 4.         35.63218391]\n",
      " [ 5.         16.42911877]]\n",
      "1 90.4367816091954\n",
      "2 77.40996168582376\n",
      "3 84.21455938697318\n",
      "4 64.36781609195403\n",
      "5 83.57088122605364\n",
      "With 1.0 0.001 30 100  number of neighboors, the accuracy of the train model is 0.7458677685950413 % and the accuracy of the valid model is 0.27019157088122603 %\n",
      "[[ 1.         10.09961686]\n",
      " [ 2.         24.35249042]\n",
      " [ 3.         14.06896552]\n",
      " [ 4.         37.1954023 ]\n",
      " [ 5.         14.2835249 ]]\n",
      "1 89.90038314176245\n",
      "2 75.64750957854406\n",
      "3 85.93103448275862\n",
      "4 62.804597701149426\n",
      "5 85.71647509578544\n",
      "With 1.0 0.001 30 150  number of neighboors, the accuracy of the train model is 0.8033057851239669 % and the accuracy of the valid model is 0.27739463601532566 %\n",
      "[[ 1.          6.75862069]\n",
      " [ 2.         28.44444444]\n",
      " [ 3.         15.54022989]\n",
      " [ 4.         36.70498084]\n",
      " [ 5.         12.55172414]]\n",
      "1 93.24137931034483\n",
      "2 71.55555555555554\n",
      "3 84.45977011494253\n",
      "4 63.29501915708812\n",
      "5 87.44827586206897\n",
      "With 1.0 0.001 30 500  number of neighboors, the accuracy of the train model is 0.7730371900826446 % and the accuracy of the valid model is 0.2700383141762452 %\n",
      "[[ 1.          9.16475096]\n",
      " [ 2.         24.6743295 ]\n",
      " [ 3.         17.05747126]\n",
      " [ 4.         35.61685824]\n",
      " [ 5.         13.48659004]]\n",
      "1 90.83524904214559\n",
      "2 75.32567049808429\n",
      "3 82.94252873563218\n",
      "4 64.38314176245211\n",
      "5 86.51340996168582\n",
      "With 1.0 0.01 10 10  number of neighboors, the accuracy of the train model is 0.6776859504132231 % and the accuracy of the valid model is 0.3124904214559387 %\n",
      "[[ 1.          6.08429119]\n",
      " [ 2.         27.87739464]\n",
      " [ 3.         10.06896552]\n",
      " [ 4.         36.81226054]\n",
      " [ 5.         19.15708812]]\n",
      "1 93.91570881226053\n",
      "2 72.12260536398468\n",
      "3 89.93103448275862\n",
      "4 63.18773946360153\n",
      "5 80.84291187739464\n",
      "With 1.0 0.01 10 50  number of neighboors, the accuracy of the train model is 0.6875 % and the accuracy of the valid model is 0.2899616858237548 %\n",
      "[[ 1.         12.99616858]\n",
      " [ 2.         21.83908046]\n",
      " [ 3.         26.63601533]\n",
      " [ 4.         24.10727969]\n",
      " [ 5.         14.42145594]]\n",
      "1 87.00383141762453\n",
      "2 78.16091954022988\n",
      "3 73.3639846743295\n",
      "4 75.89272030651341\n",
      "5 85.57854406130268\n",
      "With 1.0 0.01 10 100  number of neighboors, the accuracy of the train model is 0.6982954545454545 % and the accuracy of the valid model is 0.26911877394636013 %\n",
      "[[ 1.          8.5210728 ]\n",
      " [ 2.         35.41762452]\n",
      " [ 3.         17.7164751 ]\n",
      " [ 4.         24.95019157]\n",
      " [ 5.         13.39463602]]\n",
      "1 91.47892720306513\n",
      "2 64.5823754789272\n",
      "3 82.28352490421456\n",
      "4 75.04980842911877\n",
      "5 86.60536398467433\n",
      "With 1.0 0.01 10 150  number of neighboors, the accuracy of the train model is 0.6917355371900826 % and the accuracy of the valid model is 0.28704980842911876 %\n",
      "[[ 1.         10.94252874]\n",
      " [ 2.         26.43678161]\n",
      " [ 3.         20.04597701]\n",
      " [ 4.         24.82758621]\n",
      " [ 5.         17.74712644]]\n",
      "1 89.05747126436782\n",
      "2 73.5632183908046\n",
      "3 79.95402298850574\n",
      "4 75.17241379310344\n",
      "5 82.25287356321839\n",
      "With 1.0 0.01 10 500  number of neighboors, the accuracy of the train model is 0.7097623966942149 % and the accuracy of the valid model is 0.2976245210727969 %\n",
      "[[ 1.          6.1302682 ]\n",
      " [ 2.         28.90421456]\n",
      " [ 3.         24.91954023]\n",
      " [ 4.         23.04980843]\n",
      " [ 5.         16.99616858]]\n",
      "1 93.86973180076629\n",
      "2 71.09578544061303\n",
      "3 75.08045977011494\n",
      "4 76.95019157088122\n",
      "5 83.00383141762453\n",
      "With 1.0 0.01 20 10  number of neighboors, the accuracy of the train model is 0.7268078512396694 % and the accuracy of the valid model is 0.3117241379310345 %\n",
      "[[ 1.          3.7394636 ]\n",
      " [ 2.         34.19157088]\n",
      " [ 3.         21.08812261]\n",
      " [ 4.         25.90038314]\n",
      " [ 5.         15.08045977]]\n",
      "1 96.26053639846744\n",
      "2 65.80842911877394\n",
      "3 78.91187739463602\n",
      "4 74.09961685823755\n",
      "5 84.91954022988506\n",
      "With 1.0 0.01 20 50  number of neighboors, the accuracy of the train model is 0.7217458677685951 % and the accuracy of the valid model is 0.31386973180076627 %\n",
      "[[ 1.         17.27203065]\n",
      " [ 2.         30.34482759]\n",
      " [ 3.         14.29885057]\n",
      " [ 4.         19.23371648]\n",
      " [ 5.         18.85057471]]\n",
      "1 82.727969348659\n",
      "2 69.6551724137931\n",
      "3 85.70114942528735\n",
      "4 80.76628352490421\n",
      "5 81.14942528735632\n",
      "With 1.0 0.01 20 100  number of neighboors, the accuracy of the train model is 0.715599173553719 % and the accuracy of the valid model is 0.2928735632183908 %\n",
      "[[ 1.          7.69348659]\n",
      " [ 2.         35.57088123]\n",
      " [ 3.         16.50574713]\n",
      " [ 4.         26.40613027]\n",
      " [ 5.         13.82375479]]\n",
      "1 92.30651340996168\n",
      "2 64.42911877394636\n",
      "3 83.49425287356323\n",
      "4 73.59386973180077\n",
      "5 86.17624521072797\n",
      "With 1.0 0.01 20 150  number of neighboors, the accuracy of the train model is 0.7215392561983471 % and the accuracy of the valid model is 0.2910344827586207 %\n",
      "[[ 1.          7.98467433]\n",
      " [ 2.         30.69731801]\n",
      " [ 3.         25.74712644]\n",
      " [ 4.         21.4559387 ]\n",
      " [ 5.         14.11494253]]\n",
      "1 92.01532567049809\n",
      "2 69.30268199233717\n",
      "3 74.25287356321839\n",
      "4 78.544061302682\n",
      "5 85.88505747126437\n",
      "With 1.0 0.01 20 500  number of neighboors, the accuracy of the train model is 0.7101239669421487 % and the accuracy of the valid model is 0.29409961685823754 %\n",
      "[[ 1.          8.99616858]\n",
      " [ 2.         32.30651341]\n",
      " [ 3.         15.57088123]\n",
      " [ 4.         24.19923372]\n",
      " [ 5.         18.92720307]]\n",
      "1 91.00383141762453\n",
      "2 67.6934865900383\n",
      "3 84.42911877394637\n",
      "4 75.8007662835249\n",
      "5 81.07279693486589\n",
      "With 1.0 0.01 30 10  number of neighboors, the accuracy of the train model is 0.7055785123966942 % and the accuracy of the valid model is 0.3009961685823755 %\n",
      "[[ 1.          5.79310345]\n",
      " [ 2.         25.04214559]\n",
      " [ 3.         33.02681992]\n",
      " [ 4.         18.25287356]\n",
      " [ 5.         17.88505747]]\n",
      "1 94.20689655172414\n",
      "2 74.95785440613027\n",
      "3 66.97318007662835\n",
      "4 81.74712643678161\n",
      "5 82.11494252873564\n",
      "With 1.0 0.01 30 50  number of neighboors, the accuracy of the train model is 0.7040289256198347 % and the accuracy of the valid model is 0.3109578544061303 %\n",
      "[[ 1.          8.39846743]\n",
      " [ 2.         26.92720307]\n",
      " [ 3.         18.31417625]\n",
      " [ 4.         28.33716475]\n",
      " [ 5.         18.02298851]]\n",
      "1 91.6015325670498\n",
      "2 73.0727969348659\n",
      "3 81.68582375478928\n",
      "4 71.66283524904215\n",
      "5 81.97701149425288\n",
      "With 1.0 0.01 30 100  number of neighboors, the accuracy of the train model is 0.7316115702479339 % and the accuracy of the valid model is 0.3036015325670498 %\n",
      "[[ 1.          4.87356322]\n",
      " [ 2.         27.60153257]\n",
      " [ 3.         16.50574713]\n",
      " [ 4.         32.19923372]\n",
      " [ 5.         18.81992337]]\n",
      "1 95.12643678160919\n",
      "2 72.39846743295018\n",
      "3 83.49425287356323\n",
      "4 67.80076628352491\n",
      "5 81.1800766283525\n",
      "With 1.0 0.01 30 150  number of neighboors, the accuracy of the train model is 0.7235020661157024 % and the accuracy of the valid model is 0.29747126436781607 %\n",
      "[[ 1.         11.49425287]\n",
      " [ 2.         27.96934866]\n",
      " [ 3.         26.8045977 ]\n",
      " [ 4.         18.95785441]\n",
      " [ 5.         14.77394636]]\n",
      "1 88.50574712643679\n",
      "2 72.03065134099617\n",
      "3 73.19540229885058\n",
      "4 81.04214559386973\n",
      "5 85.22605363984674\n",
      "With 1.0 0.01 30 500  number of neighboors, the accuracy of the train model is 0.7192148760330579 % and the accuracy of the valid model is 0.290727969348659 %\n",
      "[[ 1.          9.24137931]\n",
      " [ 2.         34.03831418]\n",
      " [ 3.         18.19157088]\n",
      " [ 4.         23.81609195]\n",
      " [ 5.         14.71264368]]\n",
      "1 90.75862068965517\n",
      "2 65.96168582375479\n",
      "3 81.80842911877394\n",
      "4 76.183908045977\n",
      "5 85.28735632183908\n",
      "With 1.0 0.1 10 10  number of neighboors, the accuracy of the train model is 0.47985537190082644 % and the accuracy of the valid model is 0.2875095785440613 %\n",
      "[[ 1.         11.08045977]\n",
      " [ 2.         61.82375479]\n",
      " [ 3.          0.4137931 ]\n",
      " [ 4.         14.37547893]\n",
      " [ 5.         12.30651341]]\n",
      "1 88.91954022988506\n",
      "2 38.17624521072797\n",
      "3 99.58620689655172\n",
      "4 85.62452107279694\n",
      "5 87.69348659003832\n",
      "With 1.0 0.1 10 50  number of neighboors, the accuracy of the train model is 0.5016528925619834 % and the accuracy of the valid model is 0.26666666666666666 %\n",
      "[[ 1.         15.14176245]\n",
      " [ 2.         57.18007663]\n",
      " [ 3.          5.96168582]\n",
      " [ 4.         10.91187739]\n",
      " [ 5.         10.8045977 ]]\n",
      "1 84.85823754789273\n",
      "2 42.81992337164751\n",
      "3 94.03831417624521\n",
      "4 89.08812260536398\n",
      "5 89.19540229885058\n",
      "With 1.0 0.1 10 100  number of neighboors, the accuracy of the train model is 0.4756714876033058 % and the accuracy of the valid model is 0.2767816091954023 %\n",
      "[[ 1.         21.14942529]\n",
      " [ 2.         30.16091954]\n",
      " [ 3.         25.02681992]\n",
      " [ 4.          6.02298851]\n",
      " [ 5.         17.63984674]]\n",
      "1 78.85057471264368\n",
      "2 69.83908045977012\n",
      "3 74.97318007662835\n",
      "4 93.97701149425288\n",
      "5 82.36015325670498\n",
      "With 1.0 0.1 10 150  number of neighboors, the accuracy of the train model is 0.45526859504132233 % and the accuracy of the valid model is 0.2973180076628352 %\n",
      "[[ 1.         10.88122605]\n",
      " [ 2.         41.83908046]\n",
      " [ 3.          5.37931034]\n",
      " [ 4.         22.71264368]\n",
      " [ 5.         19.18773946]]\n",
      "1 89.11877394636015\n",
      "2 58.160919540229884\n",
      "3 94.62068965517241\n",
      "4 77.28735632183908\n",
      "5 80.81226053639847\n",
      "With 1.0 0.1 10 500  number of neighboors, the accuracy of the train model is 0.2 % and the accuracy of the valid model is 0.2 %\n",
      "[[  2. 100.]]\n",
      "1 100.0\n",
      "2 0.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 100.0\n",
      "With 1.0 0.1 20 10  number of neighboors, the accuracy of the train model is 0.5016012396694215 % and the accuracy of the valid model is 0.29149425287356323 %\n",
      "[[ 1.         15.67816092]\n",
      " [ 2.         46.78927203]\n",
      " [ 3.          4.87356322]\n",
      " [ 4.         18.32950192]\n",
      " [ 5.         14.32950192]]\n",
      "1 84.32183908045977\n",
      "2 53.21072796934866\n",
      "3 95.12643678160919\n",
      "4 81.67049808429118\n",
      "5 85.6704980842912\n",
      "With 1.0 0.1 20 50  number of neighboors, the accuracy of the train model is 0.4959194214876033 % and the accuracy of the valid model is 0.27371647509578545 %\n",
      "[[ 1.         14.22222222]\n",
      " [ 2.         50.40613027]\n",
      " [ 3.          2.2835249 ]\n",
      " [ 4.         20.64367816]\n",
      " [ 5.         12.44444444]]\n",
      "1 85.77777777777777\n",
      "2 49.593869731800766\n",
      "3 97.71647509578544\n",
      "4 79.35632183908045\n",
      "5 87.55555555555556\n",
      "With 1.0 0.1 20 100  number of neighboors, the accuracy of the train model is 0.4818698347107438 % and the accuracy of the valid model is 0.282911877394636 %\n",
      "[[1.00000000e+00 6.02298851e+00]\n",
      " [2.00000000e+00 3.75632184e+01]\n",
      " [3.00000000e+00 1.53256705e-02]\n",
      " [4.00000000e+00 4.11340996e+01]\n",
      " [5.00000000e+00 1.52643678e+01]]\n",
      "1 93.97701149425288\n",
      "2 62.4367816091954\n",
      "3 99.98467432950191\n",
      "4 58.86590038314176\n",
      "5 84.73563218390805\n",
      "With 1.0 0.1 20 150  number of neighboors, the accuracy of the train model is 0.4836776859504132 % and the accuracy of the valid model is 0.28122605363984676 %\n",
      "[[ 1.         13.33333333]\n",
      " [ 2.         43.4789272 ]\n",
      " [ 3.         15.7394636 ]\n",
      " [ 4.         11.72413793]\n",
      " [ 5.         15.72413793]]\n",
      "1 86.66666666666667\n",
      "2 56.52107279693487\n",
      "3 84.26053639846744\n",
      "4 88.27586206896552\n",
      "5 84.27586206896551\n",
      "With 1.0 0.1 20 500  number of neighboors, the accuracy of the train model is 0.47665289256198345 % and the accuracy of the valid model is 0.2534865900383142 %\n",
      "[[ 1.         20.75095785]\n",
      " [ 2.         13.4559387 ]\n",
      " [ 3.         43.12643678]\n",
      " [ 4.          8.18390805]\n",
      " [ 5.         14.48275862]]\n",
      "1 79.24904214559388\n",
      "2 86.544061302682\n",
      "3 56.8735632183908\n",
      "4 91.816091954023\n",
      "5 85.51724137931035\n",
      "With 1.0 0.1 30 10  number of neighboors, the accuracy of the train model is 0.4952479338842975 % and the accuracy of the valid model is 0.2724904214559387 %\n",
      "[[ 1.         15.20306513]\n",
      " [ 2.         56.01532567]\n",
      " [ 4.         16.9348659 ]\n",
      " [ 5.         11.8467433 ]]\n",
      "1 84.79693486590038\n",
      "2 43.984674329501914\n",
      "3 100.0\n",
      "4 83.06513409961686\n",
      "5 88.15325670498085\n",
      "With 1.0 0.1 30 50  number of neighboors, the accuracy of the train model is 0.48465909090909093 % and the accuracy of the valid model is 0.2793869731800766 %\n",
      "[[ 1.          4.96551724]\n",
      " [ 2.         53.56321839]\n",
      " [ 4.         33.28735632]\n",
      " [ 5.          8.18390805]]\n",
      "1 95.03448275862068\n",
      "2 46.43678160919541\n",
      "3 100.0\n",
      "4 66.71264367816092\n",
      "5 91.816091954023\n",
      "With 1.0 0.1 30 100  number of neighboors, the accuracy of the train model is 0.4791838842975207 % and the accuracy of the valid model is 0.2674329501915709 %\n",
      "[[ 1.         24.30651341]\n",
      " [ 2.         56.10727969]\n",
      " [ 3.          5.88505747]\n",
      " [ 4.          1.63984674]\n",
      " [ 5.         12.06130268]]\n",
      "1 75.69348659003832\n",
      "2 43.89272030651341\n",
      "3 94.11494252873564\n",
      "4 98.36015325670499\n",
      "5 87.93869731800767\n",
      "With 1.0 0.1 30 150  number of neighboors, the accuracy of the train model is 0.4831611570247934 % and the accuracy of the valid model is 0.293639846743295 %\n",
      "[[ 1.          7.15708812]\n",
      " [ 2.         58.06896552]\n",
      " [ 4.         20.55172414]\n",
      " [ 5.         14.22222222]]\n",
      "1 92.84291187739464\n",
      "2 41.93103448275862\n",
      "3 100.0\n",
      "4 79.44827586206897\n",
      "5 85.77777777777777\n",
      "With 1.0 0.1 30 500  number of neighboors, the accuracy of the train model is 0.46410123966942146 % and the accuracy of the valid model is 0.2882758620689655 %\n",
      "[[ 1.          6.5440613 ]\n",
      " [ 2.         49.27203065]\n",
      " [ 3.         19.49425287]\n",
      " [ 4.         12.03065134]\n",
      " [ 5.         12.65900383]]\n",
      "1 93.455938697318\n",
      "2 50.72796934865901\n",
      "3 80.50574712643677\n",
      "4 87.96934865900383\n",
      "5 87.34099616858238\n"
     ]
    }
   ],
   "source": [
    "loss_train, loss_valid = [], []\n",
    "list_nn_acc_valid, list_nn_acc_train, a_list, lr_list, neuron_list, layer_list, precision, recall = [\n",
    "], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for a in alpha:\n",
    "    for lr in learning_rates:\n",
    "        for neuron in nb_neurons:\n",
    "            for count, layer in enumerate(nb_hidden_layer):\n",
    "                nn = MLPClassifier(alpha=a,\n",
    "                                   hidden_layer_sizes=(neuron, layer),\n",
    "                                   random_state=1,\n",
    "                                   learning_rate_init=lr,\n",
    "                                   max_iter=100,\n",
    "                                   early_stopping=True\n",
    "                                   )\n",
    "                nn.fit(train_data_features, y_train)\n",
    "\n",
    "                nn_acc_train = nn.score(train_data_features, y_train)\n",
    "                nn_acc_valid = nn.score(valid_data_features, y_val)\n",
    "\n",
    "                unique, counts = np.unique(nn.predict(\n",
    "                    valid_data_features), return_counts=True)\n",
    "\n",
    "                loss_train.append(nn_acc_train)\n",
    "                loss_valid.append(nn_acc_valid)\n",
    "\n",
    "                print(\"With\", a, lr, neuron, layer, \" number of neighboors, the accuracy of the train model is\", nn_acc_train,\n",
    "                      \"% and the accuracy of the valid model is\", nn_acc_valid, \"%\")\n",
    "\n",
    "                #Combien j'en ai mis dans mon train Data\n",
    "\n",
    "                print(np.asarray((unique, (counts/len(y_val))*100)).T)\n",
    "\n",
    "                #Combien j'ai pas pu prédire\n",
    "\n",
    "\n",
    "\n",
    "                for i in np.unique(y_val):\n",
    "                    lmao = (sum(nn.predict(valid_data_features)\n",
    "                                != i)/len(y_val == i))*100\n",
    "                    print(i, lmao)\n",
    "\n",
    "                prf = precision_recall_fscore_support(y_val, nn.predict(\n",
    "                    valid_data_features), average='weighted', zero_division=1)\n",
    "\n",
    "                list_nn_acc_train.append(nn_acc_train)\n",
    "                list_nn_acc_valid.append(nn_acc_valid)\n",
    "                a_list.append(a)\n",
    "                lr_list.append(lr)\n",
    "                neuron_list.append(neuron)\n",
    "                layer_list.append(layer)\n",
    "                precision.append(prf[0])\n",
    "                recall.append(prf[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2 Regularizarion term</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Accuracy of Train</th>\n",
       "      <th>Acccuracy of Valid</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.766064</td>\n",
       "      <td>0.262989</td>\n",
       "      <td>0.253502</td>\n",
       "      <td>0.262989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.828099</td>\n",
       "      <td>0.260230</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.260230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.815083</td>\n",
       "      <td>0.261916</td>\n",
       "      <td>0.263603</td>\n",
       "      <td>0.261916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.814773</td>\n",
       "      <td>0.262529</td>\n",
       "      <td>0.258885</td>\n",
       "      <td>0.262529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.843647</td>\n",
       "      <td>0.265594</td>\n",
       "      <td>0.269716</td>\n",
       "      <td>0.265594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.495248</td>\n",
       "      <td>0.272490</td>\n",
       "      <td>0.439099</td>\n",
       "      <td>0.272490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.484659</td>\n",
       "      <td>0.279387</td>\n",
       "      <td>0.456687</td>\n",
       "      <td>0.279387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.479184</td>\n",
       "      <td>0.267433</td>\n",
       "      <td>0.270995</td>\n",
       "      <td>0.267433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.293640</td>\n",
       "      <td>0.449746</td>\n",
       "      <td>0.293640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>0.464101</td>\n",
       "      <td>0.288276</td>\n",
       "      <td>0.298628</td>\n",
       "      <td>0.288276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L2 Regularizarion term  Learning Rate  Number of neurons  \\\n",
       "0                       0.0          0.001                 10   \n",
       "1                       0.0          0.001                 10   \n",
       "2                       0.0          0.001                 10   \n",
       "3                       0.0          0.001                 10   \n",
       "4                       0.0          0.001                 10   \n",
       "..                      ...            ...                ...   \n",
       "130                     1.0          0.100                 30   \n",
       "131                     1.0          0.100                 30   \n",
       "132                     1.0          0.100                 30   \n",
       "133                     1.0          0.100                 30   \n",
       "134                     1.0          0.100                 30   \n",
       "\n",
       "     Number of layers  Accuracy of Train  Acccuracy of Valid  Precision  \\\n",
       "0                  10           0.766064            0.262989   0.253502   \n",
       "1                  50           0.828099            0.260230   0.239497   \n",
       "2                 100           0.815083            0.261916   0.263603   \n",
       "3                 150           0.814773            0.262529   0.258885   \n",
       "4                 500           0.843647            0.265594   0.269716   \n",
       "..                ...                ...                 ...        ...   \n",
       "130                10           0.495248            0.272490   0.439099   \n",
       "131                50           0.484659            0.279387   0.456687   \n",
       "132               100           0.479184            0.267433   0.270995   \n",
       "133               150           0.483161            0.293640   0.449746   \n",
       "134               500           0.464101            0.288276   0.298628   \n",
       "\n",
       "       Recall  \n",
       "0    0.262989  \n",
       "1    0.260230  \n",
       "2    0.261916  \n",
       "3    0.262529  \n",
       "4    0.265594  \n",
       "..        ...  \n",
       "130  0.272490  \n",
       "131  0.279387  \n",
       "132  0.267433  \n",
       "133  0.293640  \n",
       "134  0.288276  \n",
       "\n",
       "[135 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_tuples = list(zip(a_list, lr_list, neuron_list, layer_list,\n",
    "                       list_nn_acc_train, list_nn_acc_valid, precision, recall))\n",
    "q3_data = pd.DataFrame(data_tuples, columns=['L2 Regularizarion term',\n",
    "                                             'Learning Rate',\n",
    "                                             'Number of neurons',\n",
    "                                             'Number of layers',\n",
    "                                             'Accuracy of Train',\n",
    "                                             'Acccuracy of Valid',\n",
    "                                             'Precision',\n",
    "                                             'Recall'])\n",
    "q3_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2 Regularizarion term</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Accuracy of Train</th>\n",
       "      <th>Acccuracy of Valid</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702273</td>\n",
       "      <td>0.320613</td>\n",
       "      <td>0.316792</td>\n",
       "      <td>0.320613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.769267</td>\n",
       "      <td>0.313870</td>\n",
       "      <td>0.294263</td>\n",
       "      <td>0.313870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.721746</td>\n",
       "      <td>0.313870</td>\n",
       "      <td>0.310658</td>\n",
       "      <td>0.313870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.312490</td>\n",
       "      <td>0.312741</td>\n",
       "      <td>0.312490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.726808</td>\n",
       "      <td>0.311724</td>\n",
       "      <td>0.293287</td>\n",
       "      <td>0.311724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>0.476653</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>0.268060</td>\n",
       "      <td>0.253487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.788171</td>\n",
       "      <td>0.249195</td>\n",
       "      <td>0.263461</td>\n",
       "      <td>0.249195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L2 Regularizarion term  Learning Rate  Number of neurons  \\\n",
       "60                      0.5          0.010                 10   \n",
       "65                      0.5          0.010                 20   \n",
       "111                     1.0          0.010                 20   \n",
       "105                     1.0          0.010                 10   \n",
       "110                     1.0          0.010                 20   \n",
       "..                      ...            ...                ...   \n",
       "129                     1.0          0.100                 20   \n",
       "48                      0.5          0.001                 10   \n",
       "78                      0.5          0.100                 10   \n",
       "79                      0.5          0.100                 10   \n",
       "124                     1.0          0.100                 10   \n",
       "\n",
       "     Number of layers  Accuracy of Train  Acccuracy of Valid  Precision  \\\n",
       "60                 10           0.702273            0.320613   0.316792   \n",
       "65                 10           0.769267            0.313870   0.294263   \n",
       "111                50           0.721746            0.313870   0.310658   \n",
       "105                10           0.677686            0.312490   0.312741   \n",
       "110                10           0.726808            0.311724   0.293287   \n",
       "..                ...                ...                 ...        ...   \n",
       "129               500           0.476653            0.253487   0.268060   \n",
       "48                150           0.788171            0.249195   0.263461   \n",
       "78                150           0.200000            0.200000   0.840000   \n",
       "79                500           0.200000            0.200000   0.840000   \n",
       "124               500           0.200000            0.200000   0.840000   \n",
       "\n",
       "       Recall  \n",
       "60   0.320613  \n",
       "65   0.313870  \n",
       "111  0.313870  \n",
       "105  0.312490  \n",
       "110  0.311724  \n",
       "..        ...  \n",
       "129  0.253487  \n",
       "48   0.249195  \n",
       "78   0.200000  \n",
       "79   0.200000  \n",
       "124  0.200000  \n",
       "\n",
       "[135 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_data.sort_values(['Acccuracy of Valid', 'Accuracy of Train'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2986281477154849"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf = precision_recall_fscore_support(y_val, nn.predict(\n",
    "    valid_data_features), average='weighted', zero_division=1)\n",
    "prf[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label='Train')\n",
    "plt.plot(loss_valid, label='Validation')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Ghosting the legend\n",
    "leg = plt.gca().legend(loc='center left', bbox_to_anchor=(1, .85))\n",
    "leg.get_frame().set_alpha(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46410123966942146\n"
     ]
    }
   ],
   "source": [
    "print(nn_acc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  427]\n",
      " [   2 3215]\n",
      " [   3 1272]\n",
      " [   4  785]\n",
      " [   5  826]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f499ddd7e6d9fbd89b8b97faec72174c6c1dd701b140ff7d170263c1edbaf48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
