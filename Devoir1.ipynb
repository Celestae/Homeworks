{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['C:\\\\Users\\\\love-\\\\Documents\\\\Homeworks\\\\80-629\\\\week3-Supervised']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b725e29a7551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_svc_decision_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import generate_data, plot_predictions, plot_svc_decision_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"a22_devoir_q2-classification.npz\")\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 2 2 0 0 2 1 0 2 1 1 2 2 0 2 1 2 1 1 0 1 1 1 0 1 0 1 1 0 0 1 2 2 2 2\n",
      " 0 2 2 0 2 2 2 1 0 1 0 1 2 0 1 0 0 0 2 1 2 2 2 1 1 1 1 0 0 0 2 1 0 0 1 0 2\n",
      " 0 0 0 1 0 1 1 2 2 0 2 2 0 2 0 2 0 1 1 2 0 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15494743  0.37816252]\n",
      " [ 4.6781908   3.88829842]\n",
      " [ 0.06651722  0.3024719 ]\n",
      " [ 4.44780833  5.02608254]\n",
      " [ 4.77223375  5.00873958]\n",
      " [ 1.53277921  1.46935877]\n",
      " [ 0.17742614 -0.40178094]\n",
      " [ 4.68207696  5.33821665]\n",
      " [ 3.26816936  1.23011275]\n",
      " [-1.70627019  1.9507754 ]\n",
      " [ 5.5940149   5.15847131]\n",
      " [ 0.13905245  1.57791809]\n",
      " [ 2.50844214  2.11119275]\n",
      " [ 4.95077374  4.66826086]\n",
      " [ 6.08161797  5.66826397]\n",
      " [ 0.14404357  1.45427351]\n",
      " [ 4.9658792   5.85667136]\n",
      " [ 2.42111906  2.88331001]\n",
      " [ 5.28829541  4.89585062]\n",
      " [ 0.45814821  1.27554819]\n",
      " [ 0.34512589  2.30887379]\n",
      " [-0.51080514 -1.18063218]\n",
      " [ 1.81241247  2.96495855]\n",
      " [ 2.10351246  0.47278486]\n",
      " [ 2.0345496   2.55985975]\n",
      " [ 0.8644362  -0.74216502]\n",
      " [ 0.89523458  3.33366761]\n",
      " [ 1.86755799 -0.97727788]\n",
      " [-0.24772476  2.85123973]\n",
      " [ 4.32472605 -0.52163859]\n",
      " [ 1.23029068  1.20237985]\n",
      " [ 2.26975462 -1.45436567]\n",
      " [-0.25968511  4.41543178]\n",
      " [ 5.31261573  4.19897117]\n",
      " [ 5.38589528  5.41175208]\n",
      " [ 4.49989233  4.22761445]\n",
      " [ 4.35357155  5.13352543]\n",
      " [-0.81314628 -1.7262826 ]\n",
      " [ 4.48287858  5.34079726]\n",
      " [ 6.19157239  5.47223974]\n",
      " [-2.55298982  0.6536186 ]\n",
      " [ 5.56331796  4.46003425]\n",
      " [ 4.34204629  4.7692077 ]\n",
      " [ 5.46042941  5.15936383]\n",
      " [ 1.94735726  3.48957885]\n",
      " [ 0.97873798  2.2408932 ]\n",
      " [ 3.73237829  4.34383376]\n",
      " [ 0.95008842 -0.15135721]\n",
      " [ 1.51575003  4.17880574]\n",
      " [ 5.19800336  4.45346925]\n",
      " [-0.34791215  0.15634897]\n",
      " [ 3.20910103 -0.35223873]\n",
      " [-0.38732682 -0.30230275]\n",
      " [ 1.76405235  0.40015721]\n",
      " [ 0.3130677  -0.85409574]\n",
      " [ 4.98035859  4.41595325]\n",
      " [ 2.19849366 -0.80436553]\n",
      " [ 4.59829517  4.65522511]\n",
      " [ 4.38728224  5.42218149]\n",
      " [ 5.42841531  4.6744872 ]\n",
      " [ 0.84726967  4.27389559]\n",
      " [ 4.30133844  2.85906699]\n",
      " [ 0.87957153  0.37881778]\n",
      " [-0.4057275   2.95409506]\n",
      " [-1.63019835  0.46278226]\n",
      " [-0.63432209 -0.36274117]\n",
      " [-0.02818223  0.42833187]\n",
      " [ 4.62762259  4.58678073]\n",
      " [ 1.09799494  2.70368459]\n",
      " [-1.04855297 -1.42001794]\n",
      " [-0.89546656  0.3869025 ]\n",
      " [ 4.38441304  3.72077219]\n",
      " [-0.67246045 -0.35955316]\n",
      " [ 5.26163833  4.91422683]\n",
      " [-0.10321885  0.4105985 ]\n",
      " [-1.61389785 -0.21274028]\n",
      " [-1.25279536  0.77749036]\n",
      " [ 0.20816147  4.36509743]\n",
      " [-0.88778575 -1.98079647]\n",
      " [ 2.0646383  -0.14910119]\n",
      " [ 0.48850101  1.54774584]\n",
      " [ 5.08333675  5.31751572]\n",
      " [ 5.4747104   5.04377562]\n",
      " [ 0.76103773  0.12167502]\n",
      " [ 4.82300304  4.31252435]\n",
      " [ 4.42626567  4.78108998]\n",
      " [-0.50965218 -0.4380743 ]\n",
      " [ 4.75098377  5.96476603]\n",
      " [ 0.44386323  0.33367433]\n",
      " [ 4.6302185   5.7715073 ]\n",
      " [ 1.49407907 -0.20515826]\n",
      " [ 1.0326712   1.58424801]\n",
      " [ 0.19380428  0.6317255 ]\n",
      " [ 4.2543712   5.21969585]\n",
      " [ 0.04575852 -0.18718385]\n",
      " [-0.10612893  3.08167759]\n",
      " [ 4.54358889  5.55850814]\n",
      " [ 1.69036814  2.10298405]\n",
      " [ 2.92087795  1.26748486]\n",
      " [ 2.59363584  1.69347437]]\n",
      "[0.15494743 0.37816252]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2693209543318646"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = zip(*X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  8., 17.,  7., 11.,  6.,  8.,  9., 18., 12.]),\n",
       " array([-1.98079647, -1.18624022, -0.39168397,  0.40287228,  1.19742853,\n",
       "         1.99198478,  2.78654103,  3.58109728,  4.37565353,  5.17020978,\n",
       "         5.96476603]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.hist(x1)\n",
    "ax2.hist(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.,  7., 14., 16., 11., 10.,  3.,  9., 20.,  8.],\n",
       "        [ 2.,  6., 13., 15., 10.,  6.,  9., 11., 17., 11.]]),\n",
       " array([-2.55298982, -1.6785336 , -0.80407738,  0.07037885,  0.94483507,\n",
       "         1.81929129,  2.69374751,  3.56820373,  4.44265995,  5.31711617,\n",
       "         6.19157239]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x1, x2, hue=y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4pt) Suite `a une exploration des donn´ees, que remarquez-vous?\n",
    "# Il y a deux grands groupes que l'on peut appercevoir.\n",
    "# Que pouvez-vous dire de la performance (taux de bonne classification) de test\n",
    "# d’un mod`ele n’utilisant que des fronti`eres de d´ecision lin´eaire pour ce probl`eme?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(X, y):\n",
    "    # Note: on transforme simplement les cibles de {0,1} à {-1,+1}\n",
    "    Y = (X_train[1]*2)-1\n",
    "    Y = Y.reshape(2, 1)\n",
    "\n",
    "    # On calcule les paramètres du modèle\n",
    "    # (c'est le même calcul que celui de la semaine dernière pour w_ols)\n",
    "    A = np.linalg.inv(np.dot(X.T, X))\n",
    "    B = np.dot(X.T, Y)\n",
    "\n",
    "    return np.dot(A, B)\n",
    "\n",
    "# pour obtenir la frontière de décision visuellement\n",
    "\n",
    "\n",
    "def calculate_decision_boundary(W):\n",
    "    x_1 = np.linspace(-10, 10)  # <- pour x1;\n",
    "\n",
    "    # Le but est donc de calculer x2 à partir de x1 et des poids.\n",
    "    x_2 = (-W[0] - W[1]*x_1) / W[2]\n",
    "    return x_1, x_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,67) and (2,1) not aligned: 67 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/2641869053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 1) On (estime) entraîne les paramètres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# k est le nombre de classes et dim est la dimensionalité des données\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# dim x k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# 2) Une fois les paramètres obtenus, on peut obtenir les prédictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23336/668108507.py\u001b[0m in \u001b[0;36mOLS\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# (c'est le même calcul que celui de la semaine dernière pour w_ols)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,67) and (2,1) not aligned: 67 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "\n",
    "# On ajoute une colonne de 1 aux données\n",
    "# Ça nous permet d'apprendre le biais (w0 dans: w_1x + w0)\n",
    "X_b = np.array([np.ones(len(X)), X[:, 0], X[:, 1]]).T\n",
    "####\n",
    "\n",
    "Y = y_train\n",
    "X_test = X_test\n",
    "\n",
    "# Comme plus haut on ajoute une colonne de 1 aux données de test\n",
    "X_test_b = np.array([np.ones(len(X_test)), X_test[:, 0], X_test[:, 1]]).T\n",
    "###\n",
    "\n",
    "Y_test = y_test\n",
    "\n",
    "# 1) On (estime) entraîne les paramètres\n",
    "# k est le nombre de classes et dim est la dimensionalité des données\n",
    "W = OLS(X_b, Y)  # dim x k\n",
    "\n",
    "# 2) Une fois les paramètres obtenus, on peut obtenir les prédictions\n",
    "# a) for test data\n",
    "y_x = np.dot(W.T, X_test_b.T)  # valeur réelle\n",
    "pred_test = 1*(y_x > 0)[0]  # valeur binaire\n",
    "\n",
    "# b) Idem pour l'ensemble d'entraînement\n",
    "y_x = np.dot(W.T, X_b.T)\n",
    "pred_train = 1*(y_x > 0)[0]\n",
    "\n",
    "\n",
    "# 3) On calcule aussi la frontière de décision\n",
    "#    pour pouvoir la visualiser\n",
    "line_x, line_y = calculate_decision_boundary(W)\n",
    "\n",
    "\n",
    "# 4) Rendu visuel\n",
    "plot_predictions(X, Y, X_test, Y_test, pred_train, pred_test, line_x, line_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6pt) Divide your dataset into training, validation, and test sets.\n",
    "# The validation and test sets must each make up 20% of the total original dataset (so 40% in total).\n",
    "# Make sure to use this parameter upon calling the appropriate sklearn function: random state=1234.\n",
    "# Train a linear SVM on the training set for each one of these C hyperparameter values: {0.001,0.01,0.1,1,10}.\n",
    "# For each value of C, what is the performance (accuracy) of the model on the training and validation sets?\n",
    "#  Given your answer, obtain the performance of the best model on the test set.\n",
    "#  We ask that you provide the few lines of code you used to divide the data, train the model, and obtain the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1234)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  0.001 , the accuracy of the train model is 41.66666666666667 % ans the accuracy of the  validation model is 30.0 %\n",
      "With a value of C:  0.01 , the accuracy of the train model is 83.33333333333334 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  0.1 , the accuracy of the train model is 86.66666666666667 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  1 , the accuracy of the train model is 90.0 % ans the accuracy of the  validation model is 90.0 %\n",
      "With a value of C:  10 , the accuracy of the train model is 90.0 % ans the accuracy of the  validation model is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "for i, c in enumerate(cs):\n",
    "    model = SVC(kernel='linear', C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    acc_train = (sum(model.predict(X_train) == y_train)/len(y_train))*100\n",
    "    acc_validation = (sum(model.predict(X_val) == y_val)/len(y_val)) * 100\n",
    "\n",
    "    print(\"With a value of C: \", c, \", the accuracy of the train model is\", acc_train,\n",
    "          \"% anf<d the accuracy of the  validation model is\", acc_validation, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  10 , the accuracy of the test model is 85.0 %\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acc_test = (sum(model.predict(X_test) == y_test)/len(y_test)) * 100\n",
    "\n",
    "print(\"With a value of C: \", c, \", the accuracy of the test model is\", acc_test, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4pt) Retrain the SVM model using 10-fold cross-validation for each of the C hyperparameter values from above.\n",
    "# For each value of C, provide the training and validation accuracies as well as the performance on the test set of the best model.\n",
    "#  Careful that you must use the same test set in both cases (previous question and this question)!\n",
    "#  We ask that you provide the few lines of codes you used to divide the data, train the model, and obtain all accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep validation and train together unlike the question above\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  0.001 , the mean accuracy of the train model is 0.3875 % and the mean accuracy of the validation model is 0.3875 %\n",
      "With a value of C:  0.01 , the mean accuracy of the train model is 0.861111111111111 % and the mean accuracy of the validation model is 0.85 %\n",
      "With a value of C:  0.1 , the mean accuracy of the train model is 0.8777777777777779 % and the mean accuracy of the validation model is 0.8625 %\n",
      "With a value of C:  1 , the mean accuracy of the train model is 0.9027777777777777 % and the mean accuracy of the validation model is 0.8625 %\n",
      "With a value of C:  10 , the mean accuracy of the train model is 0.9152777777777776 % and the mean accuracy of the validation model is 0.875 %\n"
     ]
    }
   ],
   "source": [
    "for c in cs:\n",
    "    model = SVC(kernel='linear', C=c, random_state=1234)\n",
    "    test = model.fit(X_train, y_train)\n",
    "\n",
    "    scores = cross_validate(test, X_train,  y_train,\n",
    "                            cv=10,  return_train_score=True)\n",
    "\n",
    "    #acc_train = (sum(model.predict(X_train)==y_train)/len(y_train))*100\n",
    "    #acc_validation =  (sum(model.predict(X_val)==y_val)/len(y_val)) *100\n",
    "\n",
    "    print(\"With a value of C: \", c, \", the mean accuracy of the train model is\", scores['train_score'].mean(\n",
    "    ), '% and the mean accuracy of the validation model is', scores['test_score'].mean(), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a value of C:  10 , the accuracy of the test model is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=10)\n",
    "\n",
    "acc_test = (sum(test.predict(X_test) == y_test)/len(y_test)) * 100\n",
    "\n",
    "print(\"With a value of C: \", c, \", the accuracy of the test model is\", acc_test, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 - (2pt) Explain precisely how is the validation performance evaluated when doing cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5 - (2pt) Do you obtain a better model with cross validation or without it? Justify your answer and explain your result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Bought one a few years ago for my daughter and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have a stainless steel refrigerator therefor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>There are multiple shapes part like oval and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5</td>\n",
       "      <td>My 2 1/2 year old loves playing with these puz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>I only wish I bought this toy sooner!  It was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "      <td>My not quite 2 year old grandson took to this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>To say that my two year old loves these puzzle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating                                             Review\n",
       "0          5  I like the item pricing. My granddaughter want...\n",
       "1          4  Love the magnet easel... great for moving to d...\n",
       "2          5  Both sides are magnetic.  A real plus when you...\n",
       "3          5  Bought one a few years ago for my daughter and...\n",
       "4          4  I have a stainless steel refrigerator therefor...\n",
       "...      ...                                                ...\n",
       "9995       1  There are multiple shapes part like oval and t...\n",
       "9996       5  My 2 1/2 year old loves playing with these puz...\n",
       "9997       5  I only wish I bought this toy sooner!  It was ...\n",
       "9998       5  My not quite 2 year old grandson took to this ...\n",
       "9999       5  To say that my two year old loves these puzzle...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = pd.read_csv(\"/Users/mathieulamontagne/Homeworks/reviews.tsv\",\n",
    "                 sep='\\t', header=None, names=['Rating', 'Review'])\n",
    "q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    0\n",
       "Review    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating Review\n",
       "2339       5    NaN\n",
       "2702       5    NaN\n",
       "4653       5    NaN\n",
       "8751       5    NaN\n",
       "8770       2    NaN\n",
       "9258       4    NaN\n",
       "9690       5    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = q3[q3['Review'].isna()]\n",
    "check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = q3.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-2a0fc7372c8a>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n",
      "<ipython-input-9-2a0fc7372c8a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n"
     ]
    }
   ],
   "source": [
    "q3['Review'] = q3.Review.str.replace('[^a-zA-Z]', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9993,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3['Rating'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9993,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3['Review'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    0\n",
       "Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = q3['Rating']\n",
    "X = q3['Review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like the item pricing  My granddaughter wanted to mark on it but I wanted it just for the letters '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". (3pt) On vous demande ensuite d’obtenir une repr´esentation sac à mots (bag-of-words) des caract´eristiques (features). sklearn offre des fonctions pour y arriver. Pour limiter le temps d’entraˆınement requis, on vous demande d’utiliser un maximumde2000motsdansvotre vocabulaire (max features=2000) et d’utiliser la liste des mots vides de sklearn (stop words=\"english\"). Cette liste permet de retirer des mots qui à priori ne seront pas utiles a la pr´ediction. Utilisez les autres param`etres par d´efaut de la fonction. Nous vous demandons les quelques lignes de code de sklearn que vous avez utilis´ees pour encoder (et seulement encoder) les donn´ees d’entraˆınement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1234)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4946    This is a must have for any infant toy collect...\n",
       "8509    My   year old received this game for Christmas...\n",
       "6790    I bought this toy for my   boys    and    and ...\n",
       "7615    Cute accessory for Calico Critters playhouse  ...\n",
       "5438    After she killed a few sets of batteries   I p...\n",
       "                              ...                        \n",
       "2309    I have always wanted a chopper but found them ...\n",
       "8211    Bought this set for my two year old twins that...\n",
       "1232    Ok  if you have seen my other reviews then you...\n",
       "3641    My cousins would always bring this game over f...\n",
       "5500    She is really showing an interest in the state...\n",
       "Name: Review, Length: 5995, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4946    4\n",
       "8509    4\n",
       "6790    2\n",
       "7615    4\n",
       "5438    5\n",
       "       ..\n",
       "2309    4\n",
       "8211    4\n",
       "1232    4\n",
       "3641    5\n",
       "5500    5\n",
       "Name: Rating, Length: 5995, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  # Import the stop word list\n",
    "print(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                             stop_words=\"english\",\n",
    "                             max_features=2000)\n",
    "\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "valid_data_features = vectorizer.fit_transform(X_val)\n",
    "test_data_features = vectorizer.fit_transform(X_test)\n",
    "\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "valid_data_features = valid_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5995, 2000)\n",
      "(5995,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)\n",
    "print(y_train.shape)\n",
    "# This has 9993 rows and 2000 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'abc', 'abilities', 'ability', 'able', 'absolutely', 'abuse', 'access', 'accessories', 'accidentally', 'accurate', 'act', 'action', 'actions', 'activities', 'activity', 'actual', 'actually', 'adapter', 'add', 'added', 'addictive', 'adding', 'addition', 'additional', 'adds', 'adjust', 'admit', 'adorable', 'adult', 'adults', 'advance', 'advanced', 'advantage', 'adventure', 'adventures', 'affair', 'affect', 'afraid', 'age', 'aged', 'ages', 'ago', 'agree', 'ahead', 'air', 'alike', 'allow', 'allowing', 'allows', 'alot', 'alphabet', 'alternative', 'amazing', 'amazingly', 'amazon', 'american', 'ancient', 'angle', 'animal', 'animals', 'annoying', 'answer', 'answers', 'apart', 'apparently', 'appeal', 'appealing', 'appear', 'appears', 'apples', 'appreciate', 'appropriate', 'area', 'aren', 'arkham', 'arm', 'armies', 'arms', 'arrived', 'art', 'arts', 'artwork', 'aside', 'ask', 'asked', 'asking', 'asks', 'aspect', 'assemble', 'assembled', 'assembly', 'assistance', 'attach', 'attached', 'attack', 'attempt', 'attempting', 'attention', 'available', 'average', 'avoid', 'aware', 'away', 'awesome', 'awhile', 'babies', 'baby', 'backwards', 'bad', 'bag', 'balance', 'balanced', 'ball', 'balls', 'bananagrams', 'bang', 'bank', 'barely', 'barrel', 'base', 'based', 'basic', 'basically', 'basics', 'basket', 'batteries', 'battery', 'battle', 'beads', 'beans', 'bear', 'beat', 'beating', 'beautiful', 'bed', 'beds', 'begin', 'beginner', 'beginning', 'behavior', 'believe', 'bench', 'bend', 'benefit', 'bent', 'best', 'better', 'beware', 'big', 'bigger', 'biggest', 'bin', 'bird', 'birthday', 'bit', 'bite', 'black', 'blank', 'blast', 'block', 'blocks', 'blow', 'blue', 'board', 'boards', 'body', 'boggle', 'bonus', 'book', 'books', 'bored', 'boring', 'born', 'bother', 'bought', 'bounce', 'bouncing', 'box', 'boxes', 'boy', 'boys', 'brain', 'brand', 'bread', 'break', 'breaking', 'bright', 'brightly', 'bring', 'brings', 'broke', 'broken', 'brother', 'brought', 'bruder', 'bucks', 'build', 'building', 'buildings', 'built', 'bumble', 'bunch', 'bunnies', 'bunny', 'bus', 'busy', 'butterflies', 'butterfly', 'button', 'buttons', 'buy', 'buying', 'called', 'came', 'camelot', 'campaign', 'camping', 'candy', 'candyland', 'cans', 'car', 'card', 'cardboard', 'cards', 'care', 'careful', 'carpet', 'carrot', 'carry', 'carrying', 'cars', 'cart', 'case', 'cash', 'castle', 'cat', 'catan', 'catch', 'categories', 'caterpillars', 'caught', 'cause', 'center', 'certain', 'certainly', 'chain', 'challenge', 'challenges', 'challenging', 'chance', 'chances', 'change', 'changed', 'changes', 'changing', 'channel', 'character', 'characters', 'charge', 'charging', 'cheap', 'cheaper', 'cheaply', 'check', 'chess', 'chest', 'chew', 'child', 'childhood', 'children', 'chips', 'choice', 'choices', 'choking', 'choose', 'chooses', 'chose', 'chosen', 'christmas', 'circle', 'class', 'classic', 'classroom', 'clean', 'clear', 'clearly', 'click', 'climb', 'climber', 'climbing', 'clip', 'clock', 'close', 'closet', 'cloth', 'clothes', 'clue', 'clues', 'coins', 'collect', 'collection', 'college', 'color', 'colored', 'colorful', 'coloring', 'colors', 'combat', 'come', 'comes', 'comfortable', 'comfortably', 'coming', 'commodity', 'company', 'compare', 'compared', 'compete', 'competition', 'competitive', 'complain', 'complaint', 'complete', 'completed', 'completely', 'completing', 'complex', 'complicated', 'components', 'computer', 'concept', 'concern', 'concerned', 'condition', 'confusing', 'connect', 'cons', 'consider', 'considered', 'considering', 'consists', 'constant', 'constantly', 'constructed', 'construction', 'container', 'containers', 'contains', 'continue', 'continues', 'control', 'controller', 'controls', 'conversation', 'cool', 'cooperative', 'coordination', 'cooties', 'copy', 'core', 'corners', 'correct', 'correctly', 'cost', 'costs', 'couldn', 'count', 'counters', 'counting', 'counts', 'couple', 'course', 'cousin', 'cover', 'craft', 'cranky', 'crawl', 'crayola', 'crayons', 'crazy', 'create', 'created', 'creating', 'creative', 'creativity', 'credit', 'creeper', 'creepers', 'crew', 'crib', 'crowd', 'cthulhu', 'cube', 'cup', 'current', 'currently', 'cut', 'cute', 'dad', 'daddy', 'daily', 'damage', 'dance', 'dangerous', 'dark', 'date', 'daughter', 'daughters', 'day', 'days', 'dd', 'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decisions', 'deck', 'decks', 'deep', 'definitely', 'degree', 'depending', 'depends', 'depth', 'descent', 'described', 'description', 'design', 'designed', 'designs', 'despite', 'detailed', 'details', 'determine', 'dial', 'dice', 'did', 'didn', 'didnt', 'die', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'direction', 'directions', 'disappointed', 'disappointing', 'disappointment', 'discard', 'discovered', 'display', 'districts', 'doctor', 'does', 'doesn', 'doesnt', 'dog', 'doh', 'doing', 'doll', 'dollar', 'dollars', 'dolls', 'dominion', 'don', 'dont', 'doom', 'door', 'doors', 'dot', 'dots', 'double', 'doubt', 'doug', 'downside', 'drag', 'drain', 'draw', 'drawback', 'drawer', 'drawing', 'drawn', 'draws', 'drive', 'driving', 'drop', 'dropping', 'drum', 'dry', 'dumb', 'dungeon', 'dunwich', 'duplo', 'durability', 'durable', 'dvd', 'ear', 'earlier', 'early', 'ears', 'ease', 'easel', 'easier', 'easily', 'easy', 'eat', 'ebay', 'edge', 'edges', 'edition', 'education', 'educational', 'effect', 'effects', 'effort', 'eggs', 'elder', 'electric', 'electronic', 'element', 'elements', 'elf', 'empire', 'encounter', 'encourage', 'encourages', 'end', 'ended', 'endless', 'ends', 'energy', 'engine', 'engines', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enjoying', 'enjoyment', 'enjoys', 'entertain', 'entertained', 'entertaining', 'entertainment', 'entire', 'entirely', 'erase', 'especially', 'essentially', 'etch', 'euro', 'eve', 'evening', 'events', 'eventually', 'everyday', 'everytime', 'evil', 'exact', 'exactly', 'example', 'excellent', 'exception', 'excited', 'excitement', 'exciting', 'exercise', 'expansion', 'expansions', 'expect', 'expected', 'expecting', 'expensive', 'experience', 'experiment', 'explain', 'explained', 'explore', 'extra', 'extremely', 'eye', 'eyes', 'face', 'faces', 'fact', 'factor', 'fail', 'fair', 'fairly', 'falcon', 'fall', 'falling', 'falls', 'familiar', 'families', 'family', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fashion', 'fashioned', 'fast', 'faster', 'father', 'fault', 'favor', 'favorite', 'favorites', 'feature', 'features', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'ffg', 'field', 'fight', 'fighter', 'fighters', 'fighting', 'figure', 'figured', 'figuring', 'filled', 'filling', 'fills', 'final', 'finally', 'finding', 'fine', 'fingers', 'finish', 'finished', 'fish', 'fisher', 'fishing', 'fit', 'fits', 'flat', 'flexible', 'flies', 'flight', 'flimsy', 'flip', 'floor', 'floors', 'fluxx', 'fly', 'flying', 'foam', 'focus', 'fold', 'folks', 'follow', 'following', 'food', 'foot', 'force', 'forever', 'forget', 'form', 'forth', 'fortunately', 'forward', 'fourth', 'frame', 'free', 'frequently', 'fresh', 'friend', 'friendly', 'friends', 'frog', 'frogs', 'fruit', 'frustrated', 'frustrating', 'frustration', 'fully', 'fun', 'funny', 'furniture', 'future', 'gain', 'game', 'gameplay', 'gamer', 'gamers', 'games', 'gaming', 'garage', 'garbage', 'garden', 'gate', 'gather', 'gathering', 'gave', 'gear', 'gears', 'general', 'generally', 'generic', 'gets', 'getting', 'gift', 'gifts', 'girl', 'girls', 'given', 'gives', 'giving', 'glad', 'glass', 'glue', 'goal', 'goals', 'goes', 'going', 'gold', 'gone', 'good', 'goods', 'got', 'gotten', 'grab', 'grade', 'grail', 'grand', 'grandchildren', 'granddaughter', 'grandkids', 'grandma', 'grandparents', 'grandson', 'grandsons', 'graphics', 'gras', 'grasp', 'grass', 'great', 'greatly', 'green', 'grew', 'grid', 'grocery', 'ground', 'group', 'groups', 'grow', 'growing', 'grown', 'grows', 'guess', 'guests', 'gun', 'guy', 'guys', 'half', 'hammer', 'hand', 'handle', 'handling', 'hands', 'handy', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'harder', 'hardly', 'hardwood', 'harold', 'hasn', 'hate', 'haven', 'having', 'hazard', 'head', 'heads', 'hear', 'heard', 'hearing', 'heart', 'heavy', 'height', 'held', 'heli', 'helicopter', 'helicopters', 'help', 'helped', 'helpful', 'helping', 'helps', 'heroes', 'hey', 'hide', 'high', 'higher', 'highest', 'highly', 'hilarious', 'hill', 'hippo', 'hippos', 'history', 'hit', 'hitting', 'hold', 'holder', 'holders', 'holding', 'holds', 'hole', 'holes', 'holidays', 'home', 'honestly', 'hook', 'hooked', 'hope', 'hopefully', 'hoping', 'horror', 'horse', 'hot', 'hotels', 'hour', 'hours', 'house', 'houses', 'hubby', 'huge', 'hull', 'hungry', 'hurt', 'husband', 'ice', 'idea', 'ideas', 'illustrations', 'im', 'image', 'images', 'imagination', 'imagine', 'immediately', 'imperial', 'important', 'impossible', 'impressed', 'impressive', 'improve', 'improved', 'inch', 'inches', 'include', 'included', 'includes', 'including', 'increase', 'incredibly', 'individual', 'indoor', 'indoors', 'inexpensive', 'initial', 'initially', 'ink', 'insert', 'inside', 'instead', 'instruction', 'instructions', 'intended', 'interaction', 'interested', 'interesting', 'intrigue', 'introduce', 'introduced', 'investigator', 'investigators', 'investment', 'involved', 'involves', 'isn', 'issue', 'issues', 'item', 'items', 'jack', 'job', 'join', 'joy', 'jr', 'judge', 'juice', 'jump', 'jumping', 'junk', 'just', 'keeper', 'keeping', 'keeps', 'kept', 'key', 'keys', 'kick', 'kid', 'kids', 'kill', 'killing', 'kind', 'kinds', 'king', 'kingsburg', 'kit', 'kitchen', 'knew', 'knight', 'knights', 'knobs', 'knock', 'know', 'knowing', 'knows', 'lack', 'ladders', 'laminate', 'land', 'landing', 'lands', 'large', 'larger', 'lasted', 'lasting', 'later', 'laugh', 'laughing', 'laughs', 'launcher', 'law', 'lawn', 'lay', 'layout', 'lead', 'leads', 'leap', 'leapfrog', 'learn', 'learned', 'learning', 'leave', 'leaves', 'leaving', 'left', 'lego', 'legos', 'legs', 'length', 'lessons', 'let', 'lets', 'letter', 'letters', 'letting', 'level', 'levels', 'lever', 'lid', 'life', 'lift', 'light', 'lights', 'lightweight', 'like', 'liked', 'likely', 'likes', 'limit', 'limited', 'limiting', 'line', 'lines', 'list', 'listen', 'literally', 'little', 'live', 'living', 'll', 'llama', 'loads', 'local', 'location', 'lock', 'logic', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'loom', 'loops', 'loose', 'lose', 'losing', 'loss', 'lost', 'lot', 'lots', 'loud', 'love', 'lovecraft', 'loved', 'loves', 'loving', 'low', 'lower', 'lowercase', 'lowest', 'luck', 'luckily', 'lucky', 'magic', 'magnetic', 'magnets', 'mail', 'main', 'mainly', 'major', 'make', 'makes', 'making', 'man', 'manage', 'managed', 'mancala', 'maneuver', 'manipulate', 'manufacturer', 'map', 'marble', 'marbles', 'mark', 'marker', 'markers', 'market', 'marks', 'master', 'mat', 'match', 'matching', 'material', 'materials', 'math', 'matter', 'maximum', 'maybe', 'mean', 'meaning', 'means', 'meant', 'mechanic', 'mechanics', 'meet', 'melissa', 'members', 'memories', 'memory', 'mention', 'mentioned', 'mess', 'metal', 'middle', 'milk', 'mind', 'mini', 'miniature', 'miniatures', 'minimal', 'minimum', 'minis', 'minor', 'minute', 'minutes', 'mirror', 'misfit', 'miss', 'missiles', 'missing', 'mission', 'missions', 'mix', 'mixed', 'mo', 'mobile', 'mode', 'model', 'models', 'module', 'mom', 'moment', 'mommy', 'money', 'monkey', 'monkeys', 'monopoly', 'monster', 'monsters', 'month', 'months', 'monty', 'morning', 'mother', 'motor', 'mouth', 'moved', 'movement', 'moves', 'movie', 'movies', 'moving', 'mr', 'multiple', 'munchkin', 'music', 'musical', 'mythos', 'names', 'nature', 'nd', 'near', 'nearly', 'neat', 'necessary', 'neck', 'need', 'needed', 'needs', 'negative', 'nephew', 'new', 'newer', 'nice', 'nicely', 'niece', 'night', 'nights', 'noise', 'noises', 'noisy', 'non', 'normal', 'north', 'note', 'noted', 'notice', 'noticed', 'number', 'numbers', 'numerous', 'object', 'objects', 'obsessed', 'obvious', 'obviously', 'occasion', 'occasionally', 'occupied', 'offer', 'offered', 'offers', 'office', 'oh', 'ok', 'okay', 'old', 'older', 'oldest', 'olds', 'ones', 'online', 'open', 'opened', 'opening', 'operate', 'opinion', 'opponent', 'opponents', 'opportunity', 'option', 'options', 'orange', 'order', 'ordered', 'organs', 'original', 'originally', 'othello', 'ounce', 'outdoor', 'outside', 'overall', 'overly', 'pack', 'package', 'packaging', 'packed', 'pad', 'page', 'pages', 'paid', 'pain', 'paint', 'painted', 'painting', 'paints', 'pairs', 'paper', 'parent', 'parents', 'park', 'particular', 'particularly', 'parties', 'parts', 'party', 'pass', 'passed', 'past', 'patience', 'pattern', 'patterns', 'pawns', 'pay', 'paying', 'peg', 'pegs', 'pen', 'pencils', 'penny', 'people', 'perfect', 'perfectly', 'perform', 'person', 'personal', 'personally', 'pete', 'phase', 'phone', 'photo', 'piano', 'pick', 'picked', 'picking', 'picks', 'picture', 'pictures', 'piece', 'pieces', 'pile', 'pilot', 'pilots', 'pirate', 'pit', 'place', 'placed', 'placement', 'places', 'placing', 'plan', 'planet', 'planets', 'planning', 'plastic', 'plate', 'plates', 'play', 'playdoh', 'played', 'player', 'players', 'playing', 'plays', 'pleased', 'plenty', 'plug', 'plus', 'point', 'points', 'pole', 'pooh', 'pool', 'poor', 'pop', 'popper', 'pops', 'popular', 'portable', 'position', 'positive', 'possibilities', 'possible', 'possibly', 'post', 'pot', 'potential', 'potentially', 'potholders', 'pound', 'pounding', 'power', 'powerful', 'practice', 'pre', 'prefer', 'prefers', 'premise', 'prepared', 'preschool', 'preschooler', 'present', 'press', 'pressing', 'pretend', 'pretty', 'prevent', 'previous', 'previously', 'price', 'priced', 'prices', 'pricey', 'printed', 'probably', 'problem', 'problems', 'process', 'product', 'products', 'program', 'progress', 'projects', 'properly', 'properties', 'property', 'pros', 'provide', 'provided', 'provides', 'puck', 'pull', 'pulled', 'pulling', 'pulls', 'pump', 'purchase', 'purchased', 'purchasing', 'pure', 'purple', 'purpose', 'push', 'pushed', 'pushing', 'puts', 'putting', 'puzzle', 'puzzles', 'pvc', 'python', 'quality', 'quest', 'question', 'questions', 'quests', 'quick', 'quickly', 'quiet', 'quite', 'quot', 'race', 'racing', 'rainy', 'random', 'range', 'rarely', 'rate', 'rated', 'rating', 'ravensburger', 'rc', 'rd', 'reach', 'read', 'reading', 'reads', 'ready', 'real', 'realistic', 'reality', 'realize', 'realized', 'really', 'realm', 'reason', 'reasonable', 'reasons', 'rebel', 'receive', 'received', 'recently', 'recommend', 'recommended', 'red', 'register', 'regular', 'regularly', 'relatively', 'release', 'released', 'remember', 'remembered', 'remote', 'remove', 'rent', 'replace', 'replaced', 'replacement', 'replay', 'replayability', 'report', 'require', 'required', 'requires', 'research', 'resources', 'response', 'rest', 'result', 'results', 'return', 'returned', 'reveal', 'review', 'reviewer', 'reviewers', 'reviews', 'rewards', 'ride', 'rides', 'riding', 'right', 'ring', 'rings', 'risk', 'road', 'rocket', 'rockets', 'rocks', 'rody', 'role', 'roles', 'roll', 'rolled', 'rolling', 'rolls', 'roof', 'room', 'rooms', 'rope', 'rough', 'round', 'rounds', 'routes', 'rover', 'row', 'rudolph', 'ruin', 'rule', 'rules', 'run', 'running', 'runs', 'rush', 'safe', 'safety', 'said', 'sale', 'sand', 'sandbox', 'santa', 'sat', 'save', 'saw', 'say', 'saying', 'says', 'scenarios', 'scene', 'school', 'score', 'scoring', 'scrabble', 'screen', 'screw', 'search', 'seat', 'second', 'secondary', 'seconds', 'seeing', 'seen', 'select', 'selection', 'sell', 'send', 'sense', 'sent', 'series', 'seriously', 'session', 'set', 'sets', 'setting', 'settings', 'setup', 'seven', 'shake', 'shallow', 'shape', 'shaped', 'shapes', 'share', 'sharp', 'sheet', 'sheets', 'shelf', 'ship', 'shipping', 'ships', 'shoot', 'shop', 'shopping', 'short', 'shot', 'shouldn', 'showed', 'shown', 'shows', 'shut', 'sided', 'sides', 'sign', 'signs', 'silly', 'similar', 'simple', 'simply', 'sing', 'singing', 'single', 'sister', 'sit', 'site', 'sits', 'sitting', 'situation', 'size', 'sized', 'sketch', 'skill', 'skills', 'skip', 'sleep', 'slide', 'slightly', 'slinky', 'slots', 'slow', 'slowly', 'small', 'smaller', 'smart', 'smell', 'smile', 'smock', 'smooth', 'snap', 'snow', 'soft', 'sold', 'solid', 'solitaire', 'solo', 'solution', 'solve', 'solving', 'somewhat', 'son', 'song', 'songs', 'sons', 'soon', 'sorry', 'sort', 'sorting', 'sorts', 'sound', 'sounds', 'space', 'spaces', 'special', 'specific', 'speed', 'spell', 'spelling', 'spells', 'spend', 'spending', 'spent', 'spin', 'spinner', 'spinning', 'spins', 'spot', 'spots', 'square', 'st', 'stable', 'stack', 'stacked', 'stacking', 'stairs', 'stand', 'standard', 'standards', 'standing', 'stands', 'star', 'stars', 'start', 'started', 'starter', 'starting', 'starts', 'state', 'states', 'stay', 'stays', 'steal', 'step', 'stethoscope', 'stick', 'sticker', 'stickers', 'sticking', 'sticks', 'stocking', 'stood', 'stop', 'stops', 'storage', 'store', 'stores', 'stories', 'story', 'straight', 'strategic', 'strategies', 'strategy', 'strength', 'string', 'strong', 'stronger', 'structure', 'structures', 'stuck', 'students', 'stuff', 'stuffed', 'sturdier', 'sturdy', 'style', 'subject', 'subtle', 'successful', 'sugar', 'suggest', 'suggested', 'summer', 'sun', 'super', 'support', 'supports', 'suppose', 'supposed', 'sure', 'surface', 'surprise', 'surprised', 'survey', 'survived', 'sweet', 'swing', 'switch', 'symbols', 'table', 'tabletop', 'tactical', 'tad', 'tail', 'taken', 'takes', 'taking', 'talk', 'talking', 'tall', 'tape', 'target', 'task', 'tasks', 'tea', 'teach', 'teacher', 'teaches', 'teaching', 'team', 'teams', 'tech', 'technology', 'tell', 'telling', 'tells', 'tend', 'tends', 'tent', 'terms', 'test', 'testing', 'th', 'thanks', 'thanksgiving', 'theme', 'themed', 'thicker', 'thing', 'things', 'think', 'thinkfun', 'thinking', 'thinks', 'thomas', 'thought', 'thrilled', 'throw', 'thrown', 'ticket', 'tie', 'tight', 'tikes', 'tile', 'tiles', 'till', 'time', 'timeline', 'timer', 'times', 'tin', 'tiny', 'tip', 'tips', 'tire', 'tired', 'title', 'today', 'toddler', 'toddlers', 'token', 'tokens', 'told', 'ton', 'tonka', 'tons', 'took', 'tool', 'tools', 'toss', 'total', 'totally', 'touch', 'tough', 'toy', 'toys', 'track', 'tracks', 'trade', 'tradition', 'traditional', 'train', 'trains', 'traitor', 'travel', 'tray', 'treasure', 'treat', 'tree', 'trees', 'tricky', 'tried', 'tries', 'trim', 'trip', 'trips', 'trouble', 'truck', 'true', 'truly', 'try', 'trying', 'tub', 'tube', 'tune', 'tunes', 'tunnel', 'tunnels', 'turn', 'turned', 'turning', 'turns', 'tv', 'twice', 'twins', 'twist', 'twister', 'twists', 'type', 'types', 'typical', 'typically', 'underneath', 'understand', 'understanding', 'unfortunately', 'unique', 'unit', 'unless', 'unlike', 'uno', 'update', 'updated', 'upgrade', 'upgrades', 'upper', 'upset', 'upside', 'usb', 'use', 'used', 'useful', 'useless', 'uses', 'using', 'usual', 'usually', 'vacuum', 'value', 'variation', 'variations', 'variety', 'various', 've', 'velcro', 'version', 'versions', 'vertical', 'vibrant', 'victory', 'video', 'village', 'vinyl', 'visit', 'visual', 'visually', 'vocabulary', 'voice', 'volume', 'vs', 'wagon', 'wait', 'waiting', 'walk', 'walker', 'walking', 'wall', 'walls', 'want', 'wanted', 'wanting', 'wants', 'wars', 'wash', 'washable', 'wasn', 'waste', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weapon', 'weapons', 'wear', 'weather', 'website', 'week', 'weeks', 'weight', 'weird', 'went', 'weren', 'wheel', 'wheels', 'white', 'wide', 'wife', 'wild', 'willing', 'win', 'wind', 'wing', 'wings', 'winner', 'winning', 'wins', 'winter', 'wire', 'wish', 'withstand', 'won', 'wonder', 'wonderful', 'wood', 'wooden', 'word', 'words', 'work', 'worked', 'worker', 'working', 'workout', 'works', 'world', 'worried', 'worry', 'worse', 'worth', 'worthwhile', 'wouldn', 'write', 'writing', 'written', 'wrong', 'wrote', 'xmas', 'yahtzee', 'yard', 'yeah', 'year', 'years', 'yellow', 'yes', 'yo', 'young', 'younger', 'youngest', 'youth', 'youtube', 'yr', 'yrs', 'zero', 'zombie', 'zombies']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 aa\n",
      "23 abc\n",
      "59 abilities\n",
      "101 ability\n",
      "353 able\n",
      "20 absolutely\n",
      "148 abuse\n",
      "29 access\n",
      "24 accessories\n",
      "81 accidentally\n",
      "62 accurate\n",
      "27 act\n",
      "40 action\n",
      "53 actions\n",
      "80 activities\n",
      "336 activity\n",
      "218 actual\n",
      "96 actually\n",
      "48 adapter\n",
      "187 add\n",
      "76 added\n",
      "86 addictive\n",
      "39 adding\n",
      "43 addition\n",
      "157 additional\n",
      "265 adds\n",
      "70 adjust\n",
      "31 admit\n",
      "42 adorable\n",
      "22 adult\n",
      "23 adults\n",
      "349 advance\n",
      "255 advanced\n",
      "186 advantage\n",
      "48 adventure\n",
      "49 adventures\n",
      "109 affair\n",
      "22 affect\n",
      "21 afraid\n",
      "86 age\n",
      "26 aged\n",
      "23 ages\n",
      "95 ago\n",
      "41 agree\n",
      "82 ahead\n",
      "20 air\n",
      "26 alike\n",
      "29 allow\n",
      "85 allowing\n",
      "214 allows\n",
      "25 alot\n",
      "46 alphabet\n",
      "92 alternative\n",
      "92 amazing\n",
      "100 amazingly\n",
      "55 amazon\n",
      "34 american\n",
      "142 ancient\n",
      "34 angle\n",
      "42 animal\n",
      "30 animals\n",
      "57 annoying\n",
      "72 answer\n",
      "111 answers\n",
      "48 apart\n",
      "74 apparently\n",
      "108 appeal\n",
      "52 appealing\n",
      "32 appear\n",
      "82 appears\n",
      "67 apples\n",
      "35 appreciate\n",
      "22 appropriate\n",
      "58 area\n",
      "22 aren\n",
      "41 arkham\n",
      "28 arm\n",
      "44 armies\n",
      "23 arms\n",
      "51 arrived\n",
      "94 art\n",
      "27 arts\n",
      "27 artwork\n",
      "134 aside\n",
      "29 ask\n",
      "106 asked\n",
      "43 asking\n",
      "45 asks\n",
      "27 aspect\n",
      "292 assemble\n",
      "108 assembled\n",
      "33 assembly\n",
      "65 assistance\n",
      "307 attach\n",
      "21 attached\n",
      "213 attack\n",
      "101 attempt\n",
      "25 attempting\n",
      "67 attention\n",
      "24 available\n",
      "179 average\n",
      "160 avoid\n",
      "20 aware\n",
      "39 away\n",
      "27 awesome\n",
      "36 awhile\n",
      "218 babies\n",
      "150 baby\n",
      "166 backwards\n",
      "90 bad\n",
      "30 bag\n",
      "31 balance\n",
      "28 balanced\n",
      "181 ball\n",
      "116 balls\n",
      "46 bananagrams\n",
      "23 bang\n",
      "50 bank\n",
      "20 barely\n",
      "74 barrel\n",
      "78 base\n",
      "34 based\n",
      "50 basic\n",
      "33 basically\n",
      "33 basics\n",
      "74 basket\n",
      "87 batteries\n",
      "20 battery\n",
      "26 battle\n",
      "21 beads\n",
      "27 beans\n",
      "435 bear\n",
      "514 beat\n",
      "26 beating\n",
      "422 beautiful\n",
      "109 bed\n",
      "41 beds\n",
      "22 begin\n",
      "291 beginner\n",
      "478 beginning\n",
      "73 behavior\n",
      "32 believe\n",
      "100 bench\n",
      "56 bend\n",
      "148 benefit\n",
      "34 bent\n",
      "126 best\n",
      "946 better\n",
      "37 beware\n",
      "77 big\n",
      "63 bigger\n",
      "356 biggest\n",
      "155 bin\n",
      "83 bird\n",
      "73 birthday\n",
      "19 bit\n",
      "24 bite\n",
      "954 black\n",
      "29 blank\n",
      "569 blast\n",
      "29 block\n",
      "130 blocks\n",
      "172 blow\n",
      "38 blue\n",
      "62 board\n",
      "23 boards\n",
      "142 body\n",
      "37 boggle\n",
      "24 bonus\n",
      "116 book\n",
      "77 books\n",
      "36 bored\n",
      "65 boring\n",
      "66 born\n",
      "82 bother\n",
      "58 bought\n",
      "22 bounce\n",
      "36 bouncing\n",
      "35 box\n",
      "21 boxes\n",
      "24 boy\n",
      "32 boys\n",
      "225 brain\n",
      "226 brand\n",
      "79 bread\n",
      "20 break\n",
      "82 breaking\n",
      "65 bright\n",
      "36 brightly\n",
      "50 bring\n",
      "36 brings\n",
      "54 broke\n",
      "88 broken\n",
      "46 brother\n",
      "88 brought\n",
      "89 bruder\n",
      "599 bucks\n",
      "186 build\n",
      "70 building\n",
      "229 buildings\n",
      "37 built\n",
      "25 bumble\n",
      "24 bunch\n",
      "323 bunnies\n",
      "824 bunny\n",
      "112 bus\n",
      "1425 busy\n",
      "83 butterflies\n",
      "69 butterfly\n",
      "23 button\n",
      "55 buttons\n",
      "41 buy\n",
      "67 buying\n",
      "34 called\n",
      "198 came\n",
      "68 camelot\n",
      "222 campaign\n",
      "34 camping\n",
      "41 candy\n",
      "30 candyland\n",
      "32 cans\n",
      "35 car\n",
      "66 card\n",
      "27 cardboard\n",
      "71 cards\n",
      "39 care\n",
      "70 careful\n",
      "19 carpet\n",
      "39 carrot\n",
      "107 carry\n",
      "76 carrying\n",
      "20 cars\n",
      "102 cart\n",
      "42 case\n",
      "149 cash\n",
      "135 castle\n",
      "140 cat\n",
      "40 catan\n",
      "57 catch\n",
      "54 categories\n",
      "23 caterpillars\n",
      "114 caught\n",
      "140 cause\n",
      "47 center\n",
      "23 certain\n",
      "154 certainly\n",
      "57 chain\n",
      "30 challenge\n",
      "62 challenges\n",
      "53 challenging\n",
      "30 chance\n",
      "21 chances\n",
      "31 change\n",
      "702 changed\n",
      "44 changes\n",
      "667 changing\n",
      "33 channel\n",
      "81 character\n",
      "44 characters\n",
      "39 charge\n",
      "113 charging\n",
      "22 cheap\n",
      "23 cheaper\n",
      "28 cheaply\n",
      "502 check\n",
      "20 chess\n",
      "42 chest\n",
      "60 chew\n",
      "65 child\n",
      "49 childhood\n",
      "21 children\n",
      "214 chips\n",
      "22 choice\n",
      "110 choices\n",
      "97 choking\n",
      "38 choose\n",
      "36 chooses\n",
      "21 chose\n",
      "24 chosen\n",
      "40 christmas\n",
      "111 circle\n",
      "23 class\n",
      "20 classic\n",
      "30 classroom\n",
      "33 clean\n",
      "28 clear\n",
      "42 clearly\n",
      "40 click\n",
      "22 climb\n",
      "45 climber\n",
      "23 climbing\n",
      "55 clip\n",
      "28 clock\n",
      "99 close\n",
      "319 closet\n",
      "117 cloth\n",
      "124 clothes\n",
      "35 clue\n",
      "536 clues\n",
      "20 coins\n",
      "41 collect\n",
      "32 collection\n",
      "22 college\n",
      "21 color\n",
      "418 colored\n",
      "357 colorful\n",
      "27 coloring\n",
      "74 colors\n",
      "23 combat\n",
      "25 come\n",
      "102 comes\n",
      "50 comfortable\n",
      "25 comfortably\n",
      "33 coming\n",
      "29 commodity\n",
      "44 company\n",
      "21 compare\n",
      "93 compared\n",
      "31 compete\n",
      "131 competition\n",
      "29 competitive\n",
      "77 complain\n",
      "28 complaint\n",
      "84 complete\n",
      "21 completed\n",
      "102 completely\n",
      "80 completing\n",
      "36 complex\n",
      "125 complicated\n",
      "28 components\n",
      "23 computer\n",
      "43 concept\n",
      "24 concern\n",
      "21 concerned\n",
      "30 condition\n",
      "47 confusing\n",
      "20 connect\n",
      "29 cons\n",
      "51 consider\n",
      "62 considered\n",
      "24 considering\n",
      "92 consists\n",
      "39 constant\n",
      "48 constantly\n",
      "34 constructed\n",
      "24 construction\n",
      "37 container\n",
      "23 containers\n",
      "51 contains\n",
      "26 continue\n",
      "118 continues\n",
      "22 control\n",
      "24 controller\n",
      "151 controls\n",
      "43 conversation\n",
      "53 cool\n",
      "38 cooperative\n",
      "36 coordination\n",
      "86 cooties\n",
      "21 copy\n",
      "39 core\n",
      "25 corners\n",
      "23 correct\n",
      "58 correctly\n",
      "45 cost\n",
      "78 costs\n",
      "37 couldn\n",
      "121 count\n",
      "108 counters\n",
      "103 counting\n",
      "223 counts\n",
      "153 couple\n",
      "20 course\n",
      "20 cousin\n",
      "57 cover\n",
      "24 craft\n",
      "19 cranky\n",
      "22 crawl\n",
      "22 crayola\n",
      "41 crayons\n",
      "20 crazy\n",
      "22 create\n",
      "20 created\n",
      "68 creating\n",
      "50 creative\n",
      "59 creativity\n",
      "64 credit\n",
      "29 creeper\n",
      "35 creepers\n",
      "26 crew\n",
      "75 crib\n",
      "39 crowd\n",
      "20 cthulhu\n",
      "33 cube\n",
      "24 cup\n",
      "28 current\n",
      "29 currently\n",
      "32 cut\n",
      "71 cute\n",
      "41 dad\n",
      "25 daddy\n",
      "35 daily\n",
      "33 damage\n",
      "32 dance\n",
      "35 dangerous\n",
      "65 dark\n",
      "278 date\n",
      "49 daughter\n",
      "28 daughters\n",
      "41 day\n",
      "46 days\n",
      "69 dd\n",
      "939 dead\n",
      "61 deal\n",
      "338 death\n",
      "191 decent\n",
      "26 decide\n",
      "108 decided\n",
      "23 decisions\n",
      "21 deck\n",
      "46 decks\n",
      "37 deep\n",
      "118 definitely\n",
      "21 degree\n",
      "29 depending\n",
      "179 depends\n",
      "53 depth\n",
      "49 descent\n",
      "25 described\n",
      "21 description\n",
      "284 design\n",
      "21 designed\n",
      "46 designs\n",
      "73 despite\n",
      "20 detailed\n",
      "41 details\n",
      "23 determine\n",
      "57 dial\n",
      "103 dice\n",
      "96 did\n",
      "26 didn\n",
      "21 didnt\n",
      "51 die\n",
      "25 difference\n",
      "43 different\n",
      "29 differently\n",
      "23 difficult\n",
      "37 difficulty\n",
      "26 direction\n",
      "20 directions\n",
      "33 disappointed\n",
      "293 disappointing\n",
      "445 disappointment\n",
      "405 discard\n",
      "132 discovered\n",
      "35 display\n",
      "644 districts\n",
      "250 doctor\n",
      "55 does\n",
      "24 doesn\n",
      "44 doesnt\n",
      "72 dog\n",
      "20 doh\n",
      "110 doing\n",
      "28 doll\n",
      "26 dollar\n",
      "28 dollars\n",
      "34 dolls\n",
      "50 dominion\n",
      "36 don\n",
      "593 dont\n",
      "517 doom\n",
      "21 door\n",
      "60 doors\n",
      "39 dot\n",
      "142 dots\n",
      "97 double\n",
      "24 doubt\n",
      "39 doug\n",
      "25 downside\n",
      "29 drag\n",
      "1015 drain\n",
      "39 draw\n",
      "82 drawback\n",
      "36 drawer\n",
      "30 drawing\n",
      "51 drawn\n",
      "30 draws\n",
      "56 drive\n",
      "34 driving\n",
      "23 drop\n",
      "28 dropping\n",
      "35 drum\n",
      "45 dry\n",
      "174 dumb\n",
      "26 dungeon\n",
      "45 dunwich\n",
      "35 duplo\n",
      "28 durability\n",
      "46 durable\n",
      "38 dvd\n",
      "96 ear\n",
      "47 earlier\n",
      "25 early\n",
      "100 ears\n",
      "46 ease\n",
      "72 easel\n",
      "412 easier\n",
      "22 easily\n",
      "80 easy\n",
      "20 eat\n",
      "64 ebay\n",
      "20 edge\n",
      "25 edges\n",
      "149 edition\n",
      "438 education\n",
      "898 educational\n",
      "28 effect\n",
      "30 effects\n",
      "34 effort\n",
      "134 eggs\n",
      "23 elder\n",
      "227 electric\n",
      "50 electronic\n",
      "25 element\n",
      "33 elements\n",
      "34 elf\n",
      "37 empire\n",
      "43 encounter\n",
      "198 encourage\n",
      "32 encourages\n",
      "33 end\n",
      "46 ended\n",
      "23 endless\n",
      "318 ends\n",
      "75 energy\n",
      "24 engine\n",
      "30 engines\n",
      "65 english\n",
      "27 enjoy\n",
      "32 enjoyable\n",
      "41 enjoyed\n",
      "44 enjoying\n",
      "489 enjoyment\n",
      "60 enjoys\n",
      "273 entertain\n",
      "47 entertained\n",
      "31 entertaining\n",
      "161 entertainment\n",
      "25 entire\n",
      "40 entirely\n",
      "64 erase\n",
      "30 especially\n",
      "90 essentially\n",
      "29 etch\n",
      "27 euro\n",
      "217 eve\n",
      "32 evening\n",
      "43 events\n",
      "19 eventually\n",
      "25 everyday\n",
      "33 everytime\n",
      "34 evil\n",
      "60 exact\n",
      "45 exactly\n",
      "21 example\n",
      "29 excellent\n",
      "27 exception\n",
      "91 excited\n",
      "95 excitement\n",
      "157 exciting\n",
      "27 exercise\n",
      "136 expansion\n",
      "49 expansions\n",
      "32 expect\n",
      "20 expected\n",
      "279 expecting\n",
      "135 expensive\n",
      "111 experience\n",
      "87 experiment\n",
      "30 explain\n",
      "85 explained\n",
      "153 explore\n",
      "26 extra\n",
      "46 extremely\n",
      "196 eye\n",
      "67 eyes\n",
      "59 face\n",
      "59 faces\n",
      "145 fact\n",
      "42 factor\n",
      "192 fail\n",
      "39 fair\n",
      "49 fairly\n",
      "128 falcon\n",
      "165 fall\n",
      "43 falling\n",
      "44 falls\n",
      "62 familiar\n",
      "37 families\n",
      "633 family\n",
      "99 fan\n",
      "60 fans\n",
      "78 fantastic\n",
      "103 fantasy\n",
      "294 far\n",
      "191 fashion\n",
      "53 fashioned\n",
      "28 fast\n",
      "323 faster\n",
      "47 father\n",
      "72 fault\n",
      "44 favor\n",
      "245 favorite\n",
      "38 favorites\n",
      "59 feature\n",
      "105 features\n",
      "32 feel\n",
      "54 feeling\n",
      "19 feels\n",
      "23 feet\n",
      "20 fell\n",
      "27 felt\n",
      "61 ffg\n",
      "28 field\n",
      "29 fight\n",
      "31 fighter\n",
      "159 fighters\n",
      "80 fighting\n",
      "41 figure\n",
      "53 figured\n",
      "30 figuring\n",
      "105 filled\n",
      "53 filling\n",
      "32 fills\n",
      "191 final\n",
      "34 finally\n",
      "56 finding\n",
      "68 fine\n",
      "48 fingers\n",
      "21 finish\n",
      "100 finished\n",
      "56 fish\n",
      "26 fisher\n",
      "260 fishing\n",
      "72 fit\n",
      "26 fits\n",
      "23 flat\n",
      "56 flexible\n",
      "27 flies\n",
      "115 flight\n",
      "85 flimsy\n",
      "49 flip\n",
      "137 floor\n",
      "22 floors\n",
      "119 fluxx\n",
      "127 fly\n",
      "67 flying\n",
      "25 foam\n",
      "52 focus\n",
      "30 fold\n",
      "23 folks\n",
      "71 follow\n",
      "34 following\n",
      "95 food\n",
      "24 foot\n",
      "32 force\n",
      "23 forever\n",
      "62 forget\n",
      "39 form\n",
      "64 forth\n",
      "28 fortunately\n",
      "113 forward\n",
      "20 fourth\n",
      "82 frame\n",
      "28 free\n",
      "30 frequently\n",
      "125 fresh\n",
      "42 friend\n",
      "332 friendly\n",
      "52 friends\n",
      "21 frog\n",
      "73 frogs\n",
      "82 fruit\n",
      "41 frustrated\n",
      "2520 frustrating\n",
      "58 frustration\n",
      "25 fully\n",
      "56 fun\n",
      "31 funny\n",
      "6995 furniture\n",
      "91 future\n",
      "37 gain\n",
      "77 game\n",
      "1230 gameplay\n",
      "86 gamer\n",
      "21 gamers\n",
      "32 games\n",
      "30 gaming\n",
      "156 garage\n",
      "28 garbage\n",
      "75 garden\n",
      "58 gate\n",
      "38 gather\n",
      "22 gathering\n",
      "20 gave\n",
      "20 gear\n",
      "384 gears\n",
      "391 general\n",
      "21 generally\n",
      "376 generic\n",
      "57 gets\n",
      "104 getting\n",
      "114 gift\n",
      "141 gifts\n",
      "81 girl\n",
      "62 girls\n",
      "106 given\n",
      "30 gives\n",
      "24 giving\n",
      "47 glad\n",
      "25 glass\n",
      "82 glue\n",
      "29 goal\n",
      "186 goals\n",
      "383 goes\n",
      "52 going\n",
      "45 gold\n",
      "1335 gone\n",
      "23 good\n",
      "910 goods\n",
      "79 got\n",
      "37 gotten\n",
      "25 grab\n",
      "62 grade\n",
      "72 grail\n",
      "105 grand\n",
      "37 grandchildren\n",
      "22 granddaughter\n",
      "29 grandkids\n",
      "228 grandma\n",
      "27 grandparents\n",
      "30 grandson\n",
      "21 grandsons\n",
      "2324 graphics\n",
      "94 gras\n",
      "42 grasp\n",
      "29 grass\n",
      "48 great\n",
      "208 greatly\n",
      "43 green\n",
      "66 grew\n",
      "51 grid\n",
      "33 grocery\n",
      "25 ground\n",
      "150 group\n",
      "33 groups\n",
      "49 grow\n",
      "22 growing\n",
      "25 grown\n",
      "114 grows\n",
      "26 guess\n",
      "297 guests\n",
      "155 gun\n",
      "220 guy\n",
      "28 guys\n",
      "53 half\n",
      "58 hammer\n",
      "28 hand\n",
      "61 handle\n",
      "219 handling\n",
      "481 hands\n",
      "55 handy\n",
      "20 hang\n",
      "68 happen\n",
      "21 happened\n",
      "37 happens\n",
      "133 happy\n",
      "338 hard\n",
      "40 harder\n",
      "87 hardly\n",
      "32 hardwood\n",
      "64 harold\n",
      "38 hasn\n",
      "19 hate\n",
      "34 haven\n",
      "88 having\n",
      "24 hazard\n",
      "111 head\n",
      "54 heads\n",
      "83 hear\n",
      "30 heard\n",
      "354 hearing\n",
      "74 heart\n",
      "35 heavy\n",
      "37 height\n",
      "124 held\n",
      "57 heli\n",
      "52 helicopter\n",
      "37 helicopters\n",
      "26 help\n",
      "233 helped\n",
      "61 helpful\n",
      "320 helping\n",
      "40 helps\n",
      "25 heroes\n",
      "213 hey\n",
      "26 hide\n",
      "239 high\n",
      "21 higher\n",
      "64 highest\n",
      "105 highly\n",
      "68 hilarious\n",
      "101 hill\n",
      "25 hippo\n",
      "20 hippos\n",
      "161 history\n",
      "23 hit\n",
      "34 hitting\n",
      "33 hold\n",
      "78 holder\n",
      "34 holders\n",
      "19 holding\n",
      "42 holds\n",
      "23 hole\n",
      "59 holes\n",
      "44 holidays\n",
      "52 home\n",
      "142 honestly\n",
      "274 hook\n",
      "385 hooked\n",
      "20 hope\n",
      "119 hopefully\n",
      "21 hoping\n",
      "26 horror\n",
      "44 horse\n",
      "193 hot\n",
      "73 hotels\n",
      "250 hour\n",
      "25 hours\n",
      "22 house\n",
      "24 houses\n",
      "20 hubby\n",
      "27 huge\n",
      "21 hull\n",
      "62 hungry\n",
      "66 hurt\n",
      "72 husband\n",
      "27 ice\n",
      "85 idea\n",
      "42 ideas\n",
      "41 illustrations\n",
      "23 im\n",
      "30 image\n",
      "21 images\n",
      "33 imagination\n",
      "76 imagine\n",
      "171 immediately\n",
      "89 imperial\n",
      "79 important\n",
      "28 impossible\n",
      "31 impressed\n",
      "29 impressive\n",
      "37 improve\n",
      "31 improved\n",
      "38 inch\n",
      "21 inches\n",
      "19 include\n",
      "35 included\n",
      "23 includes\n",
      "34 including\n",
      "38 increase\n",
      "173 incredibly\n",
      "241 individual\n",
      "123 indoor\n",
      "20 indoors\n",
      "22 inexpensive\n",
      "42 initial\n",
      "31 initially\n",
      "20 ink\n",
      "99 insert\n",
      "120 inside\n",
      "41 instead\n",
      "34 instruction\n",
      "31 instructions\n",
      "21 intended\n",
      "21 interaction\n",
      "27 interested\n",
      "86 interesting\n",
      "26 intrigue\n",
      "22 introduce\n",
      "293 introduced\n",
      "88 investigator\n",
      "59 investigators\n",
      "167 investment\n",
      "105 involved\n",
      "32 involves\n",
      "85 isn\n",
      "24 issue\n",
      "26 issues\n",
      "22 item\n",
      "59 items\n",
      "20 jack\n",
      "29 job\n",
      "28 join\n",
      "2154 joy\n",
      "32 jr\n",
      "65 judge\n",
      "144 juice\n",
      "88 jump\n",
      "57 jumping\n",
      "25 junk\n",
      "32 just\n",
      "303 keeper\n",
      "1755 keeping\n",
      "59 keeps\n",
      "175 kept\n",
      "23 key\n",
      "40 keys\n",
      "35 kick\n",
      "25 kid\n",
      "80 kids\n",
      "90 kill\n",
      "69 killing\n",
      "28 kind\n",
      "34 kinds\n",
      "29 king\n",
      "478 kingsburg\n",
      "29 kit\n",
      "27 kitchen\n",
      "34 knew\n",
      "74 knight\n",
      "29 knights\n",
      "20 knobs\n",
      "30 knock\n",
      "23 know\n",
      "73 knowing\n",
      "20 knows\n",
      "212 lack\n",
      "118 ladders\n",
      "37 laminate\n",
      "29 land\n",
      "149 landing\n",
      "58 lands\n",
      "43 large\n",
      "33 larger\n",
      "31 lasted\n",
      "30 lasting\n",
      "90 later\n",
      "26 laugh\n",
      "34 laughing\n",
      "430 laughs\n",
      "110 launcher\n",
      "354 law\n",
      "70 lawn\n",
      "23 lay\n",
      "20 layout\n",
      "123 lead\n",
      "87 leads\n",
      "66 leap\n",
      "54 leapfrog\n",
      "58 learn\n",
      "201 learned\n",
      "42 learning\n",
      "160 leave\n",
      "238 leaves\n",
      "25 leaving\n",
      "212 left\n",
      "58 lego\n",
      "83 legos\n",
      "154 legs\n",
      "148 length\n",
      "85 lessons\n",
      "23 let\n",
      "2076 lets\n",
      "144 letter\n",
      "68 letters\n",
      "289 letting\n",
      "23 level\n",
      "52 levels\n",
      "155 lever\n",
      "45 lid\n",
      "66 life\n",
      "21 lift\n",
      "20 light\n",
      "30 lights\n",
      "1686 lightweight\n",
      "56 like\n",
      "43 liked\n",
      "423 likely\n",
      "24 likes\n",
      "41 limit\n",
      "30 limited\n",
      "36 limiting\n",
      "24 line\n",
      "41 lines\n",
      "584 list\n",
      "163 listen\n",
      "316 literally\n",
      "77 little\n",
      "294 live\n",
      "203 living\n",
      "24 ll\n",
      "45 llama\n",
      "34 loads\n",
      "36 local\n",
      "133 location\n",
      "19 lock\n",
      "50 logic\n",
      "122 lol\n",
      "764 long\n",
      "255 longer\n",
      "110 look\n",
      "1313 looked\n",
      "32 looking\n",
      "462 looks\n",
      "23 loom\n",
      "1133 loops\n",
      "27 loose\n",
      "89 lose\n",
      "66 losing\n",
      "180 loss\n",
      "23 lost\n",
      "36 lot\n",
      "29 lots\n",
      "94 loud\n",
      "32 love\n",
      "41 lovecraft\n",
      "33 loved\n",
      "37 loves\n",
      "69 loving\n",
      "36 low\n",
      "26 lower\n",
      "995 lowercase\n",
      "490 lowest\n",
      "217 luck\n",
      "38 luckily\n",
      "27 lucky\n",
      "35 magic\n",
      "25 magnetic\n",
      "40 magnets\n",
      "45 mail\n",
      "32 main\n",
      "68 mainly\n",
      "39 major\n",
      "111 make\n",
      "36 makes\n",
      "62 making\n",
      "37 man\n",
      "84 manage\n",
      "26 managed\n",
      "67 mancala\n",
      "43 maneuver\n",
      "38 manipulate\n",
      "92 manufacturer\n",
      "89 map\n",
      "23 marble\n",
      "216 marbles\n",
      "58 mark\n",
      "27 marker\n",
      "86 markers\n",
      "35 market\n",
      "38 marks\n",
      "94 master\n",
      "52 mat\n",
      "22 match\n",
      "40 matching\n",
      "35 material\n",
      "67 materials\n",
      "47 math\n",
      "53 matter\n",
      "52 maximum\n",
      "21 maybe\n",
      "68 mean\n",
      "60 meaning\n",
      "25 means\n",
      "130 meant\n",
      "31 mechanic\n",
      "72 mechanics\n",
      "60 meet\n",
      "41 melissa\n",
      "54 members\n",
      "332 memories\n",
      "29 memory\n",
      "52 mention\n",
      "31 mentioned\n",
      "55 mess\n",
      "26 metal\n",
      "39 middle\n",
      "38 milk\n",
      "87 mind\n",
      "50 mini\n",
      "80 miniature\n",
      "27 miniatures\n",
      "22 minimal\n",
      "27 minimum\n",
      "380 minis\n",
      "83 minor\n",
      "92 minute\n",
      "129 minutes\n",
      "301 mirror\n",
      "495 misfit\n",
      "71 miss\n",
      "24 missiles\n",
      "49 missing\n",
      "85 mission\n",
      "76 missions\n",
      "21 mix\n",
      "51 mixed\n",
      "37 mo\n",
      "79 mobile\n",
      "60 mode\n",
      "63 model\n",
      "104 models\n",
      "19 module\n",
      "86 mom\n",
      "87 moment\n",
      "222 mommy\n",
      "34 money\n",
      "24 monkey\n",
      "23 monkeys\n",
      "43 monopoly\n",
      "41 monster\n",
      "52 monsters\n",
      "39 month\n",
      "62 months\n",
      "46 monty\n",
      "39 morning\n",
      "503 mother\n",
      "136 motor\n",
      "120 mouth\n",
      "44 moved\n",
      "23 movement\n",
      "23 moves\n",
      "77 movie\n",
      "23 movies\n",
      "658 moving\n",
      "28 mr\n",
      "597 multiple\n",
      "80 munchkin\n",
      "66 music\n",
      "188 musical\n",
      "26 mythos\n",
      "120 names\n",
      "29 nature\n",
      "43 nd\n",
      "88 near\n",
      "42 nearly\n",
      "24 neat\n",
      "76 necessary\n",
      "21 neck\n",
      "25 need\n",
      "28 needed\n",
      "58 needs\n",
      "268 negative\n",
      "110 nephew\n",
      "26 new\n",
      "57 newer\n",
      "26 nice\n",
      "45 nicely\n",
      "19 niece\n",
      "30 night\n",
      "38 nights\n",
      "30 noise\n",
      "28 noises\n",
      "19 noisy\n",
      "35 non\n",
      "38 normal\n",
      "58 north\n",
      "84 note\n",
      "53 noted\n",
      "2338 notice\n",
      "313 noticed\n",
      "31 number\n",
      "93 numbers\n",
      "304 numerous\n",
      "60 object\n",
      "19 objects\n",
      "192 obsessed\n",
      "65 obvious\n",
      "48 obviously\n",
      "27 occasion\n",
      "28 occasionally\n",
      "63 occupied\n",
      "53 offer\n",
      "42 offered\n",
      "28 offers\n",
      "37 office\n",
      "77 oh\n",
      "41 ok\n",
      "193 okay\n",
      "126 old\n",
      "28 older\n",
      "226 oldest\n",
      "37 olds\n",
      "22 ones\n",
      "31 online\n",
      "117 open\n",
      "271 opened\n",
      "25 opening\n",
      "31 operate\n",
      "20 opinion\n",
      "33 opponent\n",
      "80 opponents\n",
      "47 opportunity\n",
      "50 option\n",
      "38 options\n",
      "76 orange\n",
      "74 order\n",
      "66 ordered\n",
      "67 organs\n",
      "30 original\n",
      "191 originally\n",
      "47 othello\n",
      "39 ounce\n",
      "48 outdoor\n",
      "115 outside\n",
      "56 overall\n",
      "138 overly\n",
      "32 pack\n",
      "76 package\n",
      "45 packaging\n",
      "36 packed\n",
      "164 pad\n",
      "157 page\n",
      "58 pages\n",
      "33 paid\n",
      "92 pain\n",
      "39 paint\n",
      "40 painted\n",
      "34 painting\n",
      "31 paints\n",
      "82 pairs\n",
      "35 paper\n",
      "21 parent\n",
      "34 parents\n",
      "123 park\n",
      "38 particular\n",
      "22 particularly\n",
      "55 parties\n",
      "552 parts\n",
      "27 party\n",
      "310 pass\n",
      "69 passed\n",
      "27 past\n",
      "22 patience\n",
      "213 pattern\n",
      "22 patterns\n",
      "49 pawns\n",
      "45 pay\n",
      "60 paying\n",
      "21 peg\n",
      "198 pegs\n",
      "69 pen\n",
      "48 pencils\n",
      "23 penny\n",
      "142 people\n",
      "127 perfect\n",
      "262 perfectly\n",
      "901 perform\n",
      "21 person\n",
      "49 personal\n",
      "70 personally\n",
      "49 pete\n",
      "33 phase\n",
      "32 phone\n",
      "293 photo\n",
      "65 piano\n",
      "42 pick\n",
      "60 picked\n",
      "34 picking\n",
      "32 picks\n",
      "72 picture\n",
      "22 pictures\n",
      "38 piece\n",
      "484 pieces\n",
      "40 pile\n",
      "41 pilot\n",
      "2992 pilots\n",
      "914 pirate\n",
      "628 pit\n",
      "889 place\n",
      "1167 placed\n",
      "320 placement\n",
      "88 places\n",
      "89 placing\n",
      "145 plan\n",
      "24 planet\n",
      "221 planets\n",
      "291 planning\n",
      "31 plastic\n",
      "114 plate\n",
      "41 plates\n",
      "23 play\n",
      "111 playdoh\n",
      "30 played\n",
      "32 player\n",
      "24 players\n",
      "47 playing\n",
      "35 plays\n",
      "54 pleased\n",
      "20 plenty\n",
      "49 plug\n",
      "32 plus\n",
      "114 point\n",
      "22 points\n",
      "22 pole\n",
      "24 pooh\n",
      "22 pool\n",
      "73 poor\n",
      "23 pop\n",
      "20 popper\n",
      "83 pops\n",
      "44 popular\n",
      "52 portable\n",
      "25 position\n",
      "27 positive\n",
      "35 possibilities\n",
      "23 possible\n",
      "90 possibly\n",
      "48 post\n",
      "23 pot\n",
      "56 potential\n",
      "447 potentially\n",
      "26 potholders\n",
      "42 pound\n",
      "460 pounding\n",
      "26 power\n",
      "23 powerful\n",
      "23 practice\n",
      "21 pre\n",
      "35 prefer\n",
      "246 prefers\n",
      "268 premise\n",
      "112 prepared\n",
      "49 preschool\n",
      "386 preschooler\n",
      "91 present\n",
      "21 press\n",
      "25 pressing\n",
      "24 pretend\n",
      "48 pretty\n",
      "40 prevent\n",
      "45 previous\n",
      "40 previously\n",
      "48 price\n",
      "149 priced\n",
      "35 prices\n",
      "40 pricey\n",
      "37 printed\n",
      "236 probably\n",
      "356 problem\n",
      "46 problems\n",
      "51 process\n",
      "49 product\n",
      "241 products\n",
      "42 program\n",
      "38 progress\n",
      "94 projects\n",
      "39 properly\n",
      "169 properties\n",
      "508 property\n",
      "223 pros\n",
      "19 provide\n",
      "505 provided\n",
      "57 provides\n",
      "74 puck\n",
      "156 pull\n",
      "81 pulled\n",
      "145 pulling\n",
      "284 pulls\n",
      "32 pump\n",
      "358 purchase\n",
      "180 purchased\n",
      "23 purchasing\n",
      "61 pure\n",
      "22 purple\n",
      "25 purpose\n",
      "24 push\n",
      "23 pushed\n",
      "21 pushing\n",
      "27 puts\n",
      "95 putting\n",
      "25 puzzle\n",
      "107 puzzles\n",
      "21 pvc\n",
      "26 python\n",
      "51 quality\n",
      "33 quest\n",
      "44 question\n",
      "25 questions\n",
      "47 quests\n",
      "35 quick\n",
      "39 quickly\n",
      "36 quiet\n",
      "255 quite\n",
      "145 quot\n",
      "31 race\n",
      "99 racing\n",
      "227 rainy\n",
      "45 random\n",
      "44 range\n",
      "29 rarely\n",
      "1494 rate\n",
      "111 rated\n",
      "32 rating\n",
      "51 ravensburger\n",
      "23 rc\n",
      "44 rd\n",
      "201 reach\n",
      "66 read\n",
      "26 reading\n",
      "23 reads\n",
      "628 ready\n",
      "21 real\n",
      "143 realistic\n",
      "150 reality\n",
      "20 realize\n",
      "27 realized\n",
      "22 really\n",
      "90 realm\n",
      "27 reason\n",
      "23 reasonable\n",
      "40 reasons\n",
      "23 rebel\n",
      "36 receive\n",
      "212 received\n",
      "25 recently\n",
      "42 recommend\n",
      "56 recommended\n",
      "27 red\n",
      "42 register\n",
      "31 regular\n",
      "56 regularly\n",
      "45 relatively\n",
      "25 release\n",
      "65 released\n",
      "68 remember\n",
      "94 remembered\n",
      "47 remote\n",
      "80 remove\n",
      "21 rent\n",
      "69 replace\n",
      "30 replaced\n",
      "34 replacement\n",
      "57 replay\n",
      "34 replayability\n",
      "20 report\n",
      "142 require\n",
      "28 required\n",
      "63 requires\n",
      "200 research\n",
      "21 resources\n",
      "21 response\n",
      "190 rest\n",
      "27 result\n",
      "50 results\n",
      "465 return\n",
      "50 returned\n",
      "85 reveal\n",
      "64 review\n",
      "22 reviewer\n",
      "23 reviewers\n",
      "65 reviews\n",
      "70 rewards\n",
      "20 ride\n",
      "29 rides\n",
      "75 riding\n",
      "199 right\n",
      "41 ring\n",
      "24 rings\n",
      "66 risk\n",
      "54 road\n",
      "229 rocket\n",
      "58 rockets\n",
      "115 rocks\n",
      "61 rody\n",
      "28 role\n",
      "29 roles\n",
      "39 roll\n",
      "39 rolled\n",
      "89 rolling\n",
      "28 rolls\n",
      "501 roof\n",
      "137 room\n",
      "22 rooms\n",
      "53 rope\n",
      "54 rough\n",
      "35 round\n",
      "25 rounds\n",
      "77 routes\n",
      "24 rover\n",
      "196 row\n",
      "39 rudolph\n",
      "84 ruin\n",
      "41 rule\n",
      "66 rules\n",
      "26 run\n",
      "39 running\n",
      "104 runs\n",
      "400 rush\n",
      "37 safe\n",
      "105 safety\n",
      "28 said\n",
      "22 sale\n",
      "36 sand\n",
      "50 sandbox\n",
      "89 santa\n",
      "120 sat\n",
      "21 save\n",
      "24 saw\n",
      "19 say\n",
      "108 saying\n",
      "46 says\n",
      "103 scenarios\n",
      "36 scene\n",
      "20 school\n",
      "26 score\n",
      "23 scoring\n",
      "71 scrabble\n",
      "191 screen\n",
      "45 screw\n",
      "35 search\n",
      "32 seat\n",
      "67 second\n",
      "137 secondary\n",
      "26 seconds\n",
      "23 seeing\n",
      "20 seen\n",
      "22 select\n",
      "34 selection\n",
      "61 sell\n",
      "40 send\n",
      "39 sense\n",
      "23 sent\n",
      "70 series\n",
      "51 seriously\n",
      "38 session\n",
      "985 set\n",
      "196 sets\n",
      "63 setting\n",
      "36 settings\n",
      "53 setup\n",
      "42 seven\n",
      "137 shake\n",
      "31 shallow\n",
      "176 shape\n",
      "35 shaped\n",
      "29 shapes\n",
      "30 share\n",
      "34 sharp\n",
      "65 sheet\n",
      "174 sheets\n",
      "61 shelf\n",
      "117 ship\n",
      "26 shipping\n",
      "34 ships\n",
      "68 shoot\n",
      "145 shop\n",
      "24 shopping\n",
      "26 short\n",
      "34 shot\n",
      "31 shouldn\n",
      "69 showed\n",
      "27 shown\n",
      "21 shows\n",
      "26 shut\n",
      "70 sided\n",
      "20 sides\n",
      "28 sign\n",
      "46 signs\n",
      "98 silly\n",
      "512 similar\n",
      "103 simple\n",
      "31 simply\n",
      "91 sing\n",
      "79 singing\n",
      "181 single\n",
      "47 sister\n",
      "84 sit\n",
      "267 site\n",
      "45 sits\n",
      "20 sitting\n",
      "29 situation\n",
      "82 size\n",
      "222 sized\n",
      "21 sketch\n",
      "20 skill\n",
      "38 skills\n",
      "24 skip\n",
      "20 sleep\n",
      "83 slide\n",
      "61 slightly\n",
      "27 slinky\n",
      "35 slots\n",
      "56 slow\n",
      "19 slowly\n",
      "503 small\n",
      "140 smaller\n",
      "29 smart\n",
      "42 smell\n",
      "23 smile\n",
      "39 smock\n",
      "31 smooth\n",
      "37 snap\n",
      "38 snow\n",
      "21 soft\n",
      "72 sold\n",
      "34 solid\n",
      "78 solitaire\n",
      "36 solo\n",
      "21 solution\n",
      "41 solve\n",
      "44 solving\n",
      "68 somewhat\n",
      "1346 son\n",
      "83 song\n",
      "65 songs\n",
      "48 sons\n",
      "112 soon\n",
      "39 sorry\n",
      "79 sort\n",
      "20 sorting\n",
      "22 sorts\n",
      "27 sound\n",
      "187 sounds\n",
      "149 space\n",
      "190 spaces\n",
      "75 special\n",
      "25 specific\n",
      "22 speed\n",
      "143 spell\n",
      "66 spelling\n",
      "66 spells\n",
      "35 spend\n",
      "32 spending\n",
      "104 spent\n",
      "22 spin\n",
      "78 spinner\n",
      "83 spinning\n",
      "51 spins\n",
      "37 spot\n",
      "27 spots\n",
      "24 square\n",
      "44 st\n",
      "24 stable\n",
      "22 stack\n",
      "25 stacked\n",
      "24 stacking\n",
      "55 stairs\n",
      "27 stand\n",
      "51 standard\n",
      "48 standards\n",
      "66 standing\n",
      "28 stands\n",
      "23 star\n",
      "28 stars\n",
      "154 start\n",
      "57 started\n",
      "44 starter\n",
      "32 starting\n",
      "191 starts\n",
      "162 state\n",
      "285 states\n",
      "158 stay\n",
      "44 stays\n",
      "81 steal\n",
      "73 step\n",
      "24 stethoscope\n",
      "28 stick\n",
      "45 sticker\n",
      "120 stickers\n",
      "29 sticking\n",
      "19 sticks\n",
      "29 stocking\n",
      "23 stood\n",
      "49 stop\n",
      "28 stops\n",
      "96 storage\n",
      "45 store\n",
      "52 stores\n",
      "65 stories\n",
      "45 story\n",
      "20 straight\n",
      "117 strategic\n",
      "22 strategies\n",
      "21 strategy\n",
      "97 strength\n",
      "197 string\n",
      "55 strong\n",
      "48 stronger\n",
      "141 structure\n",
      "82 structures\n",
      "35 stuck\n",
      "39 students\n",
      "328 stuff\n",
      "29 stuffed\n",
      "28 sturdier\n",
      "28 sturdy\n",
      "41 style\n",
      "31 subject\n",
      "83 subtle\n",
      "70 successful\n",
      "31 sugar\n",
      "117 suggest\n",
      "29 suggested\n",
      "323 summer\n",
      "88 sun\n",
      "22 super\n",
      "25 support\n",
      "32 supports\n",
      "29 suppose\n",
      "62 supposed\n",
      "24 sure\n",
      "60 surface\n",
      "34 surprise\n",
      "140 surprised\n",
      "49 survey\n",
      "24 survived\n",
      "66 sweet\n",
      "420 swing\n",
      "46 switch\n",
      "36 symbols\n",
      "70 table\n",
      "22 tabletop\n",
      "24 tactical\n",
      "42 tad\n",
      "46 tail\n",
      "35 taken\n",
      "192 takes\n",
      "30 taking\n",
      "47 talk\n",
      "30 talking\n",
      "49 tall\n",
      "285 tape\n",
      "144 target\n",
      "20 task\n",
      "42 tasks\n",
      "36 tea\n",
      "45 teach\n",
      "36 teacher\n",
      "43 teaches\n",
      "21 teaching\n",
      "33 team\n",
      "58 teams\n",
      "184 tech\n",
      "22 technology\n",
      "87 tell\n",
      "95 telling\n",
      "40 tells\n",
      "21 tend\n",
      "21 tends\n",
      "27 tent\n",
      "130 terms\n",
      "41 test\n",
      "30 testing\n",
      "44 th\n",
      "20 thanks\n",
      "44 thanksgiving\n",
      "35 theme\n",
      "20 themed\n",
      "21 thicker\n",
      "45 thing\n",
      "35 things\n",
      "76 think\n",
      "36 thinkfun\n",
      "31 thinking\n",
      "133 thinks\n",
      "25 thomas\n",
      "501 thought\n",
      "472 thrilled\n",
      "808 throw\n",
      "117 thrown\n",
      "36 ticket\n",
      "196 tie\n",
      "316 tight\n",
      "41 tikes\n",
      "66 tile\n",
      "35 tiles\n",
      "76 till\n",
      "24 time\n",
      "86 timeline\n",
      "40 timer\n",
      "36 times\n",
      "79 tin\n",
      "190 tiny\n",
      "28 tip\n",
      "1677 tips\n",
      "19 tire\n",
      "30 tired\n",
      "414 title\n",
      "78 today\n",
      "75 toddler\n",
      "28 toddlers\n",
      "53 token\n",
      "22 tokens\n",
      "20 told\n",
      "69 ton\n",
      "159 tonka\n",
      "76 tons\n",
      "43 took\n",
      "112 tool\n",
      "60 tools\n",
      "42 toss\n",
      "60 total\n",
      "225 totally\n",
      "73 touch\n",
      "36 tough\n",
      "58 toy\n",
      "70 toys\n",
      "79 track\n",
      "34 tracks\n",
      "23 trade\n",
      "23 tradition\n",
      "1942 traditional\n",
      "632 train\n",
      "170 trains\n",
      "52 traitor\n",
      "33 travel\n",
      "40 tray\n",
      "47 treasure\n",
      "201 treat\n",
      "120 tree\n",
      "25 trees\n",
      "59 tricky\n",
      "36 tried\n",
      "77 tries\n",
      "70 trim\n",
      "31 trip\n",
      "20 trips\n",
      "148 trouble\n",
      "46 truck\n",
      "37 true\n",
      "42 truly\n",
      "28 try\n",
      "100 trying\n",
      "44 tub\n",
      "21 tube\n",
      "65 tune\n",
      "53 tunes\n",
      "24 tunnel\n",
      "327 tunnels\n",
      "240 turn\n",
      "33 turned\n",
      "21 turning\n",
      "38 turns\n",
      "459 tv\n",
      "106 twice\n",
      "67 twins\n",
      "225 twist\n",
      "37 twister\n",
      "56 twists\n",
      "47 type\n",
      "28 types\n",
      "38 typical\n",
      "37 typically\n",
      "137 underneath\n",
      "55 understand\n",
      "29 understanding\n",
      "173 unfortunately\n",
      "20 unique\n",
      "73 unit\n",
      "106 unless\n",
      "39 unlike\n",
      "27 uno\n",
      "97 update\n",
      "69 updated\n",
      "41 upgrade\n",
      "50 upgrades\n",
      "25 upper\n",
      "80 upset\n",
      "36 upside\n",
      "20 usb\n",
      "33 use\n",
      "27 used\n",
      "1005 useful\n",
      "527 useless\n",
      "49 uses\n",
      "24 using\n",
      "125 usual\n",
      "311 usually\n",
      "27 vacuum\n",
      "157 value\n",
      "43 variation\n",
      "223 variations\n",
      "25 variety\n",
      "23 various\n",
      "35 ve\n",
      "142 velcro\n",
      "88 version\n",
      "26 versions\n",
      "651 vertical\n",
      "24 vibrant\n",
      "400 victory\n",
      "66 video\n",
      "23 village\n",
      "66 vinyl\n",
      "54 visit\n",
      "20 visual\n",
      "36 visually\n",
      "35 vocabulary\n",
      "22 voice\n",
      "30 volume\n",
      "40 vs\n",
      "20 wagon\n",
      "99 wait\n",
      "120 waiting\n",
      "57 walk\n",
      "132 walker\n",
      "56 walking\n",
      "81 wall\n",
      "31 walls\n",
      "50 want\n",
      "33 wanted\n",
      "492 wanting\n",
      "215 wants\n",
      "37 wars\n",
      "120 wash\n",
      "32 washable\n",
      "74 wasn\n",
      "34 waste\n",
      "43 watch\n",
      "119 watched\n",
      "42 watching\n",
      "146 water\n",
      "23 way\n",
      "108 ways\n",
      "138 weapon\n",
      "34 weapons\n",
      "710 wear\n",
      "116 weather\n",
      "24 website\n",
      "25 week\n",
      "46 weeks\n",
      "23 weight\n",
      "27 weird\n",
      "88 went\n",
      "94 weren\n",
      "57 wheel\n",
      "132 wheels\n",
      "33 white\n",
      "56 wide\n",
      "135 wife\n",
      "83 wild\n",
      "57 willing\n",
      "80 win\n",
      "30 wind\n",
      "25 wing\n",
      "244 wings\n",
      "33 winner\n",
      "148 winning\n",
      "29 wins\n",
      "80 winter\n",
      "80 wire\n",
      "93 wish\n",
      "31 withstand\n",
      "22 won\n",
      "232 wonder\n",
      "201 wonderful\n",
      "40 wood\n",
      "161 wooden\n",
      "28 word\n",
      "133 words\n",
      "142 work\n",
      "127 worked\n",
      "213 worker\n",
      "433 working\n",
      "93 workout\n",
      "38 works\n",
      "20 world\n",
      "109 worried\n",
      "258 worry\n",
      "112 worse\n",
      "27 worth\n",
      "51 worthwhile\n",
      "21 wouldn\n",
      "309 write\n",
      "140 writing\n",
      "81 written\n",
      "54 wrong\n",
      "29 wrote\n",
      "127 xmas\n",
      "21 yahtzee\n",
      "25 yard\n",
      "63 yeah\n",
      "1685 year\n",
      "624 years\n",
      "68 yellow\n",
      "125 yes\n",
      "21 yo\n",
      "69 young\n",
      "313 younger\n",
      "232 youngest\n",
      "51 youth\n",
      "28 youtube\n",
      "163 yr\n",
      "36 yrs\n",
      "59 zero\n",
      "39 zombie\n",
      "22 zombies\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it\n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3pt) Which of the following three distance functions ‘cosine’, ’euclidean’, and ‘manhattan’ do you deem more appropriate for this problem? Please justify\n",
    "\n",
    "Cosine permet de mesurer la proximité entre deux vecteurs qui est représenté par les unités de texte (train_data_features) \n",
    "Ainsi, si les vecteurs ont le même angle; ils ont une similarité cosine de 1\n",
    "Si les deux deux vecteurs sont orientés à 90 degrés, ils ont une simlarité cosine de 0 \n",
    "Enfin, si elles sont orientés à 180 degrés, donc totalement opposé, ils ont une similarité de 0.\n",
    "Cosine normalise ainsi la similarité entre deux points pour chaque vecteur.\n",
    "\n",
    "La distance euclédienne permet de mesurer la distance entre deux points dans un espace tel qu'exprimé par la mesure de pythagore. De ce fait, elle ne prend pas en considération l'angle de ceux-ci comme la mesure cosine.\n",
    "\n",
    "La distance Manhattan est la somme des différences absolues entre deux points. Dans la mesure où les points se trouvent sur le même x ou le même y; la distance euclédienne et manhattan sont équivalente.\n",
    "\n",
    "Ainsi, ces deux mesures sont similaires et réagissent similairement à la distance entre les mots. Plus un vecteur à des mots différents, plus son poids pèsera sur la balance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1  number of neighboors, the accuracy of the train model is 100.0 % and the accuracy of the valid model is 46.52326163081541 %\n",
      "With 10  number of neighboors, the accuracy of the train model is 67.2393661384487 % and the accuracy of the valid model is 59.079539769884946 %\n",
      "With 50  number of neighboors, the accuracy of the train model is 64.58715596330276 % and the accuracy of the valid model is 65.13256628314157 %\n",
      "With 100  number of neighboors, the accuracy of the train model is 64.58715596330276 % and the accuracy of the valid model is 65.13256628314157 %\n",
      "With 1000  number of neighboors, the accuracy of the train model is 64.58715596330276 % and the accuracy of the valid model is 65.28264132066033 %\n"
     ]
    }
   ],
   "source": [
    "nb_neighboors = [1, 10, 50, 100, 1000]\n",
    "for neighboors in nb_neighboors:\n",
    "    knn = KNeighborsClassifier(neighboors,\n",
    "                               metric='cosine')\n",
    "    knn.fit(train_data_features, y_train)\n",
    "\n",
    "    knn_acc_train = (sum(knn.predict(train_data_features)\n",
    "                         == y_train)/len(y_train))*100\n",
    "    knn_acc_valid = (\n",
    "        sum(knn.predict(valid_data_features) == y_val)/len(y_val))*100\n",
    "\n",
    "    print(\"With\", neighboors, \" number of neighboors, the accuracy of the train model is\", knn_acc_train,\n",
    "          \"% and the accuracy of the valid model is\", knn_acc_valid, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.645872\n",
       "4    0.199500\n",
       "3    0.089241\n",
       "2    0.036530\n",
       "1    0.028857\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".5pt)Whatvalueofthehyperparameterprovidesthebestresults?Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = [0.0, 0.5, 1.0]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "nb_neurons = [10, 20, 30]\n",
    "nb_hidden_layer = [10, 50, 100, 150, 500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.0 0.001 10 10  number of neighboors, the accuracy of the train model is 0.6892410341951626 % and the accuracy of the valid model is 0.5942971485742872 %\n",
      "[[ 3.          4.65232616]\n",
      " [ 4.          7.00350175]\n",
      " [ 5.         88.34417209]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 95.34767383691846\n",
      "4 92.99649824912456\n",
      "5 11.655827913956978\n",
      "With 0.0 0.001 10 50  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6523261630815408 %\n",
      "[[2.00000000e+00 5.00250125e-02]\n",
      " [5.00000000e+00 9.99499750e+01]]\n",
      "1 100.0\n",
      "2 99.94997498749375\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.05002501250625312\n",
      "With 0.0 0.001 10 100  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.0 0.001 10 150  number of neighboors, the accuracy of the train model is 0.7414512093411176 % and the accuracy of the valid model is 0.5487743871935968 %\n",
      "[[ 3.          1.30065033]\n",
      " [ 4.         21.81090545]\n",
      " [ 5.         76.88844422]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.69934967483742\n",
      "4 78.18909454727364\n",
      "5 23.111555777888945\n",
      "With 0.0 0.001 10 500  number of neighboors, the accuracy of the train model is 0.7549624687239366 % and the accuracy of the valid model is 0.5427713856928464 %\n",
      "[[ 3.          3.2016008 ]\n",
      " [ 4.         20.21010505]\n",
      " [ 5.         76.58829415]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.7983991995998\n",
      "4 79.78989494747374\n",
      "5 23.411705852926463\n",
      "With 0.0 0.001 20 10  number of neighboors, the accuracy of the train model is 0.7326105087572977 % and the accuracy of the valid model is 0.5897948974487244 %\n",
      "[[ 2.          1.65082541]\n",
      " [ 3.          0.45022511]\n",
      " [ 4.         10.45522761]\n",
      " [ 5.         87.44372186]]\n",
      "1 100.0\n",
      "2 98.34917458729365\n",
      "3 99.54977488744372\n",
      "4 89.54477238619309\n",
      "5 12.556278139069535\n",
      "With 0.0 0.001 20 50  number of neighboors, the accuracy of the train model is 0.8246872393661384 % and the accuracy of the valid model is 0.5307653826913457 %\n",
      "[[ 1.          0.35017509]\n",
      " [ 2.          0.35017509]\n",
      " [ 3.          3.50175088]\n",
      " [ 4.         19.75987994]\n",
      " [ 5.         76.03801901]]\n",
      "1 99.64982491245622\n",
      "2 99.64982491245622\n",
      "3 96.49824912456228\n",
      "4 80.24012006003002\n",
      "5 23.961980990495245\n",
      "With 0.0 0.001 20 100  number of neighboors, the accuracy of the train model is 0.6478732276897414 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.0 0.001 20 150  number of neighboors, the accuracy of the train model is 0.8912427022518765 % and the accuracy of the valid model is 0.5142571285642822 %\n",
      "[[ 1.          0.15007504]\n",
      " [ 2.          0.60030015]\n",
      " [ 3.          5.45272636]\n",
      " [ 4.         23.86193097]\n",
      " [ 5.         69.93496748]]\n",
      "1 99.84992496248124\n",
      "2 99.39969984992496\n",
      "3 94.5472736368184\n",
      "4 76.13806903451726\n",
      "5 30.06503251625813\n",
      "With 0.0 0.001 20 500  number of neighboors, the accuracy of the train model is 0.7601334445371143 % and the accuracy of the valid model is 0.5702851425712856 %\n",
      "[[ 3.          1.65082541]\n",
      " [ 4.         16.008004  ]\n",
      " [ 5.         82.34117059]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.34917458729365\n",
      "4 83.991995997999\n",
      "5 17.658829414707352\n",
      "With 0.0 0.001 30 10  number of neighboors, the accuracy of the train model is 0.8156797331109258 % and the accuracy of the valid model is 0.5007503751875938 %\n",
      "[[ 2.          0.20010005]\n",
      " [ 3.          1.2006003 ]\n",
      " [ 4.         30.91545773]\n",
      " [ 5.         67.68384192]]\n",
      "1 100.0\n",
      "2 99.79989994997499\n",
      "3 98.79939969984991\n",
      "4 69.08454227113556\n",
      "5 32.31615807903952\n",
      "With 0.0 0.001 30 50  number of neighboors, the accuracy of the train model is 0.7075896580483736 % and the accuracy of the valid model is 0.64032016008004 %\n",
      "[[ 3.          0.10005003]\n",
      " [ 4.          3.55177589]\n",
      " [ 5.         96.34817409]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.89994997498749\n",
      "4 96.44822411205602\n",
      "5 3.651825912956478\n",
      "With 0.0 0.001 30 100  number of neighboors, the accuracy of the train model is 0.7035863219349457 % and the accuracy of the valid model is 0.6248124062031015 %\n",
      "[[ 4.          7.15357679]\n",
      " [ 5.         92.84642321]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 92.8464232116058\n",
      "5 7.153576788394197\n",
      "With 0.0 0.001 30 150  number of neighboors, the accuracy of the train model is 0.8783986655546289 % and the accuracy of the valid model is 0.5042521260630315 %\n",
      "[[1.00000000e+00 5.00250125e-02]\n",
      " [2.00000000e+00 1.00050025e-01]\n",
      " [3.00000000e+00 2.15107554e+00]\n",
      " [4.00000000e+00 3.05652826e+01]\n",
      " [5.00000000e+00 6.71335668e+01]]\n",
      "1 99.94997498749375\n",
      "2 99.89994997498749\n",
      "3 97.84892446223111\n",
      "4 69.43471735867934\n",
      "5 32.86643321660831\n",
      "With 0.0 0.001 30 500  number of neighboors, the accuracy of the train model is 0.8290241868223519 % and the accuracy of the valid model is 0.5337668834417209 %\n",
      "[[ 3.          2.50125063]\n",
      " [ 4.         21.81090545]\n",
      " [ 5.         75.68784392]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.49874937468735\n",
      "4 78.18909454727364\n",
      "5 24.312156078039017\n",
      "With 0.0 0.01 10 10  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.0 0.01 10 50  number of neighboors, the accuracy of the train model is 0.7251042535446205 % and the accuracy of the valid model is 0.6038019009504753 %\n",
      "[[ 3.          2.55127564]\n",
      " [ 4.          8.85442721]\n",
      " [ 5.         88.59429715]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.4487243621811\n",
      "4 91.14557278639319\n",
      "5 11.405702851425712\n",
      "With 0.0 0.01 10 100  number of neighboors, the accuracy of the train model is 0.6475396163469558 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.0 0.01 10 150  number of neighboors, the accuracy of the train model is 0.741117597998332 % and the accuracy of the valid model is 0.5962981490745373 %\n",
      "[[ 3.          3.05152576]\n",
      " [ 4.         11.90595298]\n",
      " [ 5.         85.04252126]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.94847423711856\n",
      "4 88.09404702351176\n",
      "5 14.957478739369684\n",
      "With 0.0 0.01 10 500  number of neighboors, the accuracy of the train model is 0.7167639699749792 % and the accuracy of the valid model is 0.5382691345672836 %\n",
      "[[ 3.          5.6028014 ]\n",
      " [ 4.         17.40870435]\n",
      " [ 5.         76.98849425]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.39719859929964\n",
      "4 82.59129564782391\n",
      "5 23.011505752876438\n",
      "With 0.0 0.01 20 10  number of neighboors, the accuracy of the train model is 0.6478732276897414 % and the accuracy of the valid model is 0.6518259129564783 %\n",
      "[[ 4.          0.20010005]\n",
      " [ 5.         99.79989995]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.79989994997499\n",
      "5 0.2001000500250125\n",
      "With 0.0 0.01 20 50  number of neighboors, the accuracy of the train model is 0.7022518765638032 % and the accuracy of the valid model is 0.6263131565782891 %\n",
      "[[ 3.          2.95147574]\n",
      " [ 4.          3.05152576]\n",
      " [ 5.         93.9969985 ]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.04852426213107\n",
      "4 96.94847423711856\n",
      "5 6.003001500750376\n",
      "With 0.0 0.01 20 100  number of neighboors, the accuracy of the train model is 0.7127606338615513 % and the accuracy of the valid model is 0.624312156078039 %\n",
      "[[ 3.          1.40070035]\n",
      " [ 4.          4.75237619]\n",
      " [ 5.         93.84692346]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.59929964982491\n",
      "4 95.24762381190595\n",
      "5 6.153076538269135\n",
      "With 0.0 0.01 20 150  number of neighboors, the accuracy of the train model is 0.7301084236864054 % and the accuracy of the valid model is 0.5587793896948474 %\n",
      "[[ 3.          9.6048024 ]\n",
      " [ 4.          7.75387694]\n",
      " [ 5.         82.64132066]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 90.3951975987994\n",
      "4 92.24612306153077\n",
      "5 17.358679339669834\n",
      "With 0.0 0.01 20 500  number of neighboors, the accuracy of the train model is 0.714929107589658 % and the accuracy of the valid model is 0.6123061530765382 %\n",
      "[[ 3.          1.45072536]\n",
      " [ 4.          7.00350175]\n",
      " [ 5.         91.54577289]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.54927463731866\n",
      "4 92.99649824912456\n",
      "5 8.454227113556778\n",
      "With 0.0 0.01 30 10  number of neighboors, the accuracy of the train model is 0.7007506255212678 % and the accuracy of the valid model is 0.5612806403201601 %\n",
      "[[ 4.        19.6098049]\n",
      " [ 5.        80.3901951]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 80.39019509754878\n",
      "5 19.609804902451224\n",
      "With 0.0 0.01 30 50  number of neighboors, the accuracy of the train model is 0.6627189324437031 % and the accuracy of the valid model is 0.6518259129564783 %\n",
      "[[ 4.          0.25012506]\n",
      " [ 5.         99.74987494]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.74987493746873\n",
      "5 0.25012506253126565\n",
      "With 0.0 0.01 30 100  number of neighboors, the accuracy of the train model is 0.6610508757297748 % and the accuracy of the valid model is 0.6493246623311656 %\n",
      "[[ 4.         1.2006003]\n",
      " [ 5.        98.7993997]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 98.79939969984991\n",
      "5 1.2006003001500751\n",
      "With 0.0 0.01 30 150  number of neighboors, the accuracy of the train model is 0.7708090075062553 % and the accuracy of the valid model is 0.5682841420710355 %\n",
      "[[ 1.          0.10005003]\n",
      " [ 3.          4.30215108]\n",
      " [ 4.         14.20710355]\n",
      " [ 5.         81.39069535]]\n",
      "1 99.89994997498749\n",
      "2 100.0\n",
      "3 95.69784892446224\n",
      "4 85.79289644822411\n",
      "5 18.609304652326163\n",
      "With 0.0 0.01 30 500  number of neighboors, the accuracy of the train model is 0.8143452877397832 % and the accuracy of the valid model is 0.5572786393196598 %\n",
      "[[ 3.          3.40170085]\n",
      " [ 4.         13.45672836]\n",
      " [ 5.         83.14157079]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.59829914957479\n",
      "4 86.5432716358179\n",
      "5 16.858429214607305\n",
      "With 0.0 0.1 10 10  number of neighboors, the accuracy of the train model is 0.6465387823185988 % and the accuracy of the valid model is 0.6523261630815408 %\n",
      "[[4.00000000e+00 5.00250125e-02]\n",
      " [5.00000000e+00 9.99499750e+01]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.94997498749375\n",
      "5 0.05002501250625312\n",
      "With 0.0 0.1 10 50  number of neighboors, the accuracy of the train model is 0.6460383653044204 % and the accuracy of the valid model is 0.6493246623311656 %\n",
      "[[ 3.          0.55027514]\n",
      " [ 5.         99.44972486]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.44972486243121\n",
      "4 100.0\n",
      "5 0.5502751375687844\n",
      "With 0.0 0.1 10 100  number of neighboors, the accuracy of the train model is 0.6403669724770642 % and the accuracy of the valid model is 0.6293146573286643 %\n",
      "[[ 3.          0.45022511]\n",
      " [ 4.          3.35167584]\n",
      " [ 5.         96.19809905]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.54977488744372\n",
      "4 96.64832416208104\n",
      "5 3.801900950475238\n",
      "With 0.0 0.1 10 150  number of neighboors, the accuracy of the train model is 0.6455379482902419 % and the accuracy of the valid model is 0.6498249124562281 %\n",
      "[[ 4.         0.4002001]\n",
      " [ 5.        99.5997999]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.59979989994997\n",
      "5 0.400200100050025\n",
      "With 0.0 0.1 10 500  number of neighboors, the accuracy of the train model is 0.6452043369474562 % and the accuracy of the valid model is 0.6468234117058529 %\n",
      "[[ 2.          0.60030015]\n",
      " [ 4.          0.75037519]\n",
      " [ 5.         98.64932466]]\n",
      "1 100.0\n",
      "2 99.39969984992496\n",
      "3 100.0\n",
      "4 99.2496248124062\n",
      "5 1.3506753376688343\n",
      "With 0.0 0.1 20 10  number of neighboors, the accuracy of the train model is 0.6488740617180984 % and the accuracy of the valid model is 0.6438219109554777 %\n",
      "[[ 4.          1.55077539]\n",
      " [ 5.         98.44922461]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 98.44922461230615\n",
      "5 1.5507753876938468\n",
      "With 0.0 0.1 20 50  number of neighboors, the accuracy of the train model is 0.6472060050041701 % and the accuracy of the valid model is 0.6453226613306653 %\n",
      "[[ 1.          0.15007504]\n",
      " [ 3.          0.25012506]\n",
      " [ 4.          0.75037519]\n",
      " [ 5.         98.84942471]]\n",
      "1 99.84992496248124\n",
      "2 100.0\n",
      "3 99.74987493746873\n",
      "4 99.2496248124062\n",
      "5 1.150575287643822\n",
      "With 0.0 0.1 20 100  number of neighboors, the accuracy of the train model is 0.6470391993327773 % and the accuracy of the valid model is 0.6503251625812907 %\n",
      "[[ 4.          0.35017509]\n",
      " [ 5.         99.64982491]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.64982491245622\n",
      "5 0.3501750875437719\n",
      "With 0.0 0.1 20 150  number of neighboors, the accuracy of the train model is 0.6487072560467055 % and the accuracy of the valid model is 0.6253126563281641 %\n",
      "[[1.00000000e+00 5.00250125e-02]\n",
      " [3.00000000e+00 2.25112556e+00]\n",
      " [4.00000000e+00 3.40170085e+00]\n",
      " [5.00000000e+00 9.42971486e+01]]\n",
      "1 99.94997498749375\n",
      "2 100.0\n",
      "3 97.74887443721862\n",
      "4 96.59829914957479\n",
      "5 5.702851425712856\n",
      "With 0.0 0.1 20 500  number of neighboors, the accuracy of the train model is 0.6472060050041701 % and the accuracy of the valid model is 0.6353176588294147 %\n",
      "[[ 3.          0.85042521]\n",
      " [ 4.          4.45222611]\n",
      " [ 5.         94.69734867]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.1495747873937\n",
      "4 95.54777388694347\n",
      "5 5.302651325662831\n",
      "With 0.0 0.1 30 10  number of neighboors, the accuracy of the train model is 0.6460383653044204 % and the accuracy of the valid model is 0.6518259129564783 %\n",
      "[[ 4.          0.20010005]\n",
      " [ 5.         99.79989995]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.79989994997499\n",
      "5 0.2001000500250125\n",
      "With 0.0 0.1 30 50  number of neighboors, the accuracy of the train model is 0.650208507089241 % and the accuracy of the valid model is 0.6408204102051025 %\n",
      "[[ 3.          0.10005003]\n",
      " [ 4.          2.0010005 ]\n",
      " [ 5.         97.89894947]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.89994997498749\n",
      "4 97.99899949974987\n",
      "5 2.1010505252626315\n",
      "With 0.0 0.1 30 100  number of neighboors, the accuracy of the train model is 0.6477064220183486 % and the accuracy of the valid model is 0.6468234117058529 %\n",
      "[[ 2.          0.45022511]\n",
      " [ 3.          0.10005003]\n",
      " [ 4.          0.50025013]\n",
      " [ 5.         98.94947474]]\n",
      "1 100.0\n",
      "2 99.54977488744372\n",
      "3 99.89994997498749\n",
      "4 99.49974987493746\n",
      "5 1.0505252626313157\n",
      "With 0.0 0.1 30 150  number of neighboors, the accuracy of the train model is 0.647372810675563 % and the accuracy of the valid model is 0.6508254127063532 %\n",
      "[[ 3.          0.45022511]\n",
      " [ 4.          0.10005003]\n",
      " [ 5.         99.44972486]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.54977488744372\n",
      "4 99.89994997498749\n",
      "5 0.5502751375687844\n",
      "With 0.0 0.1 30 500  number of neighboors, the accuracy of the train model is 0.6490408673894913 % and the accuracy of the valid model is 0.6213106553276638 %\n",
      "[[1.00000000e+00 5.00250125e-02]\n",
      " [3.00000000e+00 1.35067534e+00]\n",
      " [4.00000000e+00 5.25262631e+00]\n",
      " [5.00000000e+00 9.33466733e+01]]\n",
      "1 99.94997498749375\n",
      "2 100.0\n",
      "3 98.64932466233117\n",
      "4 94.74737368684342\n",
      "5 6.653326663331666\n",
      "With 0.5 0.001 10 10  number of neighboors, the accuracy of the train model is 0.6747289407839867 % and the accuracy of the valid model is 0.6118059029514757 %\n",
      "[[ 3.          3.50175088]\n",
      " [ 4.          6.50325163]\n",
      " [ 5.         89.9949975 ]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.49824912456228\n",
      "4 93.49674837418709\n",
      "5 10.005002501250624\n",
      "With 0.5 0.001 10 50  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6523261630815408 %\n",
      "[[ 2.          0.10005003]\n",
      " [ 5.         99.89994997]]\n",
      "1 100.0\n",
      "2 99.89994997498749\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.10005002501250625\n",
      "With 0.5 0.001 10 100  number of neighboors, the accuracy of the train model is 0.6478732276897414 % and the accuracy of the valid model is 0.6523261630815408 %\n",
      "[[4.00000000e+00 5.00250125e-02]\n",
      " [5.00000000e+00 9.99499750e+01]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.94997498749375\n",
      "5 0.05002501250625312\n",
      "With 0.5 0.001 10 150  number of neighboors, the accuracy of the train model is 0.7539616346955796 % and the accuracy of the valid model is 0.5302651325662832 %\n",
      "[[ 3.          3.65182591]\n",
      " [ 4.         23.86193097]\n",
      " [ 5.         72.48624312]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.34817408704353\n",
      "4 76.13806903451726\n",
      "5 27.51375687843922\n",
      "With 0.5 0.001 10 500  number of neighboors, the accuracy of the train model is 0.7417848206839033 % and the accuracy of the valid model is 0.5467733866933466 %\n",
      "[[ 3.          2.95147574]\n",
      " [ 4.         19.25962981]\n",
      " [ 5.         77.78889445]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.04852426213107\n",
      "4 80.74037018509254\n",
      "5 22.211105552776388\n",
      "With 0.5 0.001 20 10  number of neighboors, the accuracy of the train model is 0.741117597998332 % and the accuracy of the valid model is 0.5772886443221611 %\n",
      "[[ 2.          2.45122561]\n",
      " [ 3.          0.90045023]\n",
      " [ 4.         11.50575288]\n",
      " [ 5.         85.14257129]]\n",
      "1 100.0\n",
      "2 97.54877438719359\n",
      "3 99.09954977488744\n",
      "4 88.49424712356178\n",
      "5 14.85742871435718\n",
      "With 0.5 0.001 20 50  number of neighboors, the accuracy of the train model is 0.7669724770642202 % and the accuracy of the valid model is 0.5742871435717859 %\n",
      "[[ 2.          0.10005003]\n",
      " [ 3.          1.90095048]\n",
      " [ 4.         15.30765383]\n",
      " [ 5.         82.69134567]]\n",
      "1 100.0\n",
      "2 99.89994997498749\n",
      "3 98.09904952476238\n",
      "4 84.69234617308655\n",
      "5 17.30865432716358\n",
      "With 0.5 0.001 20 100  number of neighboors, the accuracy of the train model is 0.6475396163469558 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.5 0.001 20 150  number of neighboors, the accuracy of the train model is 0.8535446205170976 % and the accuracy of the valid model is 0.47223611805902954 %\n",
      "[[ 1.          0.10005003]\n",
      " [ 2.          0.75037519]\n",
      " [ 3.          6.25312656]\n",
      " [ 4.         30.76538269]\n",
      " [ 5.         62.13106553]]\n",
      "1 99.89994997498749\n",
      "2 99.2496248124062\n",
      "3 93.74687343671836\n",
      "4 69.23461730865432\n",
      "5 37.868934467233615\n",
      "With 0.5 0.001 20 500  number of neighboors, the accuracy of the train model is 0.7801501251042535 % and the accuracy of the valid model is 0.5447723861930965 %\n",
      "[[ 3.          3.70185093]\n",
      " [ 4.         19.70985493]\n",
      " [ 5.         76.58829415]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.29814907453726\n",
      "4 80.29014507253626\n",
      "5 23.411705852926463\n",
      "With 0.5 0.001 30 10  number of neighboors, the accuracy of the train model is 0.8050041701417848 % and the accuracy of the valid model is 0.5047523761880941 %\n",
      "[[ 2.          0.4002001 ]\n",
      " [ 3.          2.35117559]\n",
      " [ 4.         31.01550775]\n",
      " [ 5.         66.23311656]]\n",
      "1 100.0\n",
      "2 99.59979989994997\n",
      "3 97.6488244122061\n",
      "4 68.98449224612307\n",
      "5 33.766883441720864\n",
      "With 0.5 0.001 30 50  number of neighboors, the accuracy of the train model is 0.7012510425354462 % and the accuracy of the valid model is 0.6358179089544772 %\n",
      "[[ 3.          0.20010005]\n",
      " [ 4.          4.45222611]\n",
      " [ 5.         95.34767384]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.79989994997499\n",
      "4 95.54777388694347\n",
      "5 4.652326163081541\n",
      "With 0.5 0.001 30 100  number of neighboors, the accuracy of the train model is 0.7004170141784821 % and the accuracy of the valid model is 0.631815907953977 %\n",
      "[[3.00000000e+00 5.00250125e-02]\n",
      " [4.00000000e+00 5.50275138e+00]\n",
      " [5.00000000e+00 9.44472236e+01]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.94997498749375\n",
      "4 94.49724862431216\n",
      "5 5.552776388194097\n",
      "With 0.5 0.001 30 150  number of neighboors, the accuracy of the train model is 0.7537948290241868 % and the accuracy of the valid model is 0.5787893946973487 %\n",
      "[[ 3.          0.55027514]\n",
      " [ 4.         15.80790395]\n",
      " [ 5.         83.64182091]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.44972486243121\n",
      "4 84.19209604802401\n",
      "5 16.358179089544773\n",
      "With 0.5 0.001 30 500  number of neighboors, the accuracy of the train model is 0.8281901584653878 % and the accuracy of the valid model is 0.4847423711855928 %\n",
      "[[ 3.          5.95297649]\n",
      " [ 4.         26.21310655]\n",
      " [ 5.         67.83391696]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.04702351175588\n",
      "4 73.78689344672335\n",
      "5 32.16608304152076\n",
      "With 0.5 0.01 10 10  number of neighboors, the accuracy of the train model is 0.7666388657214346 % and the accuracy of the valid model is 0.4777388694347174 %\n",
      "[[ 2.          0.8004002 ]\n",
      " [ 3.         12.30615308]\n",
      " [ 4.         22.36118059]\n",
      " [ 5.         64.53226613]]\n",
      "1 100.0\n",
      "2 99.19959979989996\n",
      "3 87.69384692346172\n",
      "4 77.63881940970485\n",
      "5 35.467733866933465\n",
      "With 0.5 0.01 10 50  number of neighboors, the accuracy of the train model is 0.6453711426188491 % and the accuracy of the valid model is 0.6508254127063532 %\n",
      "[[ 4.          0.50025013]\n",
      " [ 5.         99.49974987]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.49974987493746\n",
      "5 0.5002501250625313\n",
      "With 0.5 0.01 10 100  number of neighboors, the accuracy of the train model is 0.6462051709758132 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 0.5 0.01 10 150  number of neighboors, the accuracy of the train model is 0.7190992493744788 % and the accuracy of the valid model is 0.5717858929464732 %\n",
      "[[ 3.          8.15407704]\n",
      " [ 4.          7.15357679]\n",
      " [ 5.         84.69234617]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 91.84592296148074\n",
      "4 92.8464232116058\n",
      "5 15.307653826913455\n",
      "With 0.5 0.01 10 500  number of neighboors, the accuracy of the train model is 0.6890742285237698 % and the accuracy of the valid model is 0.5707853926963482 %\n",
      "[[ 3.          4.10205103]\n",
      " [ 4.         12.90645323]\n",
      " [ 5.         82.99149575]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 95.89794897448725\n",
      "4 87.09354677338669\n",
      "5 17.008504252126063\n",
      "With 0.5 0.01 20 10  number of neighboors, the accuracy of the train model is 0.71209341117598 % and the accuracy of the valid model is 0.6043021510755378 %\n",
      "[[ 3.          5.2026013 ]\n",
      " [ 4.          6.45322661]\n",
      " [ 5.         88.34417209]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.79739869934967\n",
      "4 93.54677338669335\n",
      "5 11.655827913956978\n",
      "With 0.5 0.01 20 50  number of neighboors, the accuracy of the train model is 0.7057547956630525 % and the accuracy of the valid model is 0.6103051525762881 %\n",
      "[[ 3.          6.05302651]\n",
      " [ 4.          3.2016008 ]\n",
      " [ 5.         90.74537269]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 93.94697348674337\n",
      "4 96.7983991995998\n",
      "5 9.254627313656828\n",
      "With 0.5 0.01 20 100  number of neighboors, the accuracy of the train model is 0.6834028356964137 % and the accuracy of the valid model is 0.6218109054527263 %\n",
      "[[ 3.          2.85142571]\n",
      " [ 4.          3.50175088]\n",
      " [ 5.         93.64682341]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.14857428714357\n",
      "4 96.49824912456228\n",
      "5 6.353176588294147\n",
      "With 0.5 0.01 20 150  number of neighboors, the accuracy of the train model is 0.7029190992493745 % and the accuracy of the valid model is 0.5792896448224112 %\n",
      "[[ 3.         10.4052026 ]\n",
      " [ 4.          3.80190095]\n",
      " [ 5.         85.79289645]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 89.59479739869936\n",
      "4 96.19809904952477\n",
      "5 14.207103551775887\n",
      "With 0.5 0.01 20 500  number of neighboors, the accuracy of the train model is 0.6785654712260217 % and the accuracy of the valid model is 0.6218109054527263 %\n",
      "[[ 3.          4.8024012 ]\n",
      " [ 4.          0.90045023]\n",
      " [ 5.         94.29714857]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 95.1975987993997\n",
      "4 99.09954977488744\n",
      "5 5.702851425712856\n",
      "With 0.5 0.01 30 10  number of neighboors, the accuracy of the train model is 0.6712260216847373 % and the accuracy of the valid model is 0.5782891445722862 %\n",
      "[[ 4.         15.80790395]\n",
      " [ 5.         84.19209605]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 84.19209604802401\n",
      "5 15.807903951975987\n",
      "With 0.5 0.01 30 50  number of neighboors, the accuracy of the train model is 0.6648874061718099 % and the accuracy of the valid model is 0.6508254127063532 %\n",
      "[[ 4.          0.65032516]\n",
      " [ 5.         99.34967484]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.34967483741872\n",
      "5 0.6503251625812907\n",
      "With 0.5 0.01 30 100  number of neighboors, the accuracy of the train model is 0.740116763969975 % and the accuracy of the valid model is 0.551775887943972 %\n",
      "[[ 1.          0.10005003]\n",
      " [ 2.          0.30015008]\n",
      " [ 3.          8.75437719]\n",
      " [ 4.          9.80490245]\n",
      " [ 5.         81.04052026]]\n",
      "1 99.89994997498749\n",
      "2 99.69984992496248\n",
      "3 91.2456228114057\n",
      "4 90.19509754877438\n",
      "5 18.959479739869938\n",
      "With 0.5 0.01 30 150  number of neighboors, the accuracy of the train model is 0.7321100917431193 % and the accuracy of the valid model is 0.5642821410705353 %\n",
      "[[ 3.          6.75337669]\n",
      " [ 4.         11.80590295]\n",
      " [ 5.         81.44072036]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 93.24662331165582\n",
      "4 88.19409704852427\n",
      "5 18.55927963981991\n",
      "With 0.5 0.01 30 500  number of neighboors, the accuracy of the train model is 0.7424520433694746 % and the accuracy of the valid model is 0.512256128064032 %\n",
      "[[ 3.         12.60630315]\n",
      " [ 4.         11.15557779]\n",
      " [ 5.         76.23811906]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 87.39369684842421\n",
      "4 88.84442221110555\n",
      "5 23.761880940470235\n",
      "With 0.5 0.1 10 10  number of neighboors, the accuracy of the train model is 0.6480400333611342 % and the accuracy of the valid model is 0.6503251625812907 %\n",
      "[[ 3.          0.50025013]\n",
      " [ 5.         99.49974987]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.49974987493746\n",
      "4 100.0\n",
      "5 0.5002501250625313\n",
      "With 0.5 0.1 10 50  number of neighboors, the accuracy of the train model is 0.6597164303586321 % and the accuracy of the valid model is 0.6378189094547274 %\n",
      "[[ 1.          0.10005003]\n",
      " [ 3.          2.45122561]\n",
      " [ 5.         97.44872436]]\n",
      "1 99.89994997498749\n",
      "2 100.0\n",
      "3 97.54877438719359\n",
      "4 100.0\n",
      "5 2.5512756378189096\n",
      "With 0.5 0.1 10 100  number of neighboors, the accuracy of the train model is 0.6545454545454545 % and the accuracy of the valid model is 0.5982991495747874 %\n",
      "[[ 3.         10.55527764]\n",
      " [ 5.         89.44472236]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 89.4447223611806\n",
      "4 100.0\n",
      "5 10.55527763881941\n",
      "With 0.5 0.1 10 150  number of neighboors, the accuracy of the train model is 0.6623853211009174 % and the accuracy of the valid model is 0.6333166583291646 %\n",
      "[[ 3.          4.25212606]\n",
      " [ 5.         95.74787394]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 95.74787393696849\n",
      "4 100.0\n",
      "5 4.252126063031516\n",
      "With 0.5 0.1 10 500  number of neighboors, the accuracy of the train model is 0.6500417014178482 % and the accuracy of the valid model is 0.647823911955978 %\n",
      "[[ 3.          1.00050025]\n",
      " [ 5.         98.99949975]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.99949974987494\n",
      "4 100.0\n",
      "5 1.0005002501250626\n",
      "With 0.5 0.1 20 10  number of neighboors, the accuracy of the train model is 0.655045871559633 % and the accuracy of the valid model is 0.6458229114557279 %\n",
      "[[ 3.          1.45072536]\n",
      " [ 5.         98.54927464]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.54927463731866\n",
      "4 100.0\n",
      "5 1.4507253626813406\n",
      "With 0.5 0.1 20 50  number of neighboors, the accuracy of the train model is 0.6620517097581318 % and the accuracy of the valid model is 0.6223111555777889 %\n",
      "[[ 3.          6.15307654]\n",
      " [ 5.         93.84692346]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 93.84692346173087\n",
      "4 100.0\n",
      "5 6.153076538269135\n",
      "With 0.5 0.1 20 100  number of neighboors, the accuracy of the train model is 0.6508757297748123 % and the accuracy of the valid model is 0.6508254127063532 %\n",
      "[[1.00000000e+00 5.00250125e-02]\n",
      " [4.00000000e+00 3.00150075e-01]\n",
      " [5.00000000e+00 9.96498249e+01]]\n",
      "1 99.94997498749375\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.69984992496248\n",
      "5 0.3501750875437719\n",
      "With 0.5 0.1 20 150  number of neighboors, the accuracy of the train model is 0.6668890742285237 % and the accuracy of the valid model is 0.5177588794397199 %\n",
      "[[ 1.         2.0010005]\n",
      " [ 3.        24.012006 ]\n",
      " [ 5.        73.9869935]]\n",
      "1 97.99899949974987\n",
      "2 100.0\n",
      "3 75.9879939969985\n",
      "4 100.0\n",
      "5 26.013006503251624\n",
      "With 0.5 0.1 20 500  number of neighboors, the accuracy of the train model is 0.6537114261884904 % and the accuracy of the valid model is 0.6353176588294147 %\n",
      "[[ 1.          2.55127564]\n",
      " [ 2.          0.65032516]\n",
      " [ 5.         96.7983992 ]]\n",
      "1 97.4487243621811\n",
      "2 99.34967483741872\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 3.2016008004002\n",
      "With 0.5 0.1 30 10  number of neighboors, the accuracy of the train model is 0.657047539616347 % and the accuracy of the valid model is 0.5962981490745373 %\n",
      "[[ 2.          4.85242621]\n",
      " [ 3.          1.85092546]\n",
      " [ 4.          6.50325163]\n",
      " [ 5.         86.7933967 ]]\n",
      "1 100.0\n",
      "2 95.14757378689345\n",
      "3 98.14907453726863\n",
      "4 93.49674837418709\n",
      "5 13.206603301650826\n",
      "With 0.5 0.1 30 50  number of neighboors, the accuracy of the train model is 0.657047539616347 % and the accuracy of the valid model is 0.6278139069534767 %\n",
      "[[ 1.          3.90195098]\n",
      " [ 5.         96.09804902]]\n",
      "1 96.09804902451225\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 3.9019509754877437\n",
      "With 0.5 0.1 30 100  number of neighboors, the accuracy of the train model is 0.6590492076730609 % and the accuracy of the valid model is 0.6413206603301651 %\n",
      "[[ 1.          0.8004002 ]\n",
      " [ 3.          0.45022511]\n",
      " [ 4.          2.20110055]\n",
      " [ 5.         96.54827414]]\n",
      "1 99.19959979989996\n",
      "2 100.0\n",
      "3 99.54977488744372\n",
      "4 97.79889944972486\n",
      "5 3.451725862931466\n",
      "With 0.5 0.1 30 150  number of neighboors, the accuracy of the train model is 0.6572143452877398 % and the accuracy of the valid model is 0.615807903951976 %\n",
      "[[ 4.        10.8054027]\n",
      " [ 5.        89.1945973]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 89.19459729864933\n",
      "5 10.805402701350674\n",
      "With 0.5 0.1 30 500  number of neighboors, the accuracy of the train model is 0.6612176814011677 % and the accuracy of the valid model is 0.607303651825913 %\n",
      "[[ 1.          0.70035018]\n",
      " [ 3.          7.65382691]\n",
      " [ 5.         91.64582291]]\n",
      "1 99.29964982491246\n",
      "2 100.0\n",
      "3 92.34617308654327\n",
      "4 100.0\n",
      "5 8.354177088544272\n",
      "With 1.0 0.001 10 10  number of neighboors, the accuracy of the train model is 0.6708924103419516 % and the accuracy of the valid model is 0.6203101550775387 %\n",
      "[[ 3.          2.90145073]\n",
      " [ 4.          5.05252626]\n",
      " [ 5.         92.04602301]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.0985492746373\n",
      "4 94.94747373686843\n",
      "5 7.953976988494247\n",
      "With 1.0 0.001 10 50  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6523261630815408 %\n",
      "[[ 2.          0.10005003]\n",
      " [ 5.         99.89994997]]\n",
      "1 100.0\n",
      "2 99.89994997498749\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.10005002501250625\n",
      "With 1.0 0.001 10 100  number of neighboors, the accuracy of the train model is 0.678231859883236 % and the accuracy of the valid model is 0.6428214107053527 %\n",
      "[[ 4.          2.75137569]\n",
      " [ 5.         97.24862431]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 97.24862431215607\n",
      "5 2.751375687843922\n",
      "With 1.0 0.001 10 150  number of neighboors, the accuracy of the train model is 0.744954128440367 % and the accuracy of the valid model is 0.5437718859429714 %\n",
      "[[ 3.         3.2016008]\n",
      " [ 4.        21.2106053]\n",
      " [ 5.        75.5877939]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.7983991995998\n",
      "4 78.78939469734867\n",
      "5 24.412206103051524\n",
      "With 1.0 0.001 10 500  number of neighboors, the accuracy of the train model is 0.7289407839866555 % and the accuracy of the valid model is 0.5567783891945973 %\n",
      "[[ 3.          2.30115058]\n",
      " [ 4.         19.00950475]\n",
      " [ 5.         78.68934467]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.69884942471235\n",
      "4 80.99049524762381\n",
      "5 21.310655327663834\n",
      "With 1.0 0.001 20 10  number of neighboors, the accuracy of the train model is 0.6728940783986656 % and the accuracy of the valid model is 0.64032016008004 %\n",
      "[[2.00000000e+00 9.00450225e-01]\n",
      " [3.00000000e+00 5.00250125e-02]\n",
      " [4.00000000e+00 2.75137569e+00]\n",
      " [5.00000000e+00 9.62981491e+01]]\n",
      "1 100.0\n",
      "2 99.09954977488744\n",
      "3 99.94997498749375\n",
      "4 97.24862431215607\n",
      "5 3.701850925462731\n",
      "With 1.0 0.001 20 50  number of neighboors, the accuracy of the train model is 0.8161801501251043 % and the accuracy of the valid model is 0.5067533766883442 %\n",
      "[[ 1.          0.55027514]\n",
      " [ 2.          0.10005003]\n",
      " [ 3.          3.85192596]\n",
      " [ 4.         26.06303152]\n",
      " [ 5.         69.43471736]]\n",
      "1 99.44972486243121\n",
      "2 99.89994997498749\n",
      "3 96.1480740370185\n",
      "4 73.93696848424212\n",
      "5 30.565282641320664\n",
      "With 1.0 0.001 20 100  number of neighboors, the accuracy of the train model is 0.6568807339449542 % and the accuracy of the valid model is 0.6503251625812907 %\n",
      "[[ 4.          0.60030015]\n",
      " [ 5.         99.39969985]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.39969984992496\n",
      "5 0.6003001500750376\n",
      "With 1.0 0.001 20 150  number of neighboors, the accuracy of the train model is 0.7366138448707256 % and the accuracy of the valid model is 0.5507753876938469 %\n",
      "[[ 3.          1.90095048]\n",
      " [ 4.         21.66083042]\n",
      " [ 5.         76.43821911]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.09904952476238\n",
      "4 78.3391695847924\n",
      "5 23.56178089044522\n",
      "With 1.0 0.001 20 500  number of neighboors, the accuracy of the train model is 0.7819849874895747 % and the accuracy of the valid model is 0.5247623811905953 %\n",
      "[[ 3.          5.35267634]\n",
      " [ 4.         20.96048024]\n",
      " [ 5.         73.68684342]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.64732366183092\n",
      "4 79.03951975987994\n",
      "5 26.313156578289142\n",
      "With 1.0 0.001 30 10  number of neighboors, the accuracy of the train model is 0.7769808173477898 % and the accuracy of the valid model is 0.5217608804402201 %\n",
      "[[ 2.          0.4002001 ]\n",
      " [ 3.          1.90095048]\n",
      " [ 4.         26.21310655]\n",
      " [ 5.         71.48574287]]\n",
      "1 100.0\n",
      "2 99.59979989994997\n",
      "3 98.09904952476238\n",
      "4 73.78689344672335\n",
      "5 28.51425712856428\n",
      "With 1.0 0.001 30 50  number of neighboors, the accuracy of the train model is 0.6964136780650542 % and the accuracy of the valid model is 0.6358179089544772 %\n",
      "[[ 3.          0.10005003]\n",
      " [ 4.          5.05252626]\n",
      " [ 5.         94.84742371]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 99.89994997498749\n",
      "4 94.94747373686843\n",
      "5 5.152576288144072\n",
      "With 1.0 0.001 30 100  number of neighboors, the accuracy of the train model is 0.7576313594662218 % and the accuracy of the valid model is 0.5742871435717859 %\n",
      "[[ 3.          2.25112556]\n",
      " [ 4.         14.75737869]\n",
      " [ 5.         82.99149575]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.74887443721862\n",
      "4 85.24262131065534\n",
      "5 17.008504252126063\n",
      "With 1.0 0.001 30 150  number of neighboors, the accuracy of the train model is 0.7577981651376147 % and the accuracy of the valid model is 0.5597798899449725 %\n",
      "[[ 3.          2.35117559]\n",
      " [ 4.         18.45922961]\n",
      " [ 5.         79.1895948 ]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.6488244122061\n",
      "4 81.5407703851926\n",
      "5 20.810405202601302\n",
      "With 1.0 0.001 30 500  number of neighboors, the accuracy of the train model is 0.7988323603002502 % and the accuracy of the valid model is 0.48574287143571787 %\n",
      "[[ 3.          8.45422711]\n",
      " [ 4.         24.16208104]\n",
      " [ 5.         67.38369185]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 91.54577288644322\n",
      "4 75.83791895947975\n",
      "5 32.61630815407704\n",
      "With 1.0 0.01 10 10  number of neighboors, the accuracy of the train model is 0.6855713094245204 % and the accuracy of the valid model is 0.6283141570785392 %\n",
      "[[ 3.          4.60230115]\n",
      " [ 4.          0.65032516]\n",
      " [ 5.         94.74737369]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 95.39769884942471\n",
      "4 99.34967483741872\n",
      "5 5.252626313156578\n",
      "With 1.0 0.01 10 50  number of neighboors, the accuracy of the train model is 0.6470391993327773 % and the accuracy of the valid model is 0.6533266633316658 %\n",
      "[[ 4.          0.10005003]\n",
      " [ 5.         99.89994997]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.89994997498749\n",
      "5 0.10005002501250625\n",
      "With 1.0 0.01 10 100  number of neighboors, the accuracy of the train model is 0.742952460383653 % and the accuracy of the valid model is 0.5032516258129065 %\n",
      "[[ 3.         12.95647824]\n",
      " [ 4.         17.25862931]\n",
      " [ 5.         69.78489245]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 87.04352176088044\n",
      "4 82.74137068534267\n",
      "5 30.21510755377689\n",
      "With 1.0 0.01 10 150  number of neighboors, the accuracy of the train model is 0.6929107589658048 % and the accuracy of the valid model is 0.5757878939469735 %\n",
      "[[ 3.          8.25412706]\n",
      " [ 4.          7.25362681]\n",
      " [ 5.         84.49224612]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 91.74587293646823\n",
      "4 92.7463731865933\n",
      "5 15.507753876938468\n",
      "With 1.0 0.01 10 500  number of neighboors, the accuracy of the train model is 0.6849040867389491 % and the accuracy of the valid model is 0.5957978989494748 %\n",
      "[[ 3.          2.70135068]\n",
      " [ 4.          9.45472736]\n",
      " [ 5.         87.84392196]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 97.29864932466234\n",
      "4 90.54527263631816\n",
      "5 12.156078039019508\n",
      "With 1.0 0.01 20 10  number of neighboors, the accuracy of the train model is 0.7206005004170142 % and the accuracy of the valid model is 0.5902951475737869 %\n",
      "[[ 3.          5.70285143]\n",
      " [ 4.          8.30415208]\n",
      " [ 5.         85.9929965 ]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.29714857428715\n",
      "4 91.69584792396198\n",
      "5 14.007003501750875\n",
      "With 1.0 0.01 20 50  number of neighboors, the accuracy of the train model is 0.7597998331943286 % and the accuracy of the valid model is 0.5402701350675337 %\n",
      "[[ 1.          0.85042521]\n",
      " [ 3.          9.70485243]\n",
      " [ 4.         10.35517759]\n",
      " [ 5.         79.08954477]]\n",
      "1 99.1495747873937\n",
      "2 100.0\n",
      "3 90.29514757378689\n",
      "4 89.64482241120561\n",
      "5 20.910455227613806\n",
      "With 1.0 0.01 20 100  number of neighboors, the accuracy of the train model is 0.741117597998332 % and the accuracy of the valid model is 0.5582791395697849 %\n",
      "[[ 1.          1.00050025]\n",
      " [ 3.          7.35367684]\n",
      " [ 4.          8.60430215]\n",
      " [ 5.         83.04152076]]\n",
      "1 98.99949974987494\n",
      "2 100.0\n",
      "3 92.6463231615808\n",
      "4 91.39569784892446\n",
      "5 16.95847923961981\n",
      "With 1.0 0.01 20 150  number of neighboors, the accuracy of the train model is 0.7177648040033361 % and the accuracy of the valid model is 0.5592796398199099 %\n",
      "[[ 3.         14.05702851]\n",
      " [ 4.          3.50175088]\n",
      " [ 5.         82.44122061]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 85.94297148574287\n",
      "4 96.49824912456228\n",
      "5 17.55877938969485\n",
      "With 1.0 0.01 20 500  number of neighboors, the accuracy of the train model is 0.7476230191826522 % and the accuracy of the valid model is 0.5022511255627814 %\n",
      "[[ 3.         14.65732866]\n",
      " [ 4.         15.70785393]\n",
      " [ 5.         69.63481741]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 85.34267133566783\n",
      "4 84.29214607303652\n",
      "5 30.365182591295646\n",
      "With 1.0 0.01 30 10  number of neighboors, the accuracy of the train model is 0.7022518765638032 % and the accuracy of the valid model is 0.608304152076038 %\n",
      "[[2.00000000e+00 5.00250125e-02]\n",
      " [3.00000000e+00 3.50175088e+00]\n",
      " [4.00000000e+00 7.40370185e+00]\n",
      " [5.00000000e+00 8.90445223e+01]]\n",
      "1 100.0\n",
      "2 99.94997498749375\n",
      "3 96.49824912456228\n",
      "4 92.59629814907454\n",
      "5 10.955477738869435\n",
      "With 1.0 0.01 30 50  number of neighboors, the accuracy of the train model is 0.6635529608006672 % and the accuracy of the valid model is 0.6498249124562281 %\n",
      "[[ 4.          0.60030015]\n",
      " [ 5.         99.39969985]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 99.39969984992496\n",
      "5 0.6003001500750376\n",
      "With 1.0 0.01 30 100  number of neighboors, the accuracy of the train model is 0.7367806505421184 % and the accuracy of the valid model is 0.5462731365682841 %\n",
      "[[ 1.          0.20010005]\n",
      " [ 2.          0.15007504]\n",
      " [ 3.         13.70685343]\n",
      " [ 4.          5.00250125]\n",
      " [ 5.         80.94047024]]\n",
      "1 99.79989994997499\n",
      "2 99.84992496248124\n",
      "3 86.29314657328663\n",
      "4 94.99749874937469\n",
      "5 19.05952976488244\n",
      "With 1.0 0.01 30 150  number of neighboors, the accuracy of the train model is 0.7147623019182652 % and the accuracy of the valid model is 0.5882941470735368 %\n",
      "[[ 3.          5.05252626]\n",
      " [ 4.          9.00450225]\n",
      " [ 5.         85.94297149]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 94.94747373686843\n",
      "4 90.99549774887443\n",
      "5 14.057028514257128\n",
      "With 1.0 0.01 30 500  number of neighboors, the accuracy of the train model is 0.7055879899916597 % and the accuracy of the valid model is 0.5467733866933466 %\n",
      "[[ 3.          7.95397699]\n",
      " [ 4.         11.50575288]\n",
      " [ 5.         80.54027014]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 92.04602301150575\n",
      "4 88.49424712356178\n",
      "5 19.459729864932466\n",
      "With 1.0 0.1 10 10  number of neighboors, the accuracy of the train model is 0.6458715596330276 % and the accuracy of the valid model is 0.6528264132066033 %\n",
      "[[  5. 100.]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 0.0\n",
      "With 1.0 0.1 10 50  number of neighboors, the accuracy of the train model is 0.6530442035029191 % and the accuracy of the valid model is 0.6418209104552276 %\n",
      "[[ 3.          3.10155078]\n",
      " [ 5.         96.89844922]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.8984492246123\n",
      "4 100.0\n",
      "5 3.1015507753876936\n",
      "With 1.0 0.1 10 100  number of neighboors, the accuracy of the train model is 0.6470391993327773 % and the accuracy of the valid model is 0.6383191595797899 %\n",
      "[[ 2.          0.65032516]\n",
      " [ 4.          3.10155078]\n",
      " [ 5.         96.24812406]]\n",
      "1 100.0\n",
      "2 99.34967483741872\n",
      "3 100.0\n",
      "4 96.8984492246123\n",
      "5 3.7518759379689848\n",
      "With 1.0 0.1 10 150  number of neighboors, the accuracy of the train model is 0.6488740617180984 % and the accuracy of the valid model is 0.647823911955978 %\n",
      "[[ 4.         1.2006003]\n",
      " [ 5.        98.7993997]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 98.79939969984991\n",
      "5 1.2006003001500751\n",
      "With 1.0 0.1 10 500  number of neighboors, the accuracy of the train model is 0.6478732276897414 % and the accuracy of the valid model is 0.6463231615807904 %\n",
      "[[ 3.         1.2006003]\n",
      " [ 5.        98.7993997]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 98.79939969984991\n",
      "4 100.0\n",
      "5 1.2006003001500751\n",
      "With 1.0 0.1 20 10  number of neighboors, the accuracy of the train model is 0.6533778148457048 % and the accuracy of the valid model is 0.6353176588294147 %\n",
      "[[ 3.          3.75187594]\n",
      " [ 5.         96.24812406]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 96.24812406203101\n",
      "4 100.0\n",
      "5 3.7518759379689848\n",
      "With 1.0 0.1 20 50  number of neighboors, the accuracy of the train model is 0.653211009174312 % and the accuracy of the valid model is 0.6008004002001001 %\n",
      "[[ 1.          1.80090045]\n",
      " [ 3.          8.30415208]\n",
      " [ 5.         89.89494747]]\n",
      "1 98.19909954977489\n",
      "2 100.0\n",
      "3 91.69584792396198\n",
      "4 100.0\n",
      "5 10.105052526263131\n",
      "With 1.0 0.1 20 100  number of neighboors, the accuracy of the train model is 0.6520433694745621 % and the accuracy of the valid model is 0.6353176588294147 %\n",
      "[[ 1.          2.35117559]\n",
      " [ 2.          0.8004002 ]\n",
      " [ 5.         96.84842421]]\n",
      "1 97.6488244122061\n",
      "2 99.19959979989996\n",
      "3 100.0\n",
      "4 100.0\n",
      "5 3.1515757878939468\n",
      "With 1.0 0.1 20 150  number of neighboors, the accuracy of the train model is 0.6582151793160967 % and the accuracy of the valid model is 0.6363181590795398 %\n",
      "[[ 2.          0.35017509]\n",
      " [ 3.          3.30165083]\n",
      " [ 5.         96.34817409]]\n",
      "1 100.0\n",
      "2 99.64982491245622\n",
      "3 96.69834917458729\n",
      "4 100.0\n",
      "5 3.651825912956478\n",
      "With 1.0 0.1 20 500  number of neighboors, the accuracy of the train model is 0.6518765638031693 % and the accuracy of the valid model is 0.5942971485742872 %\n",
      "[[ 1.          0.45022511]\n",
      " [ 3.         11.85592796]\n",
      " [ 5.         87.69384692]]\n",
      "1 99.54977488744372\n",
      "2 100.0\n",
      "3 88.144072036018\n",
      "4 100.0\n",
      "5 12.30615307653827\n",
      "With 1.0 0.1 30 10  number of neighboors, the accuracy of the train model is 0.6490408673894913 % and the accuracy of the valid model is 0.6038019009504753 %\n",
      "[[ 3.         11.25562781]\n",
      " [ 5.         88.74437219]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 88.74437218609305\n",
      "4 100.0\n",
      "5 11.255627813906953\n",
      "With 1.0 0.1 30 50  number of neighboors, the accuracy of the train model is 0.6483736447039199 % and the accuracy of the valid model is 0.6458229114557279 %\n",
      "[[ 4.          2.35117559]\n",
      " [ 5.         97.64882441]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 97.6488244122061\n",
      "5 2.351175587793897\n",
      "With 1.0 0.1 30 100  number of neighboors, the accuracy of the train model is 0.6610508757297748 % and the accuracy of the valid model is 0.631815907953977 %\n",
      "[[ 1.          0.20010005]\n",
      " [ 3.          3.55177589]\n",
      " [ 5.         96.24812406]]\n",
      "1 99.79989994997499\n",
      "2 100.0\n",
      "3 96.44822411205602\n",
      "4 100.0\n",
      "5 3.7518759379689848\n",
      "With 1.0 0.1 30 150  number of neighboors, the accuracy of the train model is 0.6482068390325271 % and the accuracy of the valid model is 0.639319659829915 %\n",
      "[[ 4.          6.20310155]\n",
      " [ 5.         93.79689845]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 100.0\n",
      "4 93.79689844922461\n",
      "5 6.203101550775387\n",
      "With 1.0 0.1 30 500  number of neighboors, the accuracy of the train model is 0.6560467055879899 % and the accuracy of the valid model is 0.6123061530765382 %\n",
      "[[ 3.         10.95547774]\n",
      " [ 5.         89.04452226]]\n",
      "1 100.0\n",
      "2 100.0\n",
      "3 89.04452226113057\n",
      "4 100.0\n",
      "5 10.955477738869435\n"
     ]
    }
   ],
   "source": [
    "loss_train, loss_valid = [], []\n",
    "list_nn_acc_valid, list_nn_acc_train, a_list, lr_list, neuron_list, layer_list, precision, recall = [\n",
    "], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for a in alpha:\n",
    "    for lr in learning_rates:\n",
    "        for neuron in nb_neurons:\n",
    "            for count, layer in enumerate(nb_hidden_layer):\n",
    "                nn = MLPClassifier(alpha=a,\n",
    "                                   hidden_layer_sizes=(neuron, layer),\n",
    "                                   random_state=1,\n",
    "                                   learning_rate_init=lr,\n",
    "                                   max_iter=100,\n",
    "                                   early_stopping=True\n",
    "                                   )\n",
    "                nn.fit(train_data_features, y_train)\n",
    "\n",
    "                nn_acc_train = nn.score(train_data_features, y_train)\n",
    "                nn_acc_valid = nn.score(valid_data_features, y_val)\n",
    "\n",
    "                unique, counts = np.unique(nn.predict(\n",
    "                    valid_data_features), return_counts=True)\n",
    "\n",
    "                loss_train.append(nn_acc_train)\n",
    "                loss_valid.append(nn_acc_valid)\n",
    "\n",
    "                print(\"With\", a, lr, neuron, layer, \" number of neighboors, the accuracy of the train model is\", nn_acc_train,\n",
    "                      \"% and the accuracy of the valid model is\", nn_acc_valid, \"%\")\n",
    "\n",
    "                print(np.asarray((unique, (counts/len(y_val))*100)).T)\n",
    "\n",
    "                for i in np.unique(y_val):\n",
    "                    lmao = (sum(nn.predict(valid_data_features)\n",
    "                                != i)/len(y_val == i))*100\n",
    "                    print(i, lmao)\n",
    "\n",
    "                prf = precision_recall_fscore_support(y_val, nn.predict(\n",
    "                    valid_data_features), average='weighted', zero_division=1)\n",
    "\n",
    "                list_nn_acc_train.append(nn_acc_train)\n",
    "                list_nn_acc_valid.append(nn_acc_valid)\n",
    "                a_list.append(a)\n",
    "                lr_list.append(lr)\n",
    "                neuron_list.append(neuron)\n",
    "                layer_list.append(layer)\n",
    "                precision.append(prf[0])\n",
    "                recall.append(prf[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2 Regularizarion term</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Accuracy of Train</th>\n",
       "      <th>Acccuracy of Valid</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.594297</td>\n",
       "      <td>0.527965</td>\n",
       "      <td>0.594297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.645872</td>\n",
       "      <td>0.652326</td>\n",
       "      <td>0.743227</td>\n",
       "      <td>0.652326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.645872</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.741451</td>\n",
       "      <td>0.548774</td>\n",
       "      <td>0.533952</td>\n",
       "      <td>0.548774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.754962</td>\n",
       "      <td>0.542771</td>\n",
       "      <td>0.527928</td>\n",
       "      <td>0.542771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.649041</td>\n",
       "      <td>0.603802</td>\n",
       "      <td>0.694856</td>\n",
       "      <td>0.603802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.645823</td>\n",
       "      <td>0.627736</td>\n",
       "      <td>0.645823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.661051</td>\n",
       "      <td>0.631816</td>\n",
       "      <td>0.664737</td>\n",
       "      <td>0.631816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>0.648207</td>\n",
       "      <td>0.639320</td>\n",
       "      <td>0.647745</td>\n",
       "      <td>0.639320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>0.656047</td>\n",
       "      <td>0.612306</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.612306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L2 Regularizarion term  Learning Rate  Number of neurons  \\\n",
       "0                       0.0          0.001                 10   \n",
       "1                       0.0          0.001                 10   \n",
       "2                       0.0          0.001                 10   \n",
       "3                       0.0          0.001                 10   \n",
       "4                       0.0          0.001                 10   \n",
       "..                      ...            ...                ...   \n",
       "130                     1.0          0.100                 30   \n",
       "131                     1.0          0.100                 30   \n",
       "132                     1.0          0.100                 30   \n",
       "133                     1.0          0.100                 30   \n",
       "134                     1.0          0.100                 30   \n",
       "\n",
       "     Number of layers  Accuracy of Train  Acccuracy of Valid  Precision  \\\n",
       "0                  10           0.689241            0.594297   0.527965   \n",
       "1                  50           0.645872            0.652326   0.743227   \n",
       "2                 100           0.645872            0.652826   0.773356   \n",
       "3                 150           0.741451            0.548774   0.533952   \n",
       "4                 500           0.754962            0.542771   0.527928   \n",
       "..                ...                ...                 ...        ...   \n",
       "130                10           0.649041            0.603802   0.694856   \n",
       "131                50           0.648374            0.645823   0.627736   \n",
       "132               100           0.661051            0.631816   0.664737   \n",
       "133               150           0.648207            0.639320   0.647745   \n",
       "134               500           0.656047            0.612306   0.700787   \n",
       "\n",
       "       Recall  \n",
       "0    0.594297  \n",
       "1    0.652326  \n",
       "2    0.652826  \n",
       "3    0.548774  \n",
       "4    0.542771  \n",
       "..        ...  \n",
       "130  0.603802  \n",
       "131  0.645823  \n",
       "132  0.631816  \n",
       "133  0.639320  \n",
       "134  0.612306  \n",
       "\n",
       "[135 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_tuples = list(zip(a_list, lr_list, neuron_list, layer_list,\n",
    "                       list_nn_acc_train, list_nn_acc_valid, precision, recall))\n",
    "q3_data = pd.DataFrame(data_tuples, columns=['L2 Regularizarion term',\n",
    "                                             'Learning Rate',\n",
    "                                             'Number of neurons',\n",
    "                                             'Number of layers',\n",
    "                                             'Accuracy of Train',\n",
    "                                             'Acccuracy of Valid',\n",
    "                                             'Precision',\n",
    "                                             'Recall'])\n",
    "q3_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2 Regularizarion term</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Accuracy of Train</th>\n",
       "      <th>Acccuracy of Valid</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>row_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.647039</td>\n",
       "      <td>0.653327</td>\n",
       "      <td>0.677485</td>\n",
       "      <td>0.653327</td>\n",
       "      <td>0.653327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.647873</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.646205</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.652826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.815680</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>0.499633</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>0.815680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>0.798832</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.520923</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.798832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>0.828190</td>\n",
       "      <td>0.484742</td>\n",
       "      <td>0.515759</td>\n",
       "      <td>0.484742</td>\n",
       "      <td>0.828190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.477739</td>\n",
       "      <td>0.500631</td>\n",
       "      <td>0.477739</td>\n",
       "      <td>0.766639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>0.853545</td>\n",
       "      <td>0.472236</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.472236</td>\n",
       "      <td>0.853545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L2 Regularizarion term  Learning Rate  Number of neurons  \\\n",
       "106                     1.0          0.010                 10   \n",
       "7                       0.0          0.001                 20   \n",
       "17                      0.0          0.010                 10   \n",
       "52                      0.5          0.001                 20   \n",
       "62                      0.5          0.010                 10   \n",
       "..                      ...            ...                ...   \n",
       "10                      0.0          0.001                 30   \n",
       "104                     1.0          0.001                 30   \n",
       "59                      0.5          0.001                 30   \n",
       "60                      0.5          0.010                 10   \n",
       "53                      0.5          0.001                 20   \n",
       "\n",
       "     Number of layers  Accuracy of Train  Acccuracy of Valid  Precision  \\\n",
       "106                50           0.647039            0.653327   0.677485   \n",
       "7                 100           0.647873            0.652826   0.773356   \n",
       "17                100           0.647540            0.652826   0.773356   \n",
       "52                100           0.647540            0.652826   0.773356   \n",
       "62                100           0.646205            0.652826   0.773356   \n",
       "..                ...                ...                 ...        ...   \n",
       "10                 10           0.815680            0.500750   0.499633   \n",
       "104               500           0.798832            0.485743   0.520923   \n",
       "59                500           0.828190            0.484742   0.515759   \n",
       "60                 10           0.766639            0.477739   0.500631   \n",
       "53                150           0.853545            0.472236   0.475700   \n",
       "\n",
       "       Recall   row_max  \n",
       "106  0.653327  0.653327  \n",
       "7    0.652826  0.652826  \n",
       "17   0.652826  0.652826  \n",
       "52   0.652826  0.652826  \n",
       "62   0.652826  0.652826  \n",
       "..        ...       ...  \n",
       "10   0.500750  0.815680  \n",
       "104  0.485743  0.798832  \n",
       "59   0.484742  0.828190  \n",
       "60   0.477739  0.766639  \n",
       "53   0.472236  0.853545  \n",
       "\n",
       "[135 rows x 9 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_data.sort_values(['Acccuracy of Valid', 'Accuracy of Train'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7007869154422267"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf = precision_recall_fscore_support(y_val, nn.predict(\n",
    "    valid_data_features), average='weighted', zero_division=1)\n",
    "prf[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label='Train')\n",
    "plt.plot(loss_valid, label='Validation')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Ghosting the legend\n",
    "leg = plt.gca().legend(loc='center left', bbox_to_anchor=(1, .85))\n",
    "leg.get_frame().set_alpha(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.652826\n",
       "4    0.192596\n",
       "3    0.098049\n",
       "2    0.030015\n",
       "1    0.026513\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6458715596330276\n"
     ]
    }
   ],
   "source": [
    "print(nn_acc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    1]\n",
      " [   3    1]\n",
      " [   4   10]\n",
      " [   5 5983]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(y_val):\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74353a82122c5d55f703c3a3a783b2a3ad031173147999716060960d34a2cdc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
